
@article{michael_verification_2011,
	title = {Verification and Validation for Trustworthy Software Systems},
	volume = {28},
	issn = {0740-7459},
	doi = {10.1109/MS.2011.151},
	abstract = {A continuous and proactive process for conducting verification and validation of systems involves using scenario-based testing to validate whether formal assertions correctly capture the intent of the natural language requirements. The process is automated through the use of statechart assertions and runtime execution monitoring. The statechart assertions can be used as part of a system reference model in support of independent verification and validation of trustworthy systems.},
	pages = {86--92},
	number = {6},
	journaltitle = {{IEEE} Software},
	author = {Michael, J.B. and Drusinsky, D. and Otani, T.W. and Shing, Man-Tak},
	date = {2011-11},
	keywords = {assertion checker, assertion languages, formal methods, formal verification, natural language requirement, performance, Performance evaluation, program, Programming, program testing, requirements, runtime execution monitoring, safety-critical software, scenario-based testing, software, Software development, Software engineering, software system validation, software system verification, specification, statechart assertion, trustworthy software systems, Validation, verification},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/7XEJAWTJ/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/6A2BKDK5/Michael et al. - 2011 - Verification and Validation for Trustworthy Softwa.pdf:application/pdf}
}

@online{pankaj_so_????,
	title = {So, you want to create users using django-tastypie - psjinx's blog},
	url = {http://psjinx.com/programming/2013/06/07/so-you-want-to-create-users-using-djangotastypie/},
	author = {Pankaj, Singh},
	urldate = {2014-03-11},
	file = {So, you want to create users using django-tastypie - psjinx's blog:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/2CSDA987/so-you-want-to-create-users-using-djangotastypie.html:text/html}
}

@inreference{_assignment_????,
	title = {Assignment operator (C++)},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {http://en.wikipedia.org/w/index.php?title=Assignment_operator_(C%2B%2B)&oldid=583584312},
	abstract = {In the C++ programming language, the assignment operator, '=', is the operator used for assignment. Like most other operators in C++, it can be overloaded.},
	booktitle = {Wikipedia, the free encyclopedia},
	urldate = {2014-02-05},
	langid = {english},
	note = {Page Version {ID}: 583584312},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/XBU2FPB6/index.html:text/html}
}

@online{_center_????,
	title = {Center for Research in Language},
	url = {http://crl.ucsd.edu/corpora/},
	urldate = {2014-03-11},
	file = {Center for Research in Language:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/2VMBD2IQ/corpora.html:text/html}
}

@article{xu_topic_????,
	title = {Topic Linkages between Papers and Patents},
	url = {http://www.researchgate.net/publication/231590354_Topic_Linkages_between_Papers_and_Patents/file/d912f506d899593d83.pdf},
	author = {Xu, Shuo and Zhu, Lijun and Qiao, Xiaodong and Shi, Qingwei and Gui, Jie},
	urldate = {2014-02-05},
	file = {[PDF] from researchgate.net:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/3N6TEEMS/Xu et al. - Topic Linkages between Papers and Patents.pdf:application/pdf}
}

@online{_minimum_????,
	title = {Minimum Spanning Trees},
	url = {http://algs4.cs.princeton.edu/43mst/},
	urldate = {2014-03-11},
	file = {Minimum Spanning Trees:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/9G8FQKRZ/43mst.html:text/html}
}

@online{_micah_????,
	title = {Micah Beverly - Second Place - {BOSS} Loop Station U.S. National Finals},
	url = {http://www.youtube.com/watch?v=-Wr6AEm_87M},
	abstract = {Congratulations to Micah Beverly who took second place in the 2010 U.S. National Finals at Musicians Institute in Hollywood, {CA}. Stay tuned for information o...},
	titleaddon = {{YouTube}},
	urldate = {2014-09-23},
	keywords = {beverly, boss, championship, loop, micah, station, world},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/5IWEUSM9/watch.html:text/html}
}

@inproceedings{wang_role-based_2007,
	title = {Role-based Recommendation and Trust Evaluation},
	pages = {278--288},
	booktitle = {E-Commerce, and E-Services},
	publisher = {E-Commerce, and E-Services},
	author = {Wang, Yan and Varadharajan, V.},
	editor = {{CEC}/{EEE}},
	date = {2007},
	keywords = {Books, Data analysis, Electronic commerce, Feedback, History, information filters, Motion pictures, Network servers, Peer to peer computing, recommendation receiver, recommendation reputation, role-based recommendation, Sections, security of data, Target recognition, trust evaluation framework, trust evaluation systems, trust ratings},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/Q9BS8PJ5/articleDetails.html:text/html}
}

@article{aiello_sensing_2013,
	title = {Sensing Trending Topics in Twitter},
	volume = {15},
	issn = {1520-9210},
	doi = {10.1109/TMM.2013.2265080},
	abstract = {Online social and news media generate rich and timely information about real-world events of all kinds. However, the huge amount of data available, along with the breadth of the user base, requires a substantial effort of information filtering to successfully drill down to relevant topics and events. Trending topic detection is therefore a fundamental building block to monitor and summarize information originating from social sources. There are a wide variety of methods and variables and they greatly affect the quality of results. We compare six topic detection methods on three Twitter datasets related to major events, which differ in their time scale and topic churn rate. We observe how the nature of the event considered, the volume of activity over time, the sampling procedure and the pre-processing of the data all greatly affect the quality of detected topics, which also depends on the type of detection method used. We find that standard natural language processing techniques can perform well for social streams on very focused topics, but novel techniques designed to mine the temporal distribution of concepts are needed to handle more heterogeneous streams containing multiple stories evolving in parallel. One of the novel topic detection methods we propose, based on -grams cooccurrence and topic ranking, consistently achieves the best performance across all these conditions, thus being more reliable than other state-of-the-art techniques.},
	pages = {1268--1282},
	number = {6},
	journaltitle = {{IEEE} Transactions on Multimedia},
	author = {Aiello, L.M. and Petkos, G. and Martin, C. and Corney, D. and Papadopoulos, S. and Skraba, R. and Goker, A and Kompatsiaris, I and Jaimes, A},
	date = {2013-10},
	keywords = {information filtering, natural language processing, natural language processing techniques, online news media, online social media, sampling procedure, sensing trending topics, Social media, social networking (online), social sensing, social sources, social streams, text mining, topic detection, topic detection methods, trending topic detection, Twitter, Twitter datasets},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/CZ9CMVVF/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/46SV8DWB/Aiello et al. - 2013 - Sensing Trending Topics in Twitter.pdf:application/pdf}
}

@article{salton_term-weighting_1988,
	title = {Term-weighting approaches in automatic text retrieval},
	volume = {24},
	issn = {0306-4573},
	url = {http://www.sciencedirect.com/science/article/pii/0306457388900210},
	doi = {10.1016/0306-4573(88)90021-0},
	abstract = {The experimental evidence accumulated over the past 20 years indicates that text indexing systems based on the assignment of appropriately weighted single terms produce retrieval results that are superior to those obtainable with other more elaborate text representations. These results depend crucially on the choice of effective termweighting systems. This article summarizes the insights gained in automatic term weighting, and provides baseline single-term-indexing models with which other more elaborate content analysis procedures can be compared.},
	pages = {513--523},
	number = {5},
	journaltitle = {Information Processing \& Management},
	shortjournal = {Information Processing \& Management},
	author = {Salton, Gerard and Buckley, Christopher},
	urldate = {2014-09-14},
	date = {1988},
	file = {ScienceDirect Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/8SVZRDGQ/Salton and Buckley - 1988 - Term-weighting approaches in automatic text retrie.pdf:application/pdf;ScienceDirect Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/HK6QEDG6/0306457388900210.html:text/html}
}

@online{_how_????,
	title = {How to Enable and Secure Remote Desktop on Windows},
	url = {http://www.howtogeek.com/175087/how-to-enable-and-secure-remote-desktop-on-windows/},
	urldate = {2014-03-11},
	file = {How to Enable and Secure Remote Desktop on Windows:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/KHZ4Q9XS/how-to-enable-and-secure-remote-desktop-on-windows.html:text/html}
}

@inreference{_plate_2014,
	title = {Plate notation},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {http://en.wikipedia.org/w/index.php?title=Plate_notation&oldid=601839889},
	abstract = {Plate notation is a method of representing variables that repeat in a graphical model. Instead of drawing each repeated variable individually, a plate or rectangle is used to group variables into a subgraph that repeat together, and a number is drawn on the plate to represent the number of repetitions of the subgraph in the plate.[1] The assumptions are that the subgraph is duplicated that many times, the variables in the subgraph are indexed by the repetition number, and any links that cross a plate boundary are replicated once for each subgraph repetition.[2]},
	booktitle = {Wikipedia, the free encyclopedia},
	urldate = {2014-09-14},
	date = {2014-08-24},
	langid = {english},
	note = {Page Version {ID}: 601839889},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/2E95HTBU/index.html:text/html}
}

@online{_design_????,
	title = {Design of Experiments for Software Testing},
	url = {http://www.isixsigma.com/tools-templates/design-of-experiments-doe/design-experiments-software-testing/},
	abstract = {When {DOE} is used for software testing, there is a large amount of savings in testing time and cost. Use of orthogonal array based testing has demonstrated to},
	urldate = {2014-09-13},
	keywords = {design of experiments, doe, software, software testing},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/GI7NUHNQ/design-experiments-software-testing.html:text/html}
}

@video{isixsigmavideos_what_2013,
	title = {What Makes Design of Experiments ({DOE}) Better than A/B Testing?},
	url = {http://www.youtube.com/watch?v=5fhiFI1eeb4&feature=youtube_gdata_player},
	abstract = {Watch the full interview: http://www.isixsigma.com/tools-templates/design-of-experiments-doe/mark-kiemele-interview/

Michael: A lot of companies in the startup world were focused on A/B testing. There are a whole slew of service providers online, like Optimizely.com or {VisualWebsiteOptimizer}.com; even Google Analytics allows companies to do A/B testing. 

So, if I have a signup page on {iSixSigma}.com, for example, I can test how many people come to the page and click and sign up with a green button versus an orange button on the side. So that is {AB} testing, or one factor at a time testing. I change one factor and I measure it. What makes {DOE} different from these other testing techniques like one factor at a time, or educated guesses, or {AB} testing?

Mark: That is a great question, Mike, because that is the heart and soul of {DOE}. Why would I want to use a {DOE} when I was taught, in high school, to do one factor at a time testing? When my chemistry teacher says, "When you want to see the effect of temperature on this experiment, you got to hold everything else the same and you just change that one thing, and then you will see what effect it has on your yield or whatever you are measuring for a response or an output." How misinformed are we, because we are teaching people at the very young stages of their life to do this {AB}, or one factor at a time, testing? There is different criteria or, what I should say, attributes of {DOE}, like replication, randomization, which we will talk about a little bit later when we get into the examples, but the one characteristic of {DOE} that distinguishes it from everything else is the concept of orthogonality. Orthogonality allows, and that is how we distinguish {DOE}. A {DOE} is a testing technique that has an orthogonal design or nearly orthogonal design. Now, what orthogonality buys is the ability to evaluate these factors, their effects, and the interactions independently from one another. That keyword is independent evaluation. And what does independent evaluation buy us? Well, independent evaluation buys us the ability to get to root cause. That is cause and effect relationships. And cause and effect relationships -- root cause analysis today is tough stuff, Mike. People make light of it. It is hard because of those doggone combination effects.

Michael: Right.

Mark: Those interaction effects. So, if you have orthogonal designs, orthogonality buys you the ability to evaluate the effects independently. Independence allows you to buy the ability to get to root cause analysis. And of course, if you can find root causes of problems, guess what? Your decision-making is enhanced and, of course, the financial aspect will also be enhanced. So that is the orthogonality aspect.

Michael: Okay. And so, that all makes sense to me, Mark. I think most of the people that watch this show are educated like you and I are, and they can understand that you are saying orthogonality is this concept that allows you to evaluate the factors independently. So you do not see the bias. You do not have results that are confounded; is another word that means the results you are seeing are actually affected by something else that you are not anticipating. So that makes sense, but then I just go back to my real world example, where I have got a signup page on {iSixSigma}.com, and the output variable from what you were telling me earlier was I want people to actually sign up. Maybe it is put in an email address and click the signup button. Right? And so, {AB} testing would tell me, or my fifth grade science teacher would tell me, "Start off with an orange button. Change it to a green button. See how much that affects it. Then go from whichever one is better. That is now your base. Now change it from a green button with a sans serif font to a serif font, and so it feels more like a typewriter. Maybe that will affect people." Every industry and every group of people is different, and you might say that the fortune one hundred, which come to visit {iSixSigma}.com to learn about concepts like {DOE} would be more attuned to a font that looks like a typewriter, let's say, and so they are going to get a higher click-through rate on that. Will {DOE} allow me to say: "My output is signups on this page; now I want to look at all the factors that are involved," and just solve it once, so I am not doing {AB} testing for the rest of my life?

Mark: Absolutely, Mike. That is the beauty and power of {DOE}. You can test multiple things simultaneously and still evaluate the effects independently. Orthogonality means balance in the design. That is -- get back to your font and you color thing. You now home in on their orange or green, and then you start changing the fonts. There is a way to test those simultaneously so that you have balance in the design. And that balance will allow you to get that independent evaluation. We will talk a little bit about that in one of the examples that we do.},
	editora = {{iSixSigmaVideos}},
	editoratype = {collaborator},
	urldate = {2014-09-21},
	date = {2013-06-13}
}

@article{gimpel_software_2014,
	title = {Software That Checks Software: The Impact of {PC}-lint},
	volume = {31},
	issn = {0740-7459},
	doi = {10.1109/MS.2014.13},
	shorttitle = {Software That Checks Software},
	abstract = {James Gimpel gives some fascinating insights into the growth, technology, and impact of the very widely used static analyzer, {PC}-lint in the never-ending battle against the bug.},
	pages = {15--19},
	number = {1},
	journaltitle = {{IEEE} Software},
	author = {Gimpel, J.},
	date = {2014-01},
	keywords = {compilers, Computer bugs, impact, lint, {PC}-lint, Program compilers, program debugging, program diagnostics, Program processors, program verification, software bug, software checking, static analyzer, Static analyzers, Turing machines},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/QBKB27VH/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/8WPFAF2X/Gimpel - 2014 - Software That Checks Software The Impact of PC-li.pdf:application/pdf}
}

@online{_support_????,
	title = {Support},
	url = {http://www.conserviscorp.com/service/},
	abstract = {Conservis' customer service team helps farmers get set up and trained on Conservis farm management software, and provides pro-active troubleshooting.},
	titleaddon = {Conservis},
	urldate = {2014-08-05},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/6PB5BX3A/service.html:text/html}
}

@online{symantec_whats_2014,
	title = {What's New in Symantec Data Loss Prevention},
	url = {http://www.symantec.com/content/en/us/enterprise/fact_sheets/b-whats-new-in-dlp12-21299912-en.us.pdf},
	author = {Symantec},
	urldate = {2014-09-08},
	date = {2014-04},
	file = {Symantec - Data Sheet - b-whats-new-in-dlp12-21299912-en.us.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/MJWNIB6N/b-whats-new-in-dlp12-21299912-en.us.pdf:application/pdf}
}

@inproceedings{wu_active_2011,
	title = {An Active Data Leakage Prevention Model for Insider Threat},
	pages = {39-- 42},
	booktitle = {Intelligence Information Processing and Trusted Computing ({IPTC})},
	publisher = {2011 2nd International Symposium on Communication},
	author = {Wu, J. and Zhou, J. and Ma, J. and Mei, S. and Ren, J.},
	date = {2011},
	note = {Networking \& Broadcasting},
	keywords = {active data leakage prevention model, active defense, Computers, Containers, data leakage prevention ({DLP}), Data models, data object, defense capabilities, Distributed databases, distributed environment, dynamic isolation mechanisms, formal description, insider threat, Memory, protection requirements, Security, security of data, security properties, virtual isolation, virtual isolation technologies, Virtual machining},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/8HWW85S8/login.html:text/html}
}

@article{antonopoulos_data_2009,
	title = {Data leakage prevention going mainstream},
	volume = {26},
	rights = {Copyright Network World Inc. Aug 31-Sep 7, 2009},
	issn = {08877661},
	url = {http://search.proquest.com.ezproxy1.lib.asu.edu/docview/215990129?pq-origsite=summon},
	abstract = {Data leakage or data loss prevention ({DLP}) systems have gradually entered the mainstream as their increasing maturity has allowed increasing adoption. Compliance drives the adoption of {DLP} in most companies, specifically compliance regulation on the privacy of personal information in healthcare, banking and credit card processing. {DLP} is not a silver bullet. Identifying and blocking all sensitive information is neither possible as an outcome nor wise as a goal. But with a narrower goal of preventing the most egregious leaks and helping both users and {IT} discover better ways to send information securely, {DLP} can be very successful.},
	pages = {20},
	number = {27},
	journaltitle = {Network World},
	author = {Antonopoulos, Andreas},
	urldate = {2014-07-19},
	date = {2009-09-31},
	keywords = {Communications--Computer Applications, Compliance, Data integrity, Loss control, Technology adoption},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/XH2UKZHE/215990129.html:text/html}
}

@online{_commentary/compiler/hscmain_????,
	title = {Commentary/Compiler/{HscMain} – {GHC}},
	url = {https://ghc.haskell.org/trac/ghc/wiki/Commentary/Compiler/HscMain},
	urldate = {2014-03-11},
	file = {Commentary/Compiler/HscMain – GHC:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/ICKUXF2T/HscMain.html:text/html}
}

@article{merkl_text_1998,
	title = {Text classification with self-organizing maps: Some lessons learned},
	volume = {21},
	url = {http://www.sciencedirect.com/science/article/pii/S0925231298000320},
	shorttitle = {Text classification with self-organizing maps},
	pages = {61--77},
	number = {1},
	journaltitle = {Neurocomputing},
	author = {Merkl, Dieter},
	urldate = {2014-09-08},
	date = {1998},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/T8SJWTMV/S0925231298000320.html:text/html}
}

@online{_template_????,
	title = {{TEMPLATE} {FOR} {SOFTWARE} {ACQUISITION} {BEST} {PRACTICES} - Model\_Based\_Testing.pdf},
	url = {https://www.csiac.org/sites/default/files/Model_Based_Testing.pdf},
	urldate = {2014-08-24},
	file = {TEMPLATE FOR SOFTWARE ACQUISITION BEST PRACTICES - Model_Based_Testing.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/RMKE6Q5U/Model_Based_Testing.pdf:application/pdf}
}

@online{_classic_????,
	title = {Classic Testing Mistakes - mistakes.pdf},
	url = {http://www.exampler.com/testing-com/writings/classic/mistakes.pdf},
	urldate = {2014-08-24},
	file = {Classic Testing Mistakes - mistakes.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/22SF488K/mistakes.pdf:application/pdf}
}

@online{_const_????,
	title = {Const correctness, C++ {FAQ}},
	url = {http://www.parashift.com/c++-faq-lite/const-correctness.html},
	urldate = {2014-02-05},
	file = {Const correctness, C++ FAQ:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/STGAZV6S/const-correctness.html:text/html}
}

@inproceedings{sotiropoulos_identifying_2013,
	title = {Identifying semantically meaningful sub-communities within Twitter blogosphere},
	doi = {10.1109/IISA.2013.6623727},
	abstract = {This paper addresses the problem of semantically meaningful group detection within a sub-community of twitter micro-bloggers by utilizing a topic modeling, multi-objective clustering approach. The proposed group detection method is anchored on the Latent Dirichlet Allocation ({LDA}) topic modeling technique, aiming at identifying clusters of twitter users that are optimal in terms of both spatial and topical compactness. Specifically, the group detection problem is formulated as a multi-objective optimization problem taking into consideration two complementary cluster formation directives. The first objective, related to spatial compactness, is achieved by minimizing the overall deviation from the corresponding cluster centers. The second, related to topical compactness, is achieved by minimizing the portion of probability mass assigned to low probability topics for the corresponding cluster centroids. In our approach, optimization is performed by employing a multi-objective genetic algorithm, which results in a variety of cluster structures that are significantly more interpretable than cluster assignments obtained with traditional single-objective clustering algorithms.},
	eventtitle = {2013 Fourth International Conference on Information, Intelligence, Systems and Applications ({IISA})},
	pages = {1--8},
	booktitle = {2013 Fourth International Conference on Information, Intelligence, Systems and Applications ({IISA})},
	author = {Sotiropoulos, D.N. and Kounavis, C.D. and Giaglis, G.M.},
	date = {2013-07},
	keywords = {cluster assignments, cluster centers, cluster centroids, Communities, complementary cluster formation directives, Context, genetic algorithms, latent dirichlet allocation, {LDA} topic modeling technique, low probability topics, multiobjective clustering, multiobjective genetic algorithm, multiobjective optimization problem, optimization, pattern clustering, Probability distribution, probability mass, semantically meaningful group detection, semantically meaningful sub-communities identification, Semantics, social networking (online), Social network services, spatial compactness, topical compactness, Twitter blogosphere, Twitter microbloggers, Vectors},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/MAB7N7G3/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/2UJDB6C5/Sotiropoulos et al. - 2013 - Identifying semantically meaningful sub-communitie.pdf:application/pdf}
}

@article{mao_artificial_1995,
	title = {Artificial neural networks for feature extraction and multivariate data projection},
	volume = {6},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=363467},
	pages = {296--317},
	number = {2},
	journaltitle = {Neural Networks, {IEEE} Transactions on},
	author = {Mao, Jianchang and Jain, Anil K.},
	urldate = {2014-09-08},
	date = {1995},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/5SKPSSMD/login.html:text/html}
}

@inproceedings{zhou_exploring_2008,
	title = {Exploring social annotations for information retrieval},
	url = {http://dl.acm.org/citation.cfm?id=1367594},
	pages = {715--724},
	booktitle = {Proceedings of the 17th international conference on World Wide Web},
	publisher = {{ACM}},
	author = {Zhou, Ding and Bian, Jiang and Zheng, Shuyi and Zha, Hongyuan and Giles, C. Lee},
	urldate = {2014-02-05},
	date = {2008},
	file = {[PDF] from psu.edu:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/5J5XCFHX/Zhou et al. - 2008 - Exploring social annotations for information retri.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/V2AKBMX4/citation.html:text/html}
}

@article{bekkerman_automatic_2004,
	title = {Automatic Categorization of Email into Folders: Benchmark Experiments on Enron and {SRI} Corpora},
	url = {http://scholarworks.umass.edu/cs_faculty_pubs/218},
	shorttitle = {Automatic Categorization of Email into Folders},
	journaltitle = {Computer Science Department Faculty Publication Series},
	author = {Bekkerman, Ron},
	date = {2004-01-01},
	file = {"Automatic Categorization of Email into Folders\: Benchmark Experiments " by Ron Bekkerman:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/IIJF4M8Z/218.html:text/html}
}

@article{aizawa_information-theoretic_2003,
	title = {An information-theoretic perspective of tf-idf measures},
	volume = {39},
	url = {http://www.sciencedirect.com.ezproxy1.lib.asu.edu/science/article/pii/S0306457302000213},
	pages = {45--65},
	number = {1},
	journaltitle = {Information Processing \& Management},
	author = {Aizawa, Akiko},
	urldate = {2014-09-14},
	date = {2003},
	file = {[PDF] from rutgers.edu:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/6DTX9MC5/Aizawa - 2003 - An information-theoretic perspective of tf–idf mea.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/93FRUI8E/S0306457302000213.html:text/html}
}

@inproceedings{minkov_contextual_2006,
	location = {New York, {NY}, {USA}},
	title = {Contextual Search and Name Disambiguation in Email Using Graphs},
	isbn = {1-59593-369-7},
	url = {http://doi.acm.org/10.1145/1148170.1148179},
	doi = {10.1145/1148170.1148179},
	series = {{SIGIR} '06},
	abstract = {Similarity measures for text have historically been an important tool for solving information retrieval problems. In many interesting settings, however, documents are often closely connected to other documents, as well as other non-textual objects: for instance, email messages are connected to other messages via header information. In this paper we consider extended similarity metrics for documents and other objects embedded in graphs, facilitated via a lazy graph walk. We provide a detailed instantiation of this framework for email data, where content, social networks and a timeline are integrated in a structural graph. The suggested framework is evaluated for two email-related problems: disambiguating names in email documents, and threading. We show that reranking schemes based on the graph-walk similarity measures often outperform baseline methods, and that further improvements can be obtained by use of appropriate learning methods.},
	pages = {27--34},
	booktitle = {Proceedings of the 29th Annual International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval},
	publisher = {{ACM}},
	author = {Minkov, Einat and Cohen, William W. and Ng, Andrew Y.},
	urldate = {2014-06-19},
	date = {2006},
	keywords = {email, graph-based retrieval, name disambiguation, threading},
	file = {ACM Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/8JUCSFSS/Minkov et al. - 2006 - Contextual Search and Name Disambiguation in Email.pdf:application/pdf}
}

@unpublished{igor_anishchenko_thrift_????,
	title = {Thrift vs Protocol Buffers vs Avro - Biased Comparison},
	rights = {© All Rights Reserved},
	url = {http://www.slideshare.net/IgorAnishchenko/pb-vs-thrift-vs-avro},
	abstract = {Igor Anishchenko
Odessa Java {TechTalks}
Lohika - May, 2012

Let's take a step back and compare data serialization formats, of which there are plenty. What are the key differences between Apache Thrift, Google Protocol Buffers and Apache Avro. Which is "The Best"? Truth of the matter is, they are all very good and each has its own strong points. Hence, the answer is as much of a personal choice, as well as understanding of the historical context for each, and correctly identifying your own, individual requirements.},
	type = {Technology},
	howpublished = {Technology},
	author = {Igor Anishchenko},
	urldate = {2014-03-11}
}

@inreference{_inclusionexclusion_2014,
	title = {Inclusion–exclusion principle},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {http://en.wikipedia.org/w/index.php?title=Inclusion%E2%80%93exclusion_principle&oldid=594524993},
	abstract = {In combinatorics (combinatorial mathematics), the inclusion–exclusion principle is a counting technique which generalizes the familiar method of obtaining the number of elements in the union of two finite sets; symbolically expressed as},
	booktitle = {Wikipedia, the free encyclopedia},
	urldate = {2014-03-15},
	date = {2014-03-15},
	langid = {english},
	note = {Page Version {ID}: 594524993},
	keywords = {problem 39},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/C5NVB9M3/index.html:text/html}
}

@inreference{_naive_2014,
	title = {Naive Bayes classifier},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {http://en.wikipedia.org/w/index.php?title=Naive_Bayes_classifier&oldid=594585795},
	booktitle = {Wikipedia, the free encyclopedia},
	urldate = {2014-02-10},
	date = {2014-02-08},
	langid = {english},
	note = {Page Version {ID}: 594585795},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/HICWVBNK/index.html:text/html}
}

@article{kumar_model_2011,
	title = {{MODEL} {BASED} {TESTING} {CONSIDERING} {STEPS}, {LEVELS}, {TOOLS} \& {STANDARDS} {OF} {SOFTWARE} {QUALITY}},
	volume = {2},
	issn = {2229-371X},
	url = {http://www.jgrcs.info/index.php/jgrcs/article/view/92},
	abstract = {{MODEL} {BASED} {TESTING} {CONSIDERING} {STEPS}, {LEVELS}, {TOOLS} \& {STANDARDS} {OF} {SOFTWARE} {QUALITY}},
	pages = {91--95},
	number = {5},
	journaltitle = {Journal of Global Research in Computer Science},
	author = {Kumar, Nirmal},
	urldate = {2014-10-01},
	date = {2011-06-06},
	note = {This paper gives an overview to the topic of model-based testing. The model based testing process is described, and the steps available at each stage are considered. The different types of tool necessary to support the process are explained and example tools listed along with the standards they support. The position for standards in model-based testing is examined, and the new skills required by tester are discussed. Throughout research on model-based testing in the last 5-10 years has verified the probability of this approach. It has been shown that it can be cost-effective, and has developed a variety of test generation strategies and model coverage criteria. Some commercial tools have started to emerge, from the {USA} (T-Vec, Reactive Systems, I-logix), and also from Europe (Conformiq, Leirios Technologies, Telelogic), as well as a wide variety of academic and research tools [{BFS}05]. The discussion in this paper is limited to functional testing, because model-based testing is less mature in other areas. Finally, means of determining the appropriateness of projects for model-based testing are considered. In this paper following factors are analyzed: Model Based Testing, Steps, Levels, Methods \& tools that affect {MBT}.},
	file = {Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/QBEZBIA6/Kumar - 2011 - MODEL BASED TESTING CONSIDERING STEPS, LEVELS, TOO.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/P8GDN24C/92.html:text/html}
}

@online{_gcov_????,
    author={{GNU Software Project}},
    date={2014},
	title = {Gcov - Using the {GNU} Compiler Collection ({GCC})},
	url = {https://gcc.gnu.org/onlinedocs/gcc/Gcov.html},
	urldate = {2014-10-19},
	file = {Gcov - Using the GNU Compiler Collection (GCC):/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/37HG3ZDZ/Gcov.html:text/html}
}

@online{_bullseye_????,
    author={{Bullseye Testing}},
	title = {Bullseye Testing Technology},
    date={2014},
	url = {http://www.bullseye.com/},
	urldate = {2014-10-19},
	file = {Bullseye Testing Technology:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/KE7P38Q5/www.bullseye.com.html:text/html}
}

@online{_cyber_????,
	title = {The Cyber Security and Information Systems Information Analysis Center ({CSIAC})},
	url = {https://www.csiac.org/},
	abstract = {Cyber Security and Information Systems Information Analysis Center ({CSIAC})
		is a United States Department of Defense Information Analysis Center sponsored by the Defense Technical Information Center ({DTIC}).},
	titleaddon = {{CSIAC}},
	urldate = {2014-08-24},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/X6PPDATB/software-acquisition-gold-practice-model-based-testing.html:text/html}
}

@article{cobb_leakage_2013,
	title = {Leakage Mapping: A Systematic Methodology for Assessing the Side-Channel Information Leakage of Cryptographic Implementations},
	volume = {16},
	issn = {1094-9224},
	url = {http://doi.acm.org/10.1145/2487222.2487224},
	doi = {10.1145/2487222.2487224},
	shorttitle = {Leakage Mapping},
	abstract = {We propose a generalized framework to evaluate the side-channel information leakage of symmetric block ciphers. The leakage mapping methodology enables the systematic and efficient identification and mitigation of problematic information leakages by exhaustively considering relevant leakage models. The evaluation procedure bounds the anticipated resistance of an implementation to the general class of univariate differential side-channel analysis techniques. Typical applications are demonstrated using the well-known Hamming weight and Hamming distance leakage models, with recommendations for the incorporation of more accurate models. The evaluation results are empirically validated against correlation-based differential side-channel analysis attacks on two typical unprotected implementations of the Advanced Encryption Standard.},
	pages = {2:1--2:29},
	number = {1},
	journaltitle = {{ACM} Trans. Inf. Syst. Secur.},
	author = {Cobb, William E. and Baldwin, Rusty O. and Laspe, Eric D.},
	urldate = {2014-05-13},
	date = {2013-06},
	keywords = {advanced encryption standard, block cipher, cryptanalysis, Cryptography, Differential power analysis, Encryption, hardware security, information leakage, physical-layer security, side-channel analysis},
	file = {a2-cobb.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/JKK8RVAE/a2-cobb.pdf:application/pdf}
}

@online{_cppcheck_????,
    author={Daniel Marj\"amaki},
	title = {Cppcheck - A tool for static C/C++ code analysis},
    date={2014},
	url = {http://cppcheck.sourceforge.net/},
	urldate = {2014-10-19},
	file = {Cppcheck - A tool for static C/C++ code analysis:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/3WKMMQDU/cppcheck.sourceforge.net.html:text/html}
}

@book{oreilly_programming_2008,
	edition = {1},
	title = {Programming Collective Intelligence},
	publisher = {O'Reilly},
	author = {Segaran, Toby},
	editor = {O'Reilly},
	date = {2008},
	file = {Programming Collective Intelligence - ASU Libraries:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/UZR6CF2H/results.html:text/html}
}

@article{gelman_how_2010,
	title = {"How many zombies do you know?" Using indirect survey methods to measure alien attacks and outbreaks of the undead},
	url = {http://arxiv.org/abs/1003.6087},
	shorttitle = {"How many zombies do you know?},
	abstract = {The zombie menace has so far been studied only qualitatively or through the use of mathematical models without empirical content. We propose to use a new tool in survey research to allow zombies to be studied indirectly without risk to the interviewers.},
	journaltitle = {{arXiv}:1003.6087 [physics]},
	author = {Gelman, Andrew},
	urldate = {2014-07-18},
	date = {2010-03-31},
	eprinttype = {arxiv},
	eprint = {1003.6087},
	keywords = {Physics - Data Analysis, Statistics and Probability, Physics - Physics and Society},
	file = {arXiv\:1003.6087 PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/T89N5ZU6/Gelman - 2010 - How many zombies do you know Using indirect sur.pdf:application/pdf;arXiv.org Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/BIWATK32/1003.html:text/html}
}

@article{lei_ipog/ipog-d:_2008,
	title = {{IPOG}/{IPOG}-D: efficient test generation for multi-way combinatorial testing},
	volume = {18},
	issn = {09600833, 10991689},
	url = {http://csrc.nist.gov/groups/SNS/acts/index.html},
	doi = {10.1002/stvr.381},
	shorttitle = {{IPOG}/{IPOG}-D},
	pages = {125--148},
	number = {3},
	journaltitle = {Software Testing, Verification and Reliability},
	author = {Lei, Yu and Kacker, Raghu and Kuhn, D. Richard and Okun, Vadim and Lawrence, James},
	urldate = {2014-09-14},
	date = {2008-09},
	langid = {english},
	file = {Combinatorial Testing, Pairwise Testing, and Design of Experiments for Software:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/6WKG64ZV/index.html:text/html}
}

@video{newcircle_training_learning_2012,
	title = {Learning Functional Programming without Growing a Neckbeard},
	url = {http://www.youtube.com/watch?v=OOvL6QAxRK4&feature=youtube_gdata_player},
	abstract = {With the help of Pam Grier, Kelsey Innis, software engineer at {StackMob}, hopes to take functional programming away from the of holier-than-thou neckbeards and bring it to the mere mortals.

In this {SF} Scala and Women Who Code collaboration, Innis explains How Scala can be used to get past functional programming's math-heavy, incomprehensible reputation to write code that is powerful, beautiful, and tough (to mess with).

** More videos on Scala Development at http://marakana.com/s/},
	editora = {{NewCircle Training}},
	editoratype = {collaborator},
	urldate = {2014-03-11},
	date = {2012-12-18}
}

@online{_list_????,
	title = {A list of open source C++ libraries - cppreference.com},
	url = {http://en.cppreference.com/w/cpp/links/libs},
	urldate = {2014-03-11},
	file = {A list of open source C++ libraries - cppreference.com:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/S34V387B/libs.html:text/html}
}

@article{riungu-kalliosaari_testing_2012,
	title = {Testing in the Cloud: Exploring the Practice},
	volume = {29},
	issn = {0740-7459},
	doi = {10.1109/MS.2011.132},
	shorttitle = {Testing in the Cloud},
	abstract = {As applications and services migrate to the cloud, testing will follow the same trend. Therefore, organizations must understand the dynamics of cloud-based testing. This article presents interviews with eight organizations that use cloud computing. The results suggest that cloud computing can make testing faster and enhance the delivery of testing services. Cloud computing also highlights important aspects of testing that require attention, such as integration and interoperability. This article includes a Web extra that provides additional references for further study.},
	pages = {46--51},
	number = {2},
	journaltitle = {{IEEE} Software},
	author = {Riungu-Kalliosaari, L. and Taipale, O. and Smolander, K.},
	date = {2012-03},
	keywords = {cloud-based testing, cloud computing, interoperability, program testing, Servers, Testing, testing in the cloud, testing services, Web and internet services, Web extra},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/Q3ZKWGF4/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/ZW5S8WGX/Riungu-Kalliosaari et al. - 2012 - Testing in the Cloud Exploring the Practice.pdf:application/pdf}
}

@incollection{blei_latent_2003,
	title = {Latent Dirichlet Allocation},
	series = {Research},
	abstract = {We describe
latent Dirichlet allocation
({LDA}), a generative probabilistic model for collections of
discrete data such as text corpora. {LDA} is a three-level hierarchical Bayesian model, in which each
item of a collection is modeled as a finite mixture over an underlying set of topics. Each topic is, in
turn, modeled as an infinite mixture over an underlying set of topic probabilities. In the context of
text modeling, the topic probabilities provide an explicit representation of a document. We present
efficient approximate inference techniques based on variational methods and an {EM} algorithm for
empirical Bayes parameter estimation. We report results in document modeling, text classification,
and collaborative filtering, comparing to a mixture of unigrams model and the probabilistic {LSI}
model},
	number = {3},
	booktitle = {Journal of Machine Learning},
	publisher = {{IEEE}},
	author = {Blei, David M and Ng, Andrew Y. and Jordan, Michael I},
	editor = {Lafferty, John},
	urldate = {2014-09-07},
	date = {2003-01},
	file = {blei03a.dvi - BleiNgJordan2003.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/K4JNZ63H/BleiNgJordan2003.pdf:application/pdf}
}

@article{sculthorpe_work_2014,
	title = {Work it, wrap it, fix it, fold it},
	volume = {24},
	doi = {10.1017/S0956796814000045},
	abstract = {The worker/wrapper transformation is a general-purpose technique for refactoring recursive programs to improve their performance. The two previous approaches to formalising the technique were based upon different recursion operators and different correctness conditions. In this paper we show how these two approaches can be generalised in a uniform manner by combining their correctness conditions, extend the theory with new conditions that are both necessary and sufficient to ensure the correctness of the worker/wrapper technique, and explore the benefits that result. All the proofs have been mechanically verified using the Agda system.},
	pages = {113--127},
	number = {1},
	journaltitle = {Journal of Functional Programming},
	author = {Sculthorpe, Neil and Hutton, Graham},
	date = {2014},
	file = {Cambridge Journals PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/BWDWPQST/Sculthorpe and Hutton - 2014 - Work it, wrap it, fix it, fold it.pdf:application/pdf;Cambridge Journals Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/TWFQBF9R/displayAbstract.html:text/html}
}

@inproceedings{xia_feature_2011,
	title = {Feature expansion for Microblogging text based on Latent Dirichlet Allocation with User Feature},
	volume = {1},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6030192},
	pages = {228--232},
	booktitle = {Information Technology and Artificial Intelligence Conference ({ITAIC}), 2011 6th {IEEE} Joint International},
	publisher = {{IEEE}},
	author = {Xia, Wei and He, Yanxiang and Tian, Ye and Chen, Qiang and Lin, Lu},
	urldate = {2014-02-05},
	date = {2011},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/BEWER364/login.html:text/html}
}

@online{_generic<programming>:_????,
	title = {Generic{\textless}Programming{\textgreater}: Change the Way You Write Exception-Safe Code - Forever},
	url = {http://www.drdobbs.com/cpp/generic-change-the-way-you-write-excepti/184403758},
	shorttitle = {Generic{\textless}Programming{\textgreater}},
	abstract = {Let's face it: Writing exception-safe code is hard. But it just got a lot easier with this amazing template.},
	titleaddon = {Dr. Dobb's},
	urldate = {2014-03-11}
}

@online{nedelcu_how_2012,
	title = {How To Build a Naive Bayes Classifier},
	url = {https://www.bionicspirit.com/blog/2012/02/09/howto-build-naive-bayes-classifier.html},
	titleaddon = {Bionicspirit},
	type = {Blog},
	author = {Nedelcu, Alexandru},
	urldate = {2014-02-10},
	date = {2012-02-09},
	file = {How To Build a Naive Bayes Classifier:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/FSE5PATD/howto-build-naive-bayes-classifier.html:text/html}
}

@inproceedings{sigholm_best-effort_2012,
	title = {Best-effort Data Leakage Prevention in inter-organizational tactical {MANETs}},
	doi = {10.1109/MILCOM.2012.6415755},
	abstract = {Reconfigurable Radio Systems ({RRS}), based on Software Defined Radio ({SDR}) and Mobile Ad-hoc Network ({MANET}) technologies, offer considerable advantages for military operations, such as increased network survivability and interoperability. The {RRS}-based Common Tactical Radio System ({GTRS}), currently in development by the Swedish Armed Forces, is designed for use in diverse geographical settings and for purposes varying from international combat missions to national contingency operations. However, protecting these networks from attacks and safeguarding the carried information against leaks is an ongoing research challenge, especially in combined scenarios where tactical data may flow across organizational boundaries. This paper presents a best-effort approach to Data Leakage Prevention ({DLP}) for inter-organizational {RRS}-based networks. The proposed architecture makes use of data mining techniques and an efficient n-dimensional clustering algorithm which has previously been successfully used for real-time anomaly detection in critical infrastructure protection. The {DLP} architecture is developed as an extension to the {GTRS} system, modeled and simulated in {OPNET}(tm) Modeler. Our results show that common data leaks can be efficiently identified by the proposed scheme, while keeping the important false positive rate at a very low level.},
	eventtitle = {{MILITARY} {COMMUNICATIONS} {CONFERENCE}, 2012 - {MILCOM} 2012},
	pages = {1--7},
	booktitle = {{MILITARY} {COMMUNICATIONS} {CONFERENCE}, 2012 - {MILCOM} 2012},
	author = {Sigholm, J. and Raciti, M.},
	date = {2012-10},
	keywords = {ad hoc networks, computer architecture, critical infrastructure protection, data leakage prevention, data mining, Data models, {DLP}, {GTRS}, Information security, international combat missions, interoperability, inter-organizational {RRS}-based networks, inter-organizational tactical {MANET}, Logic gates, {MANET} technologies, military communication, military communications, military operations, mobile ad-hoc network, Mobile ad hoc networks, Mobile ad-hoc networks, mobile communication, Mobile Computing, M\&S, national contingency operations, n-dimensional clustering algorithm, network survivability, open systems, {OPNET}, {OPNET} Modeler, pattern clustering, real-time anomaly detection, reconfigurable radio systems, {RRS}-based common tactical radio system, {SDR}, Security, security of data, Software Defined Radio, software radio, Swedish Armed Forces, tactical data},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/WIRKVZFA/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/G8J3HHJM/Sigholm and Raciti - 2012 - Best-effort Data Leakage Prevention in inter-organ.pdf:application/pdf}
}

@online{jhwilson_jhwilson/jhwhw.cls_????,
	title = {jhwilson/jhwhw.cls},
	url = {https://gist.github.com//jhwilson/1278588},
	abstract = {{JHW} document class for Homework assignments - Gist is a simple way to share snippets of text and code with others.},
	titleaddon = {{GitHub} Gists},
	author = {{jhwilson}},
	urldate = {2014-03-11},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/P2MFZDIR/1278588.html:text/html}
}

@online{_8_????,
	title = {8 Bootstrap Alternatives},
	url = {http://flippinawesome.org/2014/02/17/8-bootstrap-alternatives/},
	abstract = {Related},
	titleaddon = {Flippin' Awesome},
	urldate = {2014-06-20},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/VP9WBSV9/8-bootstrap-alternatives.html:text/html}
}

@misc{erwig_functional_????,
	title = {Functional Pearls: Probabilistic functional programming in Haskell},
	author = {Erwig, Martin and Kollmansberger, Steve},
	file = {S0956796805005721a.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/NHNDJCZN/S0956796805005721a.pdf:application/pdf}
}

@inproceedings{wang_trust2:_2005,
	title = {Trust2: developing trust in peer-to-peer environments},
	volume = {1},
	doi = {10.1109/SCC.2005.104},
	shorttitle = {Trust2},
	abstract = {In peer-to-peer (P2P) environments, a peer needs to interact with unknown peers for the services provided. This requires the trust evaluation prior to and posterior to interactions. This paper presents Trust2: a novel and dynamic peer trust evaluation model, which aims to measure the credibility of peers' recommendations, and thus to filter noise in responses and obtain more accurate and objective trust values. In our model, prior to any interaction, the trust value results from the evaluations given by other peers. Posterior to interactions, the trust values results from both other peers' evaluations and the requesting peer's experience. In the aggregation of trust evaluations, the weight to the requesting peer becomes higher and higher. Meanwhile, during this process, the credibility of each responding peer's recommendation can be measured round by round. This leads to the filtering of low credibility peers and the improvement of trust evaluations.},
	eventtitle = {2005 {IEEE} International Conference on Services Computing},
	pages = {24--31 vol.1},
	booktitle = {2005 {IEEE} International Conference on Services Computing},
	author = {Wang, Yan and Varadharajan, V.},
	date = {2005-07},
	keywords = {Authentication, Broadcasting, Feedback, Filtering, Filters, History, Noise measurement, Peer to peer computing, peer-to-peer computing, peer-to-peer environments, peer trust evaluation model, Security, security of data, Trust2, Voting},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/FCJXHJ6J/login.html:text/html}
}

@inproceedings{rowe_automated_2007,
	location = {New York, {NY}, {USA}},
	title = {Automated Social Hierarchy Detection Through Email Network Analysis},
	isbn = {978-1-59593-848-0},
	url = {http://doi.acm.org/10.1145/1348549.1348562},
	doi = {10.1145/1348549.1348562},
	series = {{WebKDD}/{SNA}-{KDD} '07},
	abstract = {This paper provides a novel algorithm for automatically extracting social hierarchy data from electronic communication behavior. The algorithm is based on data mining user behaviors to automatically analyze and catalog patterns of communications between entities in a email collection to extract social standing. The advantage to such automatic methods is that they extract relevancy between hierarchy levels and are dynamic over time. We illustrate the algorithms over real world data using the Enron corporation's email archive. The results show great promise when compared to the corporations work chart and judicial proceeding analyzing the major players.},
	pages = {109--117},
	booktitle = {Proceedings of the 9th {WebKDD} and 1st {SNA}-{KDD} 2007 Workshop on Web Mining and Social Network Analysis},
	publisher = {{ACM}},
	author = {Rowe, Ryan and Creamer, German and Hershkop, Shlomo and Stolfo, Salvatore J},
	urldate = {2014-06-19},
	date = {2007},
	keywords = {behavior profile, data, Enron, link mining, mining, social network},
	file = {ACM Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/CE2WMEDB/Rowe et al. - 2007 - Automated Social Hierarchy Detection Through Email.pdf:application/pdf}
}

@inproceedings{ciresan_multi-column_2012,
	title = {Multi-column deep neural networks for image classification},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6248110},
	pages = {3642--3649},
	booktitle = {Computer Vision and Pattern Recognition ({CVPR}), 2012 {IEEE} Conference on},
	publisher = {{IEEE}},
	author = {Ciresan, Dan and Meier, Ueli and Schmidhuber, Jürgen},
	urldate = {2014-09-08},
	date = {2012},
	file = {[PDF] from arxiv.org:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/QCIKCRHR/Ciresan et al. - 2012 - Multi-column deep neural networks for image classi.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/FZ39UV77/login.html:text/html}
}

@article{serizawa_topic_2012,
	title = {Topic Tracking Based on Identifying Proper Number of the Latent Topics in Documents.},
	volume = {16},
	url = {http://www.fujipress.jp/finder/xslt.php?mode=present&inputfile=JACII001600050007.xml},
	pages = {611--618},
	number = {5},
	journaltitle = {{JACIII}},
	author = {Serizawa, Midori and Kobayashi, Ichiro},
	urldate = {2014-02-05},
	date = {2012},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/V8T6QU4J/xslt.html:text/html}
}

@article{sperber_systematic_2014,
	title = {Systematic Program Design: From Clarity to Efficiency, by Yanhong Annie Liu, Cambridge University Press, 2013, {ISBN}: 978-1-107-03660-4.},
	volume = {24},
	doi = {10.1017/S0956796813000269},
	shorttitle = {Systematic Program Design},
	pages = {128--130},
	number = {1},
	journaltitle = {Journal of Functional Programming},
	author = {Sperber, Michael},
	date = {2014},
	file = {Cambridge Journals PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/BWTIF78R/Sperber - 2014 - Systematic Program Design From Clarity to Efficie.pdf:application/pdf;Cambridge Journals Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/7C6ZHQVN/displayAbstract.html:text/html}
}

@online{_practical_????,
	title = {Practical Cryptography},
	url = {http://practicalcryptography.com/cryptanalysis/stochastic-searching/cryptanalysis-simple-substitution-cipher/},
	urldate = {2014-03-11},
	file = {Practical Cryptography:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/3EMRMESR/cryptanalysis-simple-substitution-cipher.html:text/html;Practical Cryptography:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/742ZK9PC/cryptanalysis-simple-substitution-cipher.html:text/html;Practical Cryptography:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/AJNUEZP7/quadgrams.html:text/html}
}

@video{_wilson_2011,
	title = {Wilson Miner - When We Build},
	url = {http://vimeo.com/34017777},
	abstract = {We shape our tools and our tools shape us." As more of the tools we live with every day become digital instead of physical, our opportunity},
	urldate = {2014-02-27},
	date = {2011-12-21},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/PZRBX65D/34017777.html:text/html}
}

@inproceedings{kim_automated_2013,
	title = {Automated unit testing of large industrial embedded software using concolic testing},
	doi = {10.1109/ASE.2013.6693109},
	abstract = {Current testing practice in industry is often ineffective and slow to detect bugs, since most projects utilize manually generated test cases. Concolic testing alleviates this problem by automatically generating test cases that achieve high coverage. However, specialized execution platforms and resource constraints of embedded software hinder application of concolic testing to embedded software. To overcome these limitations, we have developed {CONcrete} and {symBOLic} ({CONBOL}) testing framework to unit test large size industrial embedded software automatically. To address the aforementioned limitations, {CONBOL} tests target units on a host {PC} platform by generating symbolic unit testing drivers/stubs automatically and applying heuristics to reduce false alarms caused by the imprecise drivers/stubs. We have applied {CONBOL} to four million lines long industrial embedded software and detected 24 new crash bugs. Furthermore, the development team of the target software adopted {CONBOL} to their development process to apply {CONBOL} to the revised target software regularly.},
	eventtitle = {2013 {IEEE}/{ACM} 28th International Conference on Automated Software Engineering ({ASE})},
	pages = {519--528},
	booktitle = {2013 {IEEE}/{ACM} 28th International Conference on Automated Software Engineering ({ASE})},
	author = {Kim, Yunho and Kim, Youil and Kim, Taeksu and Lee, Gunwoo and Jang, Yoonkyu and Kim, Moonzoo},
	date = {2013-11},
	keywords = {Arrays, automated unit testing, Computer bugs, {CONBOL} testing framework, concolic testing, concrete and symbolic testing framework, crash bugs detection, Embedded software, embedded software resource constraints, embedded systems, false alarm reduction, Hardware, heuristics, host {PC} platform, imprecise driver-stubs, large size industrial embedded software, program testing, specialized execution platforms, symbolic unit testing drivers, Testing},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/5BVBX5A7/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/4NJJT42Q/Kim et al. - 2013 - Automated unit testing of large industrial embedde.pdf:application/pdf}
}

@article{gill_worker/wrapper_2009,
	title = {The worker/wrapper transformation},
	volume = {19},
	doi = {10.1017/S0956796809007175},
	abstract = {The worker/wrapper transformation is a technique for changing the type of a computation, usually with the aim of improving its performance. It has been used by compiler writers for many years, but the technique is little known in the wider functional programming community, and has never been described precisely. In this article we explain, formalise and explore the generality of the worker/wrapper transformation. We also provide a systematic recipe for its use as an equational reasoning technique for improving the performance of programs, and illustrate the power of this recipe using a range of examples.},
	pages = {227--251},
	number = {2},
	journaltitle = {Journal of Functional Programming},
	author = {Gill, Andy and Hutton, Graham},
	date = {2009},
	file = {Cambridge Journals PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/QJQ6UJBX/Gill and Hutton - 2009 - The workerwrapper transformation.pdf:application/pdf;Cambridge Journals Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/72P3EBAC/displayAbstract.html:text/html}
}

@incollection{newman_analyzing_2006,
	title = {Analyzing Entities and Topics in News Articles Using Statistical Topic Models},
	rights = {(c) 2006 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-34478-0, 978-3-540-34479-7},
	url = {http://link.springer.com.ezproxy1.lib.asu.edu/chapter/10.1007/11760146_9},
	series = {Lecture Notes in Computer Science},
	abstract = {Statistical language models can learn relationships between topics discussed in a document collection and persons, organizations and places mentioned in each document. We present a novel combination of statistical topic models and named-entity recognizers to jointly analyze entities mentioned (persons, organizations and places) and topics discussed in a collection of 330,000 New York Times news articles. We demonstrate an analytic framework which automatically extracts from a large collection: topics; topic trends; and topics that relate entities.},
	pages = {93--104},
	number = {3975},
	booktitle = {Intelligence and Security Informatics},
	publisher = {Springer Berlin Heidelberg},
	author = {Newman, David and Chemudugunta, Chaitanya and Smyth, Padhraic and Steyvers, Mark},
	editor = {Mehrotra, Sharad and Zeng, Daniel D. and Chen, Hsinchun and Thuraisingham, Bhavani and Wang, Fei-Yue},
	urldate = {2014-06-19},
	date = {2006-01-01},
	keywords = {Computer Communication Networks, Computers and Society, Information Storage and Retrieval, Information Systems Applications (incl.Internet), Legal Aspects of Computing, Management of Computing and Information Systems},
	file = {Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/GPI43VJX/Newman et al. - 2006 - Analyzing Entities and Topics in News Articles Usi.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/PGEZHW9H/11760146_9.html:text/html}
}

@incollection{wang_attack_2008,
	title = {An Attack Graph-Based Probabilistic Security Metric},
	rights = {(c) 2008 Springer-Verlag Berlin Heidelberg},
	isbn = {978-3-540-70566-6, 978-3-540-70567-3},
	url = {http://link.springer.com.ezproxy1.lib.asu.edu/chapter/10.1007/978-3-540-70567-3_22},
	series = {Lecture Notes in Computer Science},
	abstract = {To protect critical resources in today's networked environments, it is desirable to quantify the likelihood of potential multi-step attacks that combine multiple vulnerabilities. This now becomes feasible due to a model of causal relationships between vulnerabilities, namely, attack graph. This paper proposes an attack graph-based probabilistic metric for network security and studies its efficient computation. We first define the basic metric and provide an intuitive and meaningful interpretation to the metric. We then study the definition in more complex attack graphs with cycles and extend the definition accordingly. We show that computing the metric directly from its definition is not efficient in many cases and propose heuristics to improve the efficiency of such computation.},
	pages = {283--296},
	number = {5094},
	booktitle = {Data and Applications Security {XXII}},
	publisher = {Springer Berlin Heidelberg},
	author = {Wang, Lingyu and Islam, Tania and Long, Tao and Singhal, Anoop and Jajodia, Sushil},
	editor = {Atluri, Vijay},
	urldate = {2014-05-18},
	date = {2008-01-01},
	keywords = {Algorithm Analysis and Problem Complexity, Computer Communication Networks, Data Encryption, Management of Computing and Information Systems, Special Purpose and Application-Based Systems, Systems and Data Security},
	file = {Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/A337JFNW/Wang et al. - 2008 - An Attack Graph-Based Probabilistic Security Metri.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/WB9D3NTJ/Wang et al. - 2008 - An Attack Graph-Based Probabilistic Security Metri.html:text/html}
}

@online{weingart_myth_2012,
	title = {The Myth of Text Analytics and Unobtrusive Measurement},
	url = {http://www.scottbot.net/HIAL/?p=16713},
	titleaddon = {the scottbot irregular},
	author = {Weingart, Scott},
	urldate = {2014-07-18},
	date = {2012-05-06},
	keywords = {method},
	file = {The Myth of Text Analytics and Unobtrusive Measurement – the scottbot irregular:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/ZD4GVFA2/HIAL.html:text/html}
}

@online{_dynamic_????,
	title = {Dynamic Programming {\textbar} Set 32 (Word Break Problem)},
	url = {http://www.geeksforgeeks.org/dynamic-programming-set-32-word-break-problem/},
	abstract = {Given an input string and a dictionary of words, find out if the input string can be segmented into a space-separated sequence of dictionary words. See following examples for more details. This is a famous Google interview question, also being asked by many other companies now a days.},
	titleaddon = {{GeeksforGeeks}},
	urldate = {2014-02-05},
	keywords = {Dynamic Programming},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/QN2RA5A7/dynamic-programming-set-32-word-break-problem.html:text/html}
}

@online{_pairwise_????,
	title = {Pairwise Testing - Available Tools},
	url = {http://www.pairwise.org/tools.asp},
	urldate = {2014-09-21},
	file = {Pairwise Testing - Available Tools:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/9ZSIFM7P/tools.html:text/html}
}

@online{_stanford_????,
	title = {Stanford Large Network Dataset Collection},
	url = {http://snap.stanford.edu/data/#email},
	urldate = {2014-01-24},
	keywords = {data set},
	file = {Stanford Large Network Dataset Collection:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/DKQPI7FP/data.html:text/html}
}

@online{_why_????,
	title = {Why Haskell is beyond ready for Prime Time},
	url = {http://intoverflow.wordpress.com/2009/01/13/why-haskell-is-beyond-ready-for-prime-time/},
	abstract = {I've read a few comments about why Haskell is awesome. I even wrote an ironic blog post about it. Today I'm going to explain why I use Haskell for doing real work, entirely in terms of the tools Ha...},
	titleaddon = {Integer Overflow},
	urldate = {2014-03-11},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/U4T67UEW/why-haskell-is-beyond-ready-for-prime-time.html:text/html}
}

@misc{_haskell_????,
	title = {Haskell in the Real World},
	url = {http://www.starling-software.com/misc/icfp-2009-cjs.pdf},
	abstract = {Writing a commercial application in a lazy functional language},
	file = {icfp-2009-cjs.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/2SFZHUGW/icfp-2009-cjs.pdf:application/pdf}
}

@incollection{merkl_document_2000,
	title = {Document classification with unsupervised artificial neural networks},
	url = {http://link.springer.com/chapter/10.1007/978-3-7908-1849-9_5},
	pages = {102--121},
	booktitle = {Soft computing in information retrieval},
	publisher = {Springer},
	author = {Merkl, Dieter and Rauber, Andreas},
	urldate = {2014-09-08},
	date = {2000},
	file = {[PDF] from aminer.org:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/9NRS3RTD/Merkl and Rauber - 2000 - Document classification with unsupervised artifici.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/RR3UCZVV/978-3-7908-1849-9_5.html:text/html}
}

@article{bratton_enron_2001,
	title = {Enron and the dark side of shareholder value},
	volume = {76},
	url = {http://heinonlinebackup.com/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/tulr76&section=51},
	pages = {1275},
	journaltitle = {Tul. L. Rev.},
	author = {Bratton, William W.},
	urldate = {2014-06-19},
	date = {2001},
	file = {[PDF] from upenn.edu:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/NRVF8VH4/Bratton - 2001 - Enron and the dark side of shareholder value.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/WQAJ335F/get_pdf.html:text/html}
}

@inproceedings{naslavsky_model-based_2009,
	title = {A model-based regression test selection technique},
	doi = {10.1109/ICSM.2009.5306338},
	abstract = {Throughout their life cycle, software artifacts are modified, and selective regression testing is used to identify the negative impact of modifications. Code-based regression test selection retests test cases sub-set that traverse code modifications. It uses recovered relationships between code parts and test cases that traverse them to locate test cases for retest when code is modified. Broad adoption of model-centric development has created opportunities for software testing. It enabled driving testing processes at higher abstraction levels and demonstrating code to model compliance by means of Model-Based Testing ({MBT}). Models also evolve, so an important activity of {MBT} is selective regression testing. It selects test cases for retest based on model modification, so it relies on relationships between model elements and test cases that traverse those elements to locate test cases for retest. We contribute an approach and prototype that during test case generation creates fine-grained traceability relationships between model elements and test cases, which are used to support model-based regression test selection.},
	eventtitle = {{IEEE} International Conference on Software Maintenance, 2009. {ICSM} 2009},
	pages = {515--518},
	booktitle = {{IEEE} International Conference on Software Maintenance, 2009. {ICSM} 2009},
	author = {Naslavsky, L. and Ziv, H. and Richardson, D.J.},
	date = {2009-09},
	keywords = {Analytical models, Automatic testing, code-based regression test selection technique, Drives, Information analysis, Life testing, model-based regression test selection, model-based testing, program testing, Prototypes, regression analysis, selective regression testing, software artifacts, Software quality, Software systems, software testing, test case generation, Unified modeling language},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/ZZCZW7QI/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/EJNKSPIB/Naslavsky et al. - 2009 - A model-based regression test selection technique.pdf:application/pdf}
}

@software{schoppmann_madlib:_2014,
	title = {{MADlib}:  Big Data Machine Learning in {SQL} for Data Scientists},
	url = {http://madlib.net/product/},
	shorttitle = {{MADlib}},
	abstract = {In a world of ever increasing data sizes many existing analytics solutions are not up to the task. The {MADlib} project seeks to address this need by creating a framework built to take advantage of modern computing capabilities to provide robust solutions that scale with the needs of the business.

Our approach is to leverage the efforts of commercial practice, academic research, and open-source development to build a product that addresses the needs of the analytic challenges within modern business.},
	version = {1.6},
	publisher = {Pivotal Software},
	author = {Schoppmann, Florian},
	date = {2014-07-03},
	file = {MADlib Design Document - design.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/37MW9WBF/design.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/Q2KNZ68I/madlib.net.html:text/html}
}

@book{oreilly_mining_2008,
	edition = {1},
	title = {Mining the Social Web},
	publisher = {O.Reilly},
	author = {Russell, Matthew A.},
	editor = {O'Reilly},
	date = {2008}
}

@online{_about_????,
	title = {About Docker -},
	url = {http://www.docker.io/learn_more/},
	urldate = {2014-02-08},
	file = {About Docker -:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/9RTGSPPD/learn_more.html:text/html}
}

@article{oneill_genuine_2009,
	title = {The Genuine Sieve of Eratosthenes},
	volume = {19},
	doi = {10.1017/S0956796808007004},
	abstract = {A much beloved and widely used example showing the elegance and simplicity of lazy functional programming represents itself as “The Sieve of Eratosthenes.” This paper shows that this example is not the sieve and presents an implementation that actually is.},
	pages = {95--106},
	number = {1},
	journaltitle = {Journal of Functional Programming},
	author = {O'neill, Melissa E.},
	date = {2009},
	file = {Cambridge Journals Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/J4VM38XI/displayAbstract.html:text/html}
}

@online{cloudchair_jake_????,
	title = {Jake Cloud Chair Custom Tones},
	url = {http://line6.com/customtone/profile/cloudchair/1/},
	author = {Cloudchair, Jake},
	urldate = {2014-02-05},
	file = {:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/ICXM5A37/1.html:text/html}
}

@online{_what_????,
	title = {What optimizations can {GHC} be expected to perform reliably?},
	url = {http://stackoverflow.com/questions/12653787/what-optimizations-can-ghc-be-expected-to-perform-reliably},
	abstract = {{GHC} has a lot of optimizations that it can perform, but I don't know what they all are, nor how likely they are to be performed and under what circumstances.

My question is: what transformations c...},
	urldate = {2014-03-11},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/IMB8NIUG/what-optimizations-can-ghc-be-expected-to-perform-reliably.html:text/html}
}

@online{_open-source_????,
	title = {Open-source readilibity metrics},
	url = {http://www.readability.info/info.shtml},
	urldate = {2014-03-11},
	file = {:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/MSKNXJP6/info.html:text/html}
}

@online{_operator_????,
	title = {Operator overloading},
	url = {http://stackoverflow.com/questions/4421706/operator-overloading},
	abstract = {What are the basic rules and idioms for operator overloading in C++?

Note: The answers were given in a specific order, but since many users sort answers according to votes, rather than the time they},
	urldate = {2014-03-11},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/NM4VQFDA/operator-overloading.html:text/html}
}

@online{_blei03a.dvi_????,
	title = {blei03a.dvi - {BleiNgJordan}2003.pdf},
	url = {http://www.cs.princeton.edu/~blei/papers/BleiNgJordan2003.pdf},
	urldate = {2014-09-08}
}

@online{_201401-bartholomew.pdf_????,
	title = {201401-Bartholomew.pdf},
	url = {http://www.crosstalkonline.org/storage/issue-archives/2014/201401/201401-Bartholomew.pdf},
	urldate = {2014-10-01},
	file = {201401-Bartholomew.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/I7ICBHBH/201401-Bartholomew.pdf:application/pdf}
}

@article{schrijvers_monadic_2009,
	title = {Monadic constraint programming},
	volume = {19},
	doi = {10.1017/S0956796809990086},
	abstract = {A constraint programming system combines two essential components: a constraint solver and a search engine. The constraint solver reasons about satisfiability of conjunctions of constraints, and the search engine controls the search for solutions by iteratively exploring a disjunctive search tree defined by the constraint program. In this paper we give a monadic definition of constraint programming in which the solver is defined as a monad threaded through the monadic search tree. We are then able to define search and search strategies as first-class objects that can themselves be built or extended by composable search transformers. Search transformers give a powerful and unifying approach to viewing search in constraint programming, and the resulting constraint programming system is first class and extremely flexible.},
	pages = {663--697},
	number = {6},
	journaltitle = {Journal of Functional Programming},
	author = {Schrijvers, Tom and Stuckey, Peter and Wadler, Philip},
	date = {2009},
	file = {Cambridge Journals PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/C9IK5UA3/Schrijvers et al. - 2009 - Monadic constraint programming.pdf:application/pdf;Cambridge Journals Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/26SKZ4EP/displayAbstract.html:text/html}
}

@inreference{_cosine_2014,
	title = {Cosine similarity},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {http://en.wikipedia.org/w/index.php?title=Cosine_similarity&oldid=604135823},
	abstract = {Cosine similarity is a measure of similarity between two vectors of an inner product space that measures the cosine of the angle between them. The cosine of 0° is 1, and it is less than 1 for any other angle. It is thus a judgement of orientation and not magnitude: two vectors with the same orientation have a Cosine similarity of 1, two vectors at 90° have a similarity of 0, and two vectors diametrically opposed have a similarity of -1, independent of their magnitude. Cosine similarity is particularly used in positive space, where the outcome is neatly bounded in [0,1].},
	booktitle = {Wikipedia, the free encyclopedia},
	urldate = {2014-10-14},
	date = {2014-10-13},
	langid = {english},
	note = {Page Version {ID}: 604135823},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/3FFX8CG7/index.html:text/html}
}

@online{_messaging_????,
	title = {Messaging Architecture: Using {RabbitMQ} at the World’s 8th Largest Retailer {\textbar} {VMware} {vFabric} Blog - {VMware} Blogs},
	url = {http://blogs.vmware.com/vfabric/2013/01/messaging-architecture-using-rabbitmq-at-the-worlds-8th-largest-retailer.html},
	shorttitle = {Messaging Architecture},
	urldate = {2014-10-14},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/SF225NM9/messaging-architecture-using-rabbitmq-at-the-worlds-8th-largest-retailer.html:text/html}
}

@online{_why_????-1,
	title = {Why I Dislike C++ For Large Projects},
	url = {http://www.mistybeach.com/articles/WhyIDontLikeCPlusPlusForLargeProjects.html},
	urldate = {2014-02-05},
	file = {Why I Dislike C++ For Large Projects:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/59GAKHQH/WhyIDontLikeCPlusPlusForLargeProjects.html:text/html}
}

@inproceedings{klimt_introducing_2004,
	title = {Introducing the Enron Corpus.},
	url = {http://bklimt.com/papers/2004_klimt_ceas.pdf},
	booktitle = {{CEAS}},
	author = {Klimt, Bryan and Yang, Yiming},
	urldate = {2014-06-19},
	date = {2004},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/NV6XAKBR/2004_klimt_ceas.pdf:application/pdf}
}

@video{lucenesolrrevolution_beyond_2013,
	title = {Beyond {TF}-{IDF}: Why, What and How},
	url = {http://www.youtube.com/watch?v=C25txE_dq90&feature=youtube_gdata_player},
	shorttitle = {Beyond {TF}-{IDF}},
	abstract = {Presented by Stephen Murtagh, Etsy.com, Inc.

{TF}-{IDF} (term frequency, inverse document frequency) is a standard method of weighting query terms for scoring documents, and is the method that is used by default in Solr/Lucene. Unfortunately, {TF}-{IDF} is really only a measure of rarity, not quality or usefulness. This means it would give more weight to a useless, rare term, such as a misspelling, than to a more useful, but more common, term.

In this presentation, we will discuss our experiences replacing Lucene's {TF}-{IDF} based scoring function with a more useful one using information gain, a standard machine-learning measure that combines frequency and specificity. Information gain is much more expensive to compute, however, so this requires periodically computing the term weights outside of Solr/Lucene and making the results accessible within Solr/Lucene.},
	editora = {{LuceneSolrRevolution}},
	editoratype = {collaborator},
	urldate = {2014-09-06},
	date = {2013-05-29}
}

@online{czerwonka_pairwise_2008,
	title = {Pairwise Testing in the Real World: Practical Extensions to Test-Case Scenarios},
	url = {http://msdn.microsoft.com/en-us/library/cc150619.aspx},
	titleaddon = {Microsoft},
	author = {Czerwonka, Jacek},
	urldate = {2014-09-22},
	date = {2008-02},
	file = {Pairwise Testing in the Real World\: Practical Extensions to Test-Case Scenarios:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/ACGIMZD6/cc150619.html:text/html}
}

@article{yang_identifying_2014,
	title = {Identifying interesting Twitter contents using topical analysis},
	volume = {41},
	issn = {0957-4174},
	url = {http://www.sciencedirect.com/science/article/pii/S0957417414000141},
	doi = {10.1016/j.eswa.2013.12.051},
	abstract = {Social media platforms such as Twitter are becoming increasingly mainstream which provides valuable user-generated information by publishing and sharing contents. Identifying interesting and useful contents from large text-streams is a crucial issue in social media because many users struggle with information overload. Retweeting as a forwarding function plays an important role in information propagation where the retweet counts simply reflect a tweet’s popularity. However, the main reason for retweets may be limited to personal interests and satisfactions. In this paper, we use a topic identification as a proxy to understand a large number of tweets and to score the interestingness of an individual tweet based on its latent topics. Our assumption is that fascinating topics generate contents that may be of potential interest to a wide audience. We propose a novel topic model called Trend Sensitive-Latent Dirichlet Allocation ({TS}-{LDA}) that can efficiently extract latent topics from contents by modeling temporal trends on Twitter over time. The experimental results on real world data from Twitter demonstrate that our proposed method outperforms several other baseline methods.},
	pages = {4330--4336},
	number = {9},
	journaltitle = {Expert Systems with Applications},
	shortjournal = {Expert Systems with Applications},
	author = {Yang, Min-Chul and Rim, Hae-Chang},
	urldate = {2014-07-16},
	date = {2014-07},
	keywords = {Interesting content, {LDA}, Social media, Topic model, Twitter},
	file = {ScienceDirect Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/EKNKDICC/Yang and Rim - 2014 - Identifying interesting Twitter contents using top.pdf:application/pdf;ScienceDirect Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/TI29BBVZ/S0957417414000141.html:text/html}
}

@inreference{_data_2014,
	title = {Data loss prevention software},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {http://en.wikipedia.org/w/index.php?title=Data_loss_prevention_software&oldid=628333637},
	abstract = {Data loss/leak prevention solution is a system that is designed to detect potential data breach / data ex-filtration transmissions and prevent them by monitoring, detecting and blocking sensitive data while in-use (endpoint actions), in-motion (network traffic), and at-rest (data storage). In data leakage incidents, sensitive data is disclosed to unauthorized personnel either by malicious intent or inadvertent mistake. Such sensitive data can come in the form of private or company information, intellectual property ({IP}), financial or patient information, credit-card data, and other information depending on the business and the industry.},
	booktitle = {Wikipedia, the free encyclopedia},
	urldate = {2014-10-06},
	date = {2014-10-05},
	langid = {english},
	note = {Page Version {ID}: 628333637},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/2T6EEN6D/index.html:text/html}
}

@article{chen_innovative_2009,
	title = {An innovative approach for testing bioinformatics programs using metamorphic testing},
	volume = {10},
	rights = {2009 Chen et al; licensee {BioMed} Central Ltd.},
	issn = {1471-2105},
	url = {http://www.biomedcentral.com/1471-2105/10/24/abstract},
	doi = {10.1186/1471-2105-10-24},
	abstract = {Recent advances in experimental and computational technologies have fueled the development of many sophisticated bioinformatics programs. The correctness of such programs is crucial as incorrectly computed results may lead to wrong biological conclusion or misguide downstream experimentation. Common software testing procedures involve executing the target program with a set of test inputs and then verifying the correctness of the test outputs. However, due to the complexity of many bioinformatics programs, it is often difficult to verify the correctness of the test outputs. Therefore our ability to perform systematic software testing is greatly hindered.
{PMID}: 19152705},
	pages = {24},
	number = {1},
	journaltitle = {{BMC} Bioinformatics},
	author = {Chen, Tsong Y. and Ho, Joshua {WK} and Liu, Huai and Xie, Xiaoyuan},
	urldate = {2014-10-01},
	date = {2009-01-19},
	langid = {english},
	pmid = {19152705},
	file = {Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/ZUDPSACM/Chen et al. - 2009 - An innovative approach for testing bioinformatics .pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/5ESANV9V/24.html:text/html}
}

@software{reed_topic_2013,
	title = {Topic Model Analyzer},
	rights = {{GNU} Public License v3},
	url = {https://github.com/cjrd/TMA},
	abstract = {The Topic Model Analyzer ({TMA}) is a simple tool for exploring and analyzing your real-world data with modern topic models. Using a modern, javascript-enabled web-browser (preferably not {IE}, yet...), navigate to http://geordi.cs.uiowa.edu/tma and begin using {TMA} on any reasonably sized dataset, or you can experiment with some of the example datasets. See below for documentation and installation instructions.},
	version = {c077c65beeefa279053fab89191742ba56cdb303},
	author = {Reed, Colorado},
	date = {2013-10-24},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/A7BP9T63/CTM.html:text/html}
}

@article{blei_probabilistic_2010,
	title = {Probabilistic Topic Models},
	volume = {27},
	issn = {1053-5888},
	doi = {10.1109/MSP.2010.938079},
	abstract = {In this article, we review probabilistic topic models: graphical models that can be used to summarize a large collection of documents with a smaller number of distributions over words. Those distributions are called "topics" because, when fit to data, they capture the salient themes that run through the collection. We describe both finite-dimensional parametric topic models and their Bayesian nonparametric counterparts, which are based on the hierarchical Dirichlet process ({HDP}). We discuss two extensions of topic models to time-series data-one that lets the topics slowly change over time and one that lets the assumed prevalence of the topics change. Finally, we illustrate the application of topic models to nontext data, summarizing some recent research results in image analysis.},
	pages = {55--65},
	number = {6},
	journaltitle = {{IEEE} Signal Processing Magazine},
	author = {Blei, D. and Carin, L. and Dunson, D.},
	date = {2010-11},
	keywords = {Analytical models, Bayesian methods, Bayesian nonparametric counterparts, Bayes methods, Computational modeling, Data models, document image processing, finite-dimensional parametric topic models, graphical model, Graphical models, hierarchical Dirichlet process, image analysis, Markov processes, probabilistic topic model, Probability, time series, time-series},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/VZ2SFJ3B/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/RZVAQB32/Blei et al. - 2010 - Probabilistic Topic Models.pdf:application/pdf}
}

@online{bright_arrests_2012,
	title = {With arrests, {HBGary} hack saga finally ends},
	url = {http://arstechnica.com/tech-policy/news/2012/03/the-hbgary-saga-nears-its-end.ars},
	abstract = {The team that hacked and embarrassed {HBGary} Federal was bold, hungry for  …},
	titleaddon = {Ars Technica},
	author = {Bright, Peter},
	urldate = {2014-09-08},
	date = {2012-03-10},
	keywords = {anonymous, hbgary, sabu, type: report},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/A7IIFKZ5/the-hbgary-saga-nears-its-end.html:text/html}
}

@inproceedings{jang_exploring_????,
	title = {Exploring Social Networks with Topical Analysis},
	url = {http://www2012.wwwconference.org/proceedings/webscience/wwwwebsci2012_jang.pdf},
	publisher = {International World Wide Web Conferences Committee},
	author = {Jang, Jiyeon and Choi, Jinhyuk and Jang, Gwan and Myaeng, Sung-Hyon},
	urldate = {2014-02-05},
	file = {[PDF] from wwwconference.org:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/8PGM9EZ9/Jang et al. - Exploring Social Networks with Topical Analysis.pdf:application/pdf}
}

@online{_journal_????,
	title = {Journal of Statistics Education, V4N1: Pfannkuch},
	url = {http://www.amstat.org/publications/jse/v4n1/pfannkuch.html},
	urldate = {2014-03-11},
	file = {Journal of Statistics Education, V4N1\: Pfannkuch:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/J8953XTD/pfannkuch.html:text/html}
}

@online{weingart_topic_2012,
	title = {Topic Modeling for Humanists: A Guided Tour},
	url = {http://www.scottbot.net/HIAL/?p=19113},
	shorttitle = {Topic Modeling for Humanists},
	titleaddon = {the scottbot irregular},
	author = {Weingart, Scott},
	urldate = {2014-07-18},
	date = {2012-07-25},
	keywords = {method},
	file = {Topic Modeling for Humanists\: A Guided Tour – the scottbot irregular:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/9HC8F7QA/HIAL.html:text/html}
}

@article{schieferdecker_model-based_2012,
	title = {Model-Based Testing},
	volume = {29},
	issn = {0740-7459},
	doi = {10.1109/MS.2012.13},
	abstract = {Model-based testing ({MBT}) strives to automatically and systematically generate test cases. In this column, Ina Schieferdecker introduces {MBT} technologies and methods.},
	pages = {14--18},
	number = {1},
	journaltitle = {{IEEE} Software},
	author = {Schieferdecker, I},
	date = {2012-01},
	keywords = {engineering, {MBT}, methods Fokus!{MBT}, model-based testing, Modeling, program testing, software, Software design, software testing, technology, Testing, tools},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/NAE3URKJ/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/73P2H943/Schieferdecker - 2012 - Model-Based Testing.pdf:application/pdf}
}

@article{fumera_spam_2006,
	title = {Spam Filtering Based On The Analysis Of Text Information Embedded Into Images},
	volume = {7},
	issn = {1532-4435},
	url = {http://dl.acm.org/citation.cfm?id=1248547.1248645},
	abstract = {In recent years anti-spam filters have become necessary tools for Internet service providers to face up to the continuously growing spam phenomenon. Current server-side anti-spam filters are made up of several modules aimed at detecting different features of spam e-mails. In particular, text categorisation techniques have been investigated by researchers for the design of modules for the analysis of the semantic content of e-mails, due to their potentially higher generalisation capability with respect to manually derived classification rules used in current server-side filters. However, very recently spammers introduced a new trick consisting of embedding the spam message into attached images, which can make all current techniques based on the analysis of digital text in the subject and body fields of e-mails ineffective. In this paper we propose an approach to anti-spam filtering which exploits the text information embedded into images sent as attachments. Our approach is based on the application of state-of-the-art text categorisation techniques to the analysis of text extracted by {OCR} tools from images attached to e-mails. The effectiveness of the proposed approach is experimentally evaluated on two large corpora of spam e-mails.},
	pages = {2699--2720},
	journaltitle = {J. Mach. Learn. Res.},
	author = {Fumera, Giorgio and Pillai, Ignazio and Roli, Fabio},
	urldate = {2014-06-19},
	date = {2006-12},
	file = {ACM Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/CWGP8XC2/Fumera et al. - 2006 - Spam Filtering Based On The Analysis Of Text Infor.pdf:application/pdf}
}

@online{_froglogic_????,
    author={{Froglogic GmbH}},
    date={2014},
	title = {froglogic Automated Cross-Platform {GUI} Testing},
	url = {http://www.froglogic.com/index.php},
	urldate = {2014-10-19},
	file = {froglogic - Automated Cross-Platform GUI Testing:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/5Z9KD5W9/index.html:text/html}
}

@article{hsu_new_2004,
	title = {A new hybrid case-based architecture for medical diagnosis},
	volume = {166},
	issn = {0020-0255},
	url = {http://www.sciencedirect.com/science/article/pii/S0020025503004602},
	doi = {10.1016/j.ins.2003.11.009},
	abstract = {This paper proposes a new hybrid case-based architecture, which supports multiple-disease diagnosis and the learning of new adaptation knowledge. The architecture combines case-based reasoning ({CBR}), neural networks, fuzzy theory, induction, utility theory, and knowledge-based planning technology together to facilitate medical diagnosis. The basic mechanism is that of {CBR}. A distributed fuzzy neural network is employed to perform approximate matching and thus to tolerate potential noise in case retrieval. The induction technology along with utility theory is used to select valuable features of the target case and prune unnecessary search space. Knowledge-based planning is a general-purpose mechanism for case adaptation. It creates a case adaptation plan from an adaptation tree, which contains all relevant problem features, satisfies all relevant constraints, and contains all cases whose expected utilities are greater than a threshold. Execution of the case adaptation plan leads to the diagnosis of multiple diseases. The adaptation tree facilitates the reuse of cases and the learning of various types of knowledge-including relationships between disease types and features, case-specific verification knowledge, and differential diagnosis rules. Integrating these techniques in the {CBR} paradigm can effectively produce a high-quality diagnosis for a given medical consultation.},
	pages = {231--247},
	number = {1},
	journaltitle = {Information Sciences},
	shortjournal = {Information Sciences},
	author = {Hsu, Chien-Chang and Ho, Cheng-Seen},
	urldate = {2014-09-08},
	date = {2004-10-29},
	file = {ScienceDirect Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/PBTUVTUU/Hsu and Ho - 2004 - A new hybrid case-based architecture for medical d.pdf:application/pdf;ScienceDirect Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/WJ92PHW7/S0020025503004602.html:text/html}
}

@book{norvig_artificial_2012,
	edition = {3},
	title = {Artificial Intelligence: A Modern Approach},
	url = {http://aima.cs.berkeley.edu/},
	publisher = {Berkeley},
	author = {Norvig, Stuart Russel {\textbackslash}\& Peter},
	date = {2012}
}

@article{jones_solving_2013,
	title = {Solving the snake cube puzzle in Haskell},
	volume = {23},
	doi = {10.1017/S0956796813000014},
	abstract = {We describe a concise and elegant functional program, written in Haskell, that computes solutions for a classic puzzle known as the “snake cube.” The program reflects some of the fundamental characteristics of the functional style, identifying key abstractions, and defining a small collection of operators for manipulating and working with the associated values. Well-suited for an introductory course on functional programming, this example highlights the use of visualization tools to explain and demonstrate the choices of data structures and algorithms that are used in the development.},
	pages = {145--160},
	number = {2},
	journaltitle = {Journal of Functional Programming},
	author = {Jones, Mark P.},
	date = {2013},
	file = {Cambridge Journals PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/ETXWE6IP/Jones - 2013 - Solving the snake cube puzzle in Haskell.pdf:application/pdf;Cambridge Journals Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/FEK3K92X/displayAbstract.html:text/html}
}

@online{_haskell_????-1,
	title = {haskell - What optimizations can {GHC} be expected to perform reliably? - Stack Overflow},
	url = {http://stackoverflow.com/questions/12653787/what-optimizations-can-ghc-be-expected-to-perform-reliably},
	urldate = {2014-03-11},
	file = {haskell - What optimizations can GHC be expected to perform reliably? - Stack Overflow:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/S9IFU8C7/what-optimizations-can-ghc-be-expected-to-perform-reliably.html:text/html}
}

@article{salton_extended_1983,
	title = {Extended Boolean Information Retrieval},
	volume = {26},
	issn = {0001-0782},
	url = {http://doi.acm.org/10.1145/182.358466},
	doi = {10.1145/182.358466},
	pages = {1022--1036},
	number = {11},
	journaltitle = {Commun. {ACM}},
	author = {Salton, Gerard and Fox, Edward A. and Wu, Harry},
	urldate = {2014-09-14},
	date = {1983-11},
	keywords = {generalized distance measurement, information retrieval, Lp-vector norm, online retrieval methods, query formulation},
	file = {ACM Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/8N2ZJ479/Salton et al. - 1983 - Extended Boolean Information Retrieval.pdf:application/pdf}
}

@online{_introduction_????,
	title = {Introduction to Latent Dirichlet Allocation - Edwin Chen's Blog},
	url = {http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/},
	urldate = {2014-07-25},
	file = {Introduction to Latent Dirichlet Allocation - Edwin Chen's Blog:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/XWFV475A/introduction-to-latent-dirichlet-allocation.html:text/html}
}

@online{_software_coverity,
    author={Synopsys},
	title = {Software Testing and Static Analysis Tools {\textbar} Coverity},
    date={2014},
	url = {http://www.coverity.com/},
	urldate = {2014-10-19},
	file = {Software Testing and Static Analysis Tools | Coverity:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/UEEIG6HX/www.coverity.com.html:text/html}
}

@article{trappey_development_2006,
	title = {Development of a patent document classification and search platform using a back-propagation network},
	volume = {31},
	url = {http://www.sciencedirect.com/science/article/pii/S0957417406000121},
	pages = {755--765},
	number = {4},
	journaltitle = {Expert Systems with Applications},
	author = {Trappey, Amy {JC} and Hsu, Fu-Chiang and Trappey, Charles V. and Lin, Chia-I.},
	urldate = {2014-09-08},
	date = {2006},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/8VEPHKJ9/S0957417406000121.html:text/html}
}

@online{_how_????-1,
	title = {How to embed Lua 5.1 in C++ {\textbar} c/c++ programming by examples},
	url = {http://cc.byexamples.com/2008/06/07/how-to-embed-lua-51-in-c/},
	urldate = {2014-03-11},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/5BU6RBB5/how-to-embed-lua-51-in-c.html:text/html}
}

@online{_c++_????,
	title = {c++ - boost::flat\_map and its performance compared to map and unordered\_map - Stack Overflow},
	url = {http://stackoverflow.com/questions/21166675/boostflat-map-and-its-performance-compared-to-map-and-unordered-map},
	shorttitle = {c++ - boost},
	urldate = {2014-10-14},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/BAFECPG9/boostflat-map-and-its-performance-compared-to-map-and-unordered-map.html:text/html}
}

@article{hutton_factorising_2010,
	title = {Factorising folds for faster functions},
	volume = {20},
	doi = {10.1017/S0956796810000122},
	abstract = {The worker/wrapper transformation is a general technique for improving the performance of recursive programs by changing their types. The previous formalisation (A. Gill \& G. Hutton, J. Funct. Program., vol. 19, 2009, pp. 227–251) was based upon a simple fixed-point semantics of recursion. In this paper, we develop a more structured approach, based upon initial-algebra semantics. In particular, we show how the worker/wrapper transformation can be applied to programs defined using the structured pattern of recursion captured by fold operators, and illustrate our new technique with a number of examples.},
	pages = {353--373},
	issue = {Special Issue 3-4},
	journaltitle = {Journal of Functional Programming},
	author = {Hutton, Graham and Jaskelioff, Mauro and Gill, Andy},
	date = {2010},
	file = {Cambridge Journals PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/MZ23S7Q4/Hutton et al. - 2010 - Factorising folds for faster functions.pdf:application/pdf;Cambridge Journals Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/4DR7Z3HT/displayAbstract.html:text/html}
}

@article{miljenovic_pearls_2013,
	title = {Pearls of Functional Algorithm Design, by Richard Bird, Cambridge University Press, September 2010, £35.00, {US} \$ 60.00. {ISBN}: 978052151338 (hardback), 286pp},
	volume = {23},
	doi = {10.1017/S095679681200041X},
	shorttitle = {Pearls of Functional Algorithm Design, by Richard Bird, Cambridge University Press, September 2010, £35.00, {US} \$ 60.00. {ISBN}},
	pages = {226--227},
	number = {2},
	journaltitle = {Journal of Functional Programming},
	author = {Miljenovic, Ivan Lazar},
	date = {2013},
	file = {Cambridge Journals PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/DXIHB6BC/Miljenovic - 2013 - Pearls of Functional Algorithm Design, by Richard .pdf:application/pdf;Cambridge Journals Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/DP3Z5HTA/displayAbstract.html:text/html}
}

@article{white_structural_1994,
	title = {Structural Properties for Contracting State Partially Observable Markov Decision Processes},
	volume = {186.2},
	pages = {486--503},
	journaltitle = {Journal of Mathematical Analysis and Applications},
	author = {White, D. J.},
	date = {1994},
	file = {ScienceDirect Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/X7G6NCIJ/White - 1994 - Structural Properties for Contracting State Partia.pdf:application/pdf;ScienceDirect Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/PDMHA5T9/S0022247X84713126.html:text/html;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/QPASEMM2/S0022247X84713126.html:text/html}
}

@incollection{zhang_empirical_2011,
	title = {An Empirical Study on Using the National Vulnerability Database to Predict Software Vulnerabilities},
	rights = {©2011 Springer-Verlag {GmbH} Berlin Heidelberg},
	isbn = {978-3-642-23087-5, 978-3-642-23088-2},
	url = {http://link.springer.com.ezproxy1.lib.asu.edu/chapter/10.1007/978-3-642-23088-2_15},
	series = {Lecture Notes in Computer Science},
	abstract = {Software vulnerabilities represent a major cause of cyber-security problems. The National Vulnerability Database ({NVD}) is a public data source that maintains standardized information about reported software vulnerabilities. Since its inception in 1997, {NVD} has published information about more than 43,000 software vulnerabilities affecting more than 17,000 software applications. This information is potentially valuable in understanding trends and patterns in software vulnerabilities, so that one can better manage the security of computer systems that are pestered by the ubiquitous software security flaws. In particular, one would like to be able to predict the likelihood that a piece of software contains a yet-to-be-discovered vulnerability, which must be taken into account in security management due to the increasing trend in zero-day attacks. We conducted an empirical study on applying data-mining techniques on {NVD} data with the objective of predicting the time to next vulnerability for a given software application. We experimented with various features constructed using the information available in {NVD}, and applied various machine learning algorithms to examine the predictive power of the data. Our results show that the data in {NVD} generally have poor prediction capability, with the exception of a few vendors and software applications. By doing a large number of experiments and observing the data, we suggest several reasons for why the {NVD} data have not produced a reasonable prediction model for time to next vulnerability with our current approach.},
	pages = {217--231},
	number = {6860},
	booktitle = {Database and Expert Systems Applications},
	publisher = {Springer Berlin Heidelberg},
	author = {Zhang, Su and Caragea, Doina and Ou, Xinming},
	editor = {Hameurlain, Abdelkader and Liddle, Stephen W. and Schewe, Klaus-Dieter and Zhou, Xiaofang},
	urldate = {2014-05-18},
	date = {2011-01-01},
	keywords = {Artificial Intelligence (incl. Robotics), Computer Communication Networks, cyber-security, Database Management, data mining, Data Mining and Knowledge Discovery, Information Storage and Retrieval, Information Systems Applications (incl.Internet), vulnerability prediction},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/A6Q523BS/978-3-642-23088-2_15.html:text/html}
}

@article{irani_modeling_2011,
	title = {Modeling Unintended Personal-Information Leakage from Multiple Online Social Networks},
	volume = {15},
	issn = {1089-7801},
	doi = {10.1109/MIC.2011.25},
	abstract = {Most people have multiple accounts on different social networks. Because these networks offer various levels of privacy protection, the weakest privacy policies in the social network ecosystem determine how much personal information is disclosed online. A new information leakage measure quantifies the information available about a given user. Using this measure makes it possible to evaluate the vulnerability of a user's social footprint to two known attacks: physical identification and password recovery. Experiments show the measure's usefulness in quantifying information leakage from publicly crawled information and also suggest ways of better protecting privacy and reducing information leakage in the social Web.},
	pages = {13--19},
	number = {3},
	journaltitle = {{IEEE} Internet Computing},
	author = {Irani, D. and Webb, S. and Pu, C. and Li, Kang},
	date = {2011-05},
	keywords = {Aggregates, Authentication, data privacy, Electronic mail, Modeling, multiple online social networks, Online services, personal information leakage, Privacy, privacy protection, publicly crawled information, Security and Privacy, social networking (online), Social networks, Social network services, social Web, unintended personal information leakage, user social footprint},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/6M8QIWQR/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/PWJUXXZC/Irani et al. - 2011 - Modeling Unintended Personal-Information Leakage f.pdf:application/pdf}
}

@article{kaski_websomself-organizing_1998,
	title = {{WEBSOM}–self-organizing maps of document collections},
	volume = {21},
	url = {http://www.sciencedirect.com/science/article/pii/S0925231298000393},
	pages = {101--117},
	number = {1},
	journaltitle = {Neurocomputing},
	author = {Kaski, Samuel and Honkela, Timo and Lagus, Krista and Kohonen, Teuvo},
	urldate = {2014-09-08},
	date = {1998},
	file = {[PDF] from ntust.edu.tw:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/E9ETF4ZZ/Kaski et al. - 1998 - WEBSOM–self-organizing maps of document collection.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/6RWGZRQX/S0925231298000393.html:text/html}
}

@misc{_haskell11.pdf_????,
	title = {haskell11.pdf},
	file = {haskell11.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/VI8V5GD7/haskell11.pdf:application/pdf}
}

@online{_how_????-2,
	title = {How to draw a finite-state machine},
	url = {http://martin-thoma.com/how-to-draw-a-finite-state-machine/},
	urldate = {2014-03-11},
	file = {How to draw a finite-state machine:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/VRGIDZG5/how-to-draw-a-finite-state-machine.html:text/html}
}

@online{_5_????,
	title = {5 Career Mistakes You Will Regret In 10 Years},
	url = {http://www.forbes.com/sites/ricksmith/2014/07/02/5-career-mistakes-you-will-regret-in-10-years/},
	abstract = {Too many of us navigate our careers like we’re paddling across a lake, not sailing across an ocean. We are short-sighted when making decisions. We focus on completing the task at hand, fighting for the next promotion, outperforming a colleague. But there are many seemingly minor actions that can have [...]},
	titleaddon = {Forbes},
	urldate = {2014-08-08},
	keywords = {careers, {CEO}, {CEO} Network, {CMO} Network, Entrepreneurs, Future Of Work, Leaders, Leadership, Management, Managing, money, networking, Small Business Strategies, Startups, Strategies \& Solutions, Strategies Solutions, Talent Strategies, Workforce Management},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/MZPERZXA/5-career-mistakes-you-will-regret-in-10-years.html:text/html}
}

@online{_you_????,
	title = {You Can't Handle the Creative},
	url = {http://www.linkedin.com/today/post/article/20140225195147-3154163-you-can-t-handle-the-creative},
	abstract = {In their 2011 study, "The Bias Against Creativity: Why People Desire But Reject Creative Ideas" by Jennifer Mueller ({UPenn} Wharton), Shimul Melwani ({UNC}) and Jack A. Goncalo (Cornell), they found},
	urldate = {2014-02-26},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/82PEN9QI/20140225195147-3154163-you-can-t-handle-the-creative.html:text/html}
}

@article{wang_continuous_2012,
	title = {Continuous time dynamic topic models},
	url = {http://arxiv.org/abs/1206.3298},
	journaltitle = {{arXiv} preprint {arXiv}:1206.3298},
	author = {Wang, Chong and Blei, David and Heckerman, David},
	urldate = {2014-10-12},
	date = {2012},
	file = {[PDF] from arxiv.org:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/SAF42RZJ/Wang et al. - 2012 - Continuous time dynamic topic models.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/TAGVBZJ2/1206.html:text/html}
}

@inreference{_unit_2014,
	title = {Unit testing},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {http://en.wikipedia.org/w/index.php?title=Unit_testing&oldid=623160256},
	abstract = {In computer programming, unit testing is a software testing method by which individual units of source code, sets of one or more computer program modules together with associated control data, usage procedures, and operating procedures are tested to determine if they are fit for use.[1] Intuitively, one can view a unit as the smallest testable part of an application. In procedural programming, a unit could be an entire module, but it is more commonly an individual function or procedure. In object-oriented programming, a unit is often an entire interface, such as a class, but could be an individual method.[2] Unit tests are short code fragments[3] created by programmers or occasionally by white box testers during the development process.},
	booktitle = {Wikipedia, the free encyclopedia},
	urldate = {2014-09-01},
	date = {2014-08-28},
	langid = {english},
	note = {Page Version {ID}: 623160256},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/IXQMHJA2/index.html:text/html}
}

@online{_aetg_????,
	title = {The {AETG} System: An Approach to Testing Based on Combinatorial Design},
	url = {http://aetgweb.appcomsci.com/papers/1997-tse.html},
	urldate = {2014-10-01},
	file = {The AETG System\: An Approach to Testing Based on Combinatorial Design:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/GMCGNXRU/1997-tse.html:text/html}
}

@online{_xml_????,
	title = {{XML} Web Services for Embedded Devices},
	url = {http://www.cs.fsu.edu/~engelen/cases03.html},
	urldate = {2014-03-11},
	file = {XML Web Services for Embedded Devices:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/UXE4C82A/cases03.html:text/html}
}

@article{doumit_online_????,
	title = {Online News Media Bias Analysis using an {LDA}-{NLP} Approach},
	url = {http://necsi.edu/events/iccs2011/papers/313.pdf},
	author = {Doumit, Sarjoun and Minai, Ali},
	urldate = {2014-02-05},
	file = {[PDF] from necsi.edu:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/6F42JF5V/Doumit and Minai - Online News Media Bias Analysis using an LDA-NLP A.pdf:application/pdf}
}

@article{_review_????,
	title = {A Review of Boundary Value Analysis Techniques},
	file = {Sept2001.qxd - 200804-Coe.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/86HS6KNM/200804-Coe.pdf:application/pdf}
}

@inreference{_markov_2014,
	title = {Markov decision process},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {http://en.wikipedia.org/w/index.php?title=Markov_decision_process&oldid=615180994},
	abstract = {Markov decision processes ({MDPs}), named after Andrey Markov, provide a mathematical framework for modeling decision making in situations where outcomes are partly random and partly under the control of a decision maker. {MDPs} are useful for studying a wide range of optimization problems solved via dynamic programming and reinforcement learning. {MDPs} were known at least as early as the 1950s (cf. Bellman 1957). A core body of research on Markov decision processes resulted from Ronald A. Howard's book published in 1960, Dynamic Programming and Markov Processes. They are used in a wide area of disciplines, including robotics, automated control, economics, and manufacturing.},
	booktitle = {Wikipedia, the free encyclopedia},
	urldate = {2014-09-08},
	date = {2014-08-24},
	langid = {english},
	note = {Page Version {ID}: 615180994},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/MUSC93IQ/index.html:text/html}
}

@inproceedings{kurniati_examining_2014,
	title = {Examining the performance of topic modeling techniques in Twitter trends extraction},
	doi = {10.1109/ICOIN.2014.6799706},
	abstract = {It is very important to extract the Twitter trends since it reflects the personal view over 645 million of its users. We examine the effectiveness of two topic modeling techniques i.e., standard Latent Dirichlet Allocation ({LDA}) and semantic-based Joint Multi-grain Topic-Sentiment ({JMTS}) in Twitter trends extraction. In addition, we also examine the frequent phrase method. Our finding reveals that {JMTS} significantly outperforms frequent phrase method and {LDA} by 54\% and 24\%, respectively.},
	eventtitle = {2014 International Conference on Information Networking ({ICOIN})},
	pages = {364--369},
	booktitle = {2014 International Conference on Information Networking ({ICOIN})},
	author = {Kurniati, M.N. and Ryu, Woo-Jong and Alam, M.H. and Lee, {SangKeun}},
	date = {2014-02},
	keywords = {Accuracy, Context, frequent phrase method, Games, {JMTS}, latent dirichlet allocation, {LDA}, Market research, Noise, semantic-based joint multigrain topic-sentiment, social networking (online), Tablet computers, text analysis, topic modeling techniques, Twitter, Twitter trends extraction},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/2QG82B7Q/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/MGXDTNPC/Kurniati et al. - 2014 - Examining the performance of topic modeling techni.pdf:application/pdf}
}

@online{_sqlite_????,
	title = {{SQLite} speed tests {BLOB} vs flat-file for those interested - Google Groups},
	url = {https://groups.google.com/forum/#!topic/alt.comp.lang.borland-delphi/_cFtA7YToA4},
	urldate = {2014-03-11},
	file = {SQLite speed tests BLOB vs flat-file for those interested - Google Groups:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/3VD8CQSU/forum.html:text/html}
}

@online{_principled_????,
	title = {A Principled Approach to Operating System Construction in Haskell},
	url = {http://ogi.altocumulus.org/~hallgren/ICFP2005/},
	urldate = {2014-03-11},
	file = {A Principled Approach to Operating System Construction in Haskell:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/E63BJV7R/ICFP2005.html:text/html}
}

@article{xiong_peertrust:_2004,
	title = {Peertrust: Supporting reputation-based trust for peer-to-peer electronic communities},
	pages = {14},
	author = {Xiong, L. and Liu, L.},
	date = {2004},
	keywords = {Communities, Computer applications, Computer networks, Computer Society, Consumer electronics, Costs, data management, Data security, Electronic commerce, Feedback, Information security, P2P network, Peer to peer computing, peer-to-peer electronic communities, reputation mechanism, Security, security of data, transaction-based feedback system, transaction processing, trust model},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/QD4AWV9E/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/IKUQRJME/Xiong and Liu - 2004 - PeerTrust supporting reputation-based trust for p.pdf:application/pdf}
}

@online{blei_topic_2009,
	title = {Topic Models},
	url = {http://videolectures.net/mlss09uk_blei_tm/},
	author = {Blei, David M},
	urldate = {2014-09-08},
	date = {2009-11},
	file = {mlss09uk_blei_tm.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/V7GE86Z7/mlss09uk_blei_tm.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/CB3T7UFC/mlss09uk_blei_tm.html:text/html}
}

@article{bhamidipati_programming_2009,
	title = {Programming in Haskell by Graham Hutton, Cambridge University Press, 2007, 184 pp., {ISBN} 0-521-69269-5.},
	volume = {19},
	doi = {10.1017/S0956796809007151},
	pages = {256--259},
	number = {2},
	journaltitle = {Journal of Functional Programming},
	author = {Bhamidipati, Saketh},
	date = {2009},
	file = {Cambridge Journals PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/THTWN6QU/Bhamidipati - 2009 - Programming in Haskell by Graham Hutton, Cambridge.pdf:application/pdf;Cambridge Journals Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/K6VRH3H3/displayAbstract.html:text/html}
}

@inproceedings{mimno_optimizing_2011,
	title = {Optimizing semantic coherence in topic models},
	url = {http://dl.acm.org/citation.cfm?id=2145462},
	pages = {262--272},
	booktitle = {Proceedings of the Conference on Empirical Methods in Natural Language Processing},
	publisher = {Association for Computational Linguistics},
	author = {Mimno, David and Wallach, Hanna M. and Talley, Edmund and Leenders, Miriam and {McCallum}, Andrew},
	urldate = {2014-09-14},
	date = {2011},
	file = {[PDF] from umass.edu:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/35HJ3ZVP/Mimno et al. - 2011 - Optimizing semantic coherence in topic models.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/6HXZ9ITS/citation.html:text/html}
}

@inproceedings{he_using_2000,
	title = {Using Reinforcement Learning for proactive Network Fault Management},
	volume = {2000},
	booktitle = {International Conference on Communication Technology Proceedings},
	publisher = {{WCC} - {ICCT}},
	author = {He, Qiming and Shayman, A.},
	date = {2000}
}

@online{graham_programming_????,
	title = {The Programming Historian},
	url = {http://programminghistorian.org/lessons/topic-modeling-and-mallet},
	author = {Graham, Shawn and Weingart, Scott and Milligan, Ian},
	urldate = {2014-07-18},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/FCZ9WPZG/topic-modeling-and-mallet.html:text/html}
}

@article{dolstra_nixos:_2010,
	title = {{NixOS}: A purely functional Linux distribution},
	volume = {20},
	doi = {10.1017/S0956796810000195},
	shorttitle = {{NixOS}},
	abstract = {Existing package and system configuration management tools suffer from an imperative model, where system administration actions such as package upgrades or changes to system configuration files are stateful: they destructively update the state of the system. This leads to many problems, such as the inability to roll back changes easily, to deploy multiple versions of a package side-by-side, to reproduce a configuration deterministically on another machine, or to reliably upgrade a system. In this paper we show that we can overcome these problems by moving to a purely functional system configuration model. This means that all static parts of a system (such as software packages, configuration files and system startup scripts) are built by pure functions and are immutable, stored in a way analogous to a heap in a purely functional language. We have implemented this model in {NixOS}, a non-trivial Linux distribution that uses the Nix package manager to build the entire system configuration from a modular, purely functional specification.},
	pages = {577--615},
	issue = {Special Issue 5-6},
	journaltitle = {Journal of Functional Programming},
	author = {Dolstra, Eelco and Löh, Andres and Pierron, Nicolas},
	date = {2010},
	file = {Cambridge Journals Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/AABUUA9H/displayAbstract.html:text/html}
}

@online{_you_????-1,
	title = {You are dangerously bad at cryptography {\textbar} Happy Bear Software {\textbar} Web Application Development},
	url = {http://happybearsoftware.com/you-are-dangerously-bad-at-cryptography.html},
	urldate = {2014-03-11},
	file = {You are dangerously bad at cryptography | Happy Bear Software | Web Application Development:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/BRU595BT/you-are-dangerously-bad-at-cryptography.html:text/html}
}

@inproceedings{kossinets_structure_2008,
	location = {New York, {NY}, {USA}},
	title = {The Structure of Information Pathways in a Social Communication Network},
	isbn = {978-1-60558-193-4},
	url = {http://doi.acm.org/10.1145/1401890.1401945},
	doi = {10.1145/1401890.1401945},
	series = {{KDD} '08},
	abstract = {Social networks are of interest to researchers in part because they are thought to mediate the flow of information in communities and organizations. Here we study the temporal dynamics of communication using on-line data, including e-mail communication among the faculty and staff of a large university over a two-year period. We formulate a temporal notion of "distance" in the underlying social network by measuring the minimum time required for information to spread from one node to another - a concept that draws on the notion of vector-clocks from the study of distributed computing systems. We find that such temporal measures provide structural insights that are not apparent from analyses of the pure social network topology. In particular, we define the network backbone to be the subgraph consisting of edges on which information has the potential to flow the quickest. We find that the backbone is a sparse graph with a concentration of both highly embedded edges and long-range bridges - a finding that sheds new light on the relationship between tie strength and connectivity in social networks.},
	pages = {435--443},
	booktitle = {Proceedings of the 14th {ACM} {SIGKDD} International Conference on Knowledge Discovery and Data Mining},
	publisher = {{ACM}},
	author = {Kossinets, Gueorgi and Kleinberg, Jon and Watts, Duncan},
	urldate = {2014-06-19},
	date = {2008},
	keywords = {communication latency, social network, strength of weak ties},
	file = {ACM Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/46NIXVIS/Kossinets et al. - 2008 - The Structure of Information Pathways in a Social .pdf:application/pdf}
}

@misc{_gibbs_????,
	title = {Gibbs Sampling for the uninitiated},
	url = {http://www.cs.umd.edu/~hardisty/papers/gsfu.pdf},
	file = {gsfu.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/AC8RT3E8/gsfu.pdf:application/pdf}
}

@online{mcaffee_mcaffee_????,
	title = {{McAffee} Total Protection for Data Loss Prevention},
	url = {http://www.mcafee.com/us/resources/solution-briefs/sb-total-protection-for-dlp.pdf},
	abstract = {As regulations and corporate standards place increasing demands on {IT} to
ensure safe data handling, deploying necessary protective solutions can
seem daunting. Some data loss prevention ({DLP}) products require substantial
effort to deploy and typically have large ongoing consulting costs. These
products leave it up to {IT} to know about all the data that needs to be
protected. Can {IT} be expected to know about all the data in the various
departments of an organization and how it needs to be handled? Of course
not. It’s impossible for {IT} to identify all of the sensitive data, interpret the
regulations, and translate them into effective policies. When faced with this
dilemma, many companies simply fall back to “good enough” solutions that
don’t provide basic protection and offer little insight into ongoing data-
related risks.},
	titleaddon = {{McAffee}},
	author = {{McAffee}},
	urldate = {2014-09-08},
	file = {sb-total-protection-for-dlp.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/PMGTV55C/sb-total-protection-for-dlp.pdf:application/pdf}
}

@online{_enumerating_????,
	title = {Enumerating number of solutions to an equation},
	url = {http://math.stackexchange.com/questions/203835/enumerating-number-of-solutions-to-an-equation},
	abstract = {How do you find the number of solutions like this?

\$\$x\_1 + x\_2 + x\_3 + x\_4 = 32\$\$

where \$0 {\textbackslash}le x\_i {\textbackslash}le 10\$.

What's the generalized approach for it?},
	urldate = {2014-03-15},
	keywords = {problem 39},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/HKZM7G4K/enumerating-number-of-solutions-to-an-equation.html:text/html}
}

@inproceedings{shen_hybrid_2006,
	location = {New York, {NY}, {USA}},
	title = {A Hybrid Learning System for Recognizing User Tasks from Desktop Activities and Email Messages},
	isbn = {1-59593-287-9},
	url = {http://doi.acm.org/10.1145/1111449.1111473},
	doi = {10.1145/1111449.1111473},
	series = {{IUI} '06},
	abstract = {The {TaskTracer} system seeks to help multi-tasking users manage the resources that they create and access while carrying out their work activities. It does this by associating with each user-defined activity the set of files, folders, email messages, contacts, and web pages that the user accesses when performing that activity. The initial {TaskTracer} system relies on the user to notify the system each time the user changes activities. However, this is burdensome, and users often forget to tell {TaskTracer} what activity they are working on. This paper introduces {TaskPredictor}, a machine learning system that attempts to predict the user's current activity. {TaskPredictor} has two components: one for general desktop activity and another specifically for email. {TaskPredictor} achieves high prediction precision by combining three techniques: (a) feature selection via mutual information, (b) classification based on a confidence threshold, and (c) a hybrid design in which a Naive Bayes classifier estimates the classification confidence but where the actual classification decision is made by a support vector machine. This paper provides experimental results on data collected from {TaskTracer} users.},
	pages = {86--92},
	booktitle = {Proceedings of the 11th International Conference on Intelligent User Interfaces},
	publisher = {{ACM}},
	author = {Shen, Jianqiang and Li, Lida and Dietterich, Thomas G. and Herlocker, Jonathan L.},
	urldate = {2014-06-19},
	date = {2006},
	keywords = {intelligent interfaces, machine learning, naive Bayes, support vector machines},
	file = {ACM Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/CMZHSMWB/Shen et al. - 2006 - A Hybrid Learning System for Recognizing User Task.pdf:application/pdf}
}

@incollection{kim_topic_2011,
	title = {Topic chains for understanding a news corpus},
	url = {http://link.springer.com/chapter/10.1007/978-3-642-19437-5_13},
	pages = {163--176},
	booktitle = {Computational Linguistics and Intelligent Text Processing},
	publisher = {Springer},
	author = {Kim, Dongwoo and Oh, Alice},
	urldate = {2014-02-05},
	date = {2011},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/JCTII7AR/978-3-642-19437-5_13.html:text/html;Topic Chains.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/7TGQ63B2/Topic Chains.pdf:application/pdf}
}

@online{_fast_????,
	title = {Fast Bulk Inserts into {SQLite} - Blog::Quibb},
	url = {http://blog.quibb.org/2010/08/fast-bulk-inserts-into-sqlite/},
	shorttitle = {Fast Bulk Inserts into {SQLite} - Blog},
	abstract = {Background Sometimes it’s necessary to get information into a database quickly. {SQLite} is a light weight database engine that can be easily embedded in a},
	urldate = {2014-03-11},
	keywords = {benchmarks, c++, optimization, sqlite},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/3BX8JKFB/fast-bulk-inserts-into-sqlite.html:text/html}
}

@inreference{_copy_2014,
	title = {Copy constructor},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {http://en.wikipedia.org/w/index.php?title=Copy_constructor&oldid=579432527},
	abstract = {A copy constructor is a special constructor in the C++ programming language for creating a new object as a copy of an existing object. The first argument of such a constructor is a reference to an object of the same type as is being constructed (const or non-const), which might be followed by parameters of any type (all having default values).},
	booktitle = {Wikipedia, the free encyclopedia},
	urldate = {2014-02-05},
	date = {2014-01-19},
	langid = {english},
	note = {Page Version {ID}: 579432527},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/29N957R5/index.html:text/html}
}

@inreference{_cyclomatic_2014,
	title = {Cyclomatic complexity},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {http://en.wikipedia.org/w/index.php?title=Cyclomatic_complexity&oldid=617400349},
	abstract = {Cyclomatic complexity is a software metric (measurement). It was developed by Thomas J. {McCabe}, Sr. in 1976 and is used to indicate the complexity of a program. It is a quantitative measure of the complexity of programming instructions. It directly measures the number of linearly independent paths through a program's source code. The concept, although not the method, is somewhat similar to that of general text complexity measured by the Flesch-Kincaid Readability Test.},
	booktitle = {Wikipedia, the free encyclopedia},
	urldate = {2014-08-11},
	date = {2014-08-09},
	langid = {english},
	note = {Page Version {ID}: 617400349},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/3REWMF8M/index.html:text/html}
}

@article{fischer_purely_2011,
	title = {Purely functional lazy nondeterministic programming},
	volume = {21},
	doi = {10.1017/S0956796811000189},
	abstract = {Functional logic programming and probabilistic programming have demonstrated the broad benefits of combining laziness (nonstrict evaluation with sharing of the results) with nondeterminism. Yet these benefits are seldom enjoyed in functional programming because the existing features for nonstrictness, sharing, and nondeterminism in functional languages are tricky to combine. We present a practical way to write purely functional lazy nondeterministic programs that are efficient and perspicuous. We achieve this goal by embedding the programs into existing languages (such as Haskell, {SML}, and {OCaml}) with high-quality implementations, by making choices lazily and representing data with nondeterministic components, by working with custom monadic data types and search strategies, and by providing equational laws for the programmer to reason about their code.},
	pages = {413--465},
	issue = {Special Issue 4-5},
	journaltitle = {Journal of Functional Programming},
	author = {Fischer, Sebastian and Kiselyov, Oleg and Shan, Chung-Chieh},
	date = {2011},
	file = {Cambridge Journals PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/7QN2QSRR/Fischer et al. - 2011 - Purely functional lazy nondeterministic programmin.pdf:application/pdf;Cambridge Journals Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/HRMI3KHF/displayAbstract.html:text/html}
}

@article{sims_enron_2003,
	title = {Enron ethics (or: culture matters more than codes)},
	volume = {45},
	url = {http://link.springer.com.ezproxy1.lib.asu.edu/article/10.1023/A:1024194519384},
	shorttitle = {Enron ethics (or},
	pages = {243--256},
	number = {3},
	journaltitle = {Journal of Business ethics},
	author = {Sims, Ronald R. and Brinkmann, Johannes},
	urldate = {2014-06-19},
	date = {2003},
	file = {[PDF] from springer.com:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/H6RV6AP9/Sims and Brinkmann - 2003 - Enron ethics (or culture matters more than codes).pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/ZVZSTV8T/A1024194519384.html:text/html}
}

@online{_official_????,
	title = {Official Gmail Blog: New in Labs: Got the wrong Bob?},
	url = {http://gmailblog.blogspot.com/2009/10/new-in-labs-got-wrong-bob.html},
	shorttitle = {Official Gmail Blog},
	urldate = {2014-09-26},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/TQ9RGDUD/Official Gmail Blog New in Labs Got the wrong Bo.html:text/html}
}

@online{changeuk_latent_2013,
	title = {Latent Dirichlet Allocation, {LDA}},
	url = {http://parkcu.com/blog/latent-dirichlet-allocation/},
	abstract = {{LDA} overcomes the problems in {PLSA} model by treating the topic mixture weights as a K-parameter hidden random variable rather than a large set of individual parameters which are explicitly linked to the training set.},
	titleaddon = {{ChangUk}, Park Data Science and Engineering},
	author = {{ChangeUk}, Park},
	urldate = {2014-09-14},
	date = {2013-07-30},
	file = {LDAMath.png:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/SXRMFWG9/LDAMath.png:image/png;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/W2CG4GXX/latent-dirichlet-allocation.html:text/html}
}

@article{bernardy_generic_2010,
	title = {Generic programming with C++ concepts and Haskell type classes—a comparison},
	volume = {20},
	doi = {10.1017/S095679681000016X},
	abstract = {Earlier studies have introduced a list of high-level evaluation criteria to assess how well a language supports generic programming. Languages that meet all criteria include Haskell because of its type classes and C++ with the concept feature. We refine these criteria into a taxonomy that captures commonalities and differences between type classes in Haskell and concepts in C++ and discuss which differences are incidental and which ones are due to other language features. The taxonomy allows for an improved understanding of language support for generic programming, and the comparison is useful for the ongoing discussions among language designers and users of both languages.},
	pages = {271--302},
	issue = {Special Issue 3-4},
	journaltitle = {Journal of Functional Programming},
	author = {Bernardy, Jean-Philippe and Jansson, Patrik and Zalewski, Marcin and Schupp, Sibylle},
	date = {2010},
	file = {Cambridge Journals PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/BU7UQBEG/Bernardy et al. - 2010 - Generic programming with C++ concepts and Haskell .pdf:application/pdf;Cambridge Journals Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/ED66SHHM/displayAbstract.html:text/html}
}

@inproceedings{nguyen_network_2009,
	title = {Network Coding-Based Wireless Media Transmission Using {POMDP}},
	booktitle = {17th International Packet Video Workshop},
	author = {Nguyen, Dong and Nguyen, Thinh},
	date = {2009}
}

@online{_c++_????-1,
	title = {C++ Runtime Polymorphism without Virtual Functions - {CodeProject}},
	url = {http://www.codeproject.com/Articles/603818/Cplusplus-Runtime-Polymorphism-without-Virtual-Fun},
	urldate = {2014-03-11},
	file = {C++ Runtime Polymorphism without Virtual Functions - CodeProject:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/7ZFR6D8G/Cplusplus-Runtime-Polymorphism-without-Virtual-Fun.html:text/html}
}

@software{holovaty_django_2014,
	title = {Django Web framework for perfectionists with deadlines},
	rights = {{BSD} License},
	url = {https://www.djangoproject.com/},
	shorttitle = {Django},
	version = {1.7},
	publisher = {Django Software Foundation},
	author = {Holovaty, Adrian},
	date = {2014-09-02}
}

@book{wikipedia_bellman_2013,
	title = {Bellman Equation},
	url = {http://en.wikipedia.org/wiki/Bellman_equation},
	author = {Wikipedia},
	date = {2013-02}
}

@online{_linux_????,
	title = {The Linux Cookbook: Tips and Techniques for Everyday Use - Grammar and Reference},
	url = {http://dsl.org/cookbook/cookbook_15.html#SEC220},
	urldate = {2014-01-24},
	file = {The Linux Cookbook\: Tips and Techniques for Everyday Use - Grammar and Reference:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/BXVSFVIE/cookbook_15.html:text/html;The Linux Cookbook\: Tips and Techniques for Everyday Use - Grammar and Reference:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/GTCIC8PM/cookbook_15.html:text/html}
}

@article{al-shboul_wikipedia-based_????,
	title = {Wikipedia-based query phrase expansion for patent class search and its analysis based on topic drift concept},
	url = {http://library.kaist.ac.kr/thesis02/2012/2012D020065254_S1Ver2.pdf},
	author = {Al-Shboul, Bashar Awad Mohammad},
	urldate = {2014-02-05},
	file = {[PDF] from kaist.ac.kr:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/Z53E6SN3/Al-Shboul - Wikipedia-based query phrase expansion for patent .pdf:application/pdf}
}

@online{_how_????-3,
	title = {How to apply Naive Bayes Classifiers to document classification problems. {\textbar} /bb {\textbar} [{\textasciicircum}b]\{2\}/},
	url = {http://www.nils-haldenwang.de/computer-science/machine-learning/how-to-apply-naive-bayes-classifiers-to-document-classification-problems},
	urldate = {2014-02-10},
	file = {How to apply Naive Bayes Classifiers to document classification problems. | /bb | [^b]\{2\}/:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/RURSKQ56/how-to-apply-naive-bayes-classifiers-to-document-classification-problems.html:text/html}
}

@online{206-105_design_????,
	title = {Design Patterns in Haskell : Inside 206-105},
	url = {http://blog.ezyang.com/2010/05/design-patterns-in-haskel/},
	shorttitle = {Design Patterns in Haskell},
	author = {206-105, Inside},
	urldate = {2014-03-11},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/G9FH7J3A/design-patterns-in-haskel.html:text/html}
}

@article{_introduction_????-1,
	title = {An Introduction to Scenario Testing},
	file = {Microsoft Word - scenario intro ver4.doc - scenario2.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/T26D3FRC/scenario2.pdf:application/pdf}
}

@article{_tumbleweed_2007,
	location = {New York, United States},
	title = {Tumbleweed Predicts 2007 as Year of Corporate Data Leakage Concerns and Continued Growth of Profit-Driven Spam},
	rights = {Copyright Business Wire 2007},
	url = {http://search.proquest.com.ezproxy1.lib.asu.edu/docview/445108289?pq-origsite=summon},
	pages = {n/a},
	journaltitle = {Business Wire},
	urldate = {2014-07-19},
	date = {2007-01-11},
	keywords = {Business And Economics},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/34K6MR2U/445108289.html:text/html}
}

@article{gotsman_modular_2013,
	title = {Modular verification of preemptive {OS} kernels},
	volume = {23},
	doi = {10.1017/S0956796813000075},
	abstract = {Most major {OS} kernels today run on multiprocessor systems and are preemptive: it is possible for a process running in the kernel mode to get descheduled. Existing modular techniques for verifying concurrent code are not directly applicable in this setting: they rely on scheduling being implemented correctly, and in a preemptive kernel, the correctness of the scheduler is interdependent with the correctness of the code it schedules. This interdependency is even stronger in mainstream kernels, such as those of Linux, {FreeBSD} or Mac {OS} X, where the scheduler and processes interact in complex ways. We propose the first logic that is able to decompose the verification of preemptive multiprocessor kernel code into verifying the scheduler and the rest of the kernel separately, even in the presence of complex interdependencies between the two components. The logic hides the manipulation of control by the scheduler when reasoning about preemptable code and soundly inherits proof rules from concurrent separation logic to verify it thread-modularly. We illustrate the power of our logic by verifying an example scheduler, which includes some of the key features of the scheduler from Linux 2.6.11 challenging for verification.},
	pages = {452--514},
	issue = {Special Issue 04},
	journaltitle = {Journal of Functional Programming},
	author = {Gotsman, Alexey and Yang, Hongseok},
	date = {2013},
	file = {Cambridge Journals PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/VGA45544/Gotsman and Yang - 2013 - Modular verification of preemptive OS kernels.pdf:application/pdf;Cambridge Journals Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/V8IUDS5F/displayAbstract.html:text/html}
}

@article{kim_twilite:_2014,
	title = {{TWILITE}: A recommendation system for Twitter using a probabilistic model based on latent Dirichlet allocation},
	volume = {42},
	issn = {0306-4379},
	url = {http://www.sciencedirect.com/science/article/pii/S0306437913001646},
	doi = {10.1016/j.is.2013.11.003},
	shorttitle = {{TWILITE}},
	abstract = {Twitter provides search services to help people find users to follow by recommending popular users or the friends of their friends. However, these services neither offer the most relevant users to follow nor provide a way to find the most interesting tweet messages for each user. Recently, collaborative filtering techniques for recommendations based on friend relationships in social networks have been widely investigated. However, since such techniques do not work well when friend relationships are not sufficient, we need to take advantage of as much other information as possible to improve the performance of recommendations.

In this paper, we propose {TWILITE}, a recommendation system for Twitter using probabilistic modeling based on latent Dirichlet allocation which recommends top-K users to follow and top-K tweets to read for a user. Our model can capture the realistic process of posting tweet messages by generalizing an {LDA} model as well as the process of connecting to friends by utilizing matrix factorization. We next develop an inference algorithm based on the variational {EM} algorithm for learning model parameters. Based on the estimated model parameters, we also present effective personalized recommendation algorithms to find the users to follow as well as the interesting tweet messages to read. The performance study with real-life data sets confirms the effectiveness of the proposed model and the accuracy of our personalized recommendations.},
	pages = {59--77},
	journaltitle = {Information Systems},
	shortjournal = {Information Systems},
	author = {Kim, Younghoon and Shim, Kyuseok},
	urldate = {2014-07-16},
	date = {2014-06},
	keywords = {Collaborative filtering, {LDA}, Matrix factorization, Probabilistic model, Recommendation system, Twitter},
	file = {ScienceDirect Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/SK3G23M2/Kim and Shim - 2014 - TWILITE A recommendation system for Twitter using.pdf:application/pdf;ScienceDirect Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/KQQZ6Z9G/S0306437913001646.html:text/html}
}

@online{_anatomy_????,
	title = {Anatomy of a C++ Class},
	url = {http://www.public.asu.edu/~jlwrigh1/lecture/AnatomyOfC++.html#1},
	urldate = {2014-02-05},
	file = {Anatomy of a C++ Class:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/KBQGI7UU/AnatomyOfC++.html:text/html}
}

@book{knight_risk_1921,
	title = {Risk, uncertainty and profit,},
	url = {http://hdl.handle.net/2027/loc.ark:/13960/t2j687w8t},
	publisher = {[Boston and New York,},
	author = {Knight, Frank H.},
	date = {1921},
	file = {Risk, uncertainty and profit, . - Full View | HathiTrust Digital Library | HathiTrust Digital Library:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/U6KB86PN/pt.html:text/html}
}

@inproceedings{buduru_cloudassure:_2013,
	location = {Tempe, {AZ}},
	title = {{CloudAssure}: A Data Transfer Decision Framework for Cloud-based Systems using Dynamic Trust Metrics},
	eventtitle = {{ASU} Information Assurance Conference},
	author = {Buduru, Arun Balaji and Lucero, David and Wright, Jeremy},
	date = {2013-04-08}
}

@inreference{_stars_2014,
	title = {Stars and bars (combinatorics)},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {http://en.wikipedia.org/w/index.php?title=Stars_and_bars_(combinatorics)&oldid=594472616},
	abstract = {In the context of combinatorial mathematics, stars and bars is a graphical aid for deriving certain combinatorial theorems. It was popularized by William Feller in his classic book on probability. It can be used to solve many simple counting problems, such as how many ways there are to put k indistinguishable balls into n distinguishable bins.[1]},
	booktitle = {Wikipedia, the free encyclopedia},
	urldate = {2014-03-15},
	date = {2014-02-16},
	langid = {english},
	note = {Page Version {ID}: 594472616},
	keywords = {problem 39},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/IX5I2DZJ/index.html:text/html}
}

@article{healy_governance_2002,
	title = {Governance and intermediation problems in capital markets: Evidence from the fall of Enron},
	url = {http://papers.ssrn.com.ezproxy1.lib.asu.edu/sol3/papers.cfm?abstract_id=325440},
	shorttitle = {Governance and intermediation problems in capital markets},
	author = {Healy, Paul M. and Palepu, Krishna},
	urldate = {2014-06-19},
	date = {2002},
	file = {[PDF] from itrevizija.ba:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/58FIAPU2/Healy and Palepu - 2002 - Governance and intermediation problems in capital .pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/XE6RN7XF/papers.html:text/html}
}

@article{jahanbakhsh_predictive_2014,
	title = {The Predictive Power of Social Media: On the Predictability of U.S. Presidential Elections using Twitter},
	url = {http://arxiv.org/abs/1407.0622},
	shorttitle = {The Predictive Power of Social Media},
	abstract = {Twitter as a new form of social media potentially contains useful information that opens new opportunities for content analysis on tweets. This paper examines the predictive power of Twitter regarding the {US} presidential election of 2012. For this study, we analyzed 32 million tweets regarding the {US} presidential election by employing a combination of machine learning techniques. We devised an advanced classifier for sentiment analysis in order to increase the accuracy of Twitter content analysis. We carried out our analysis by comparing Twitter results with traditional opinion polls. In addition, we used the Latent Dirichlet Allocation model to extract the underlying topical structure from the selected tweets. Our results show that we can determine the popularity of candidates by running sentiment analysis. We can also uncover candidates popularities in the {US} states by running the sentiment analysis algorithm on geo-tagged tweets. To the best of our knowledge, no previous work in the field has presented a systematic analysis of a considerable number of tweets employing a combination of analysis techniques by which we conducted this study. Thus, our results aptly suggest that Twitter as a well-known social medium is a valid source in predicting future events such as elections. This implies that understanding public opinions and trends via social media in turn allows us to propose a cost- and time-effective way not only for spreading and sharing information, but also for predicting future events.},
	journaltitle = {{arXiv}:1407.0622 [physics]},
	author = {Jahanbakhsh, Kazem and Moon, Yumi},
	urldate = {2014-07-16},
	date = {2014-07-01},
	eprinttype = {arxiv},
	eprint = {1407.0622},
	keywords = {Computer Science - Computers and Society, Computer Science - Social and Information Networks, Physics - Physics and Society},
	file = {arXiv\:1407.0622 PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/FFXUDWE4/Jahanbakhsh and Moon - 2014 - The Predictive Power of Social Media On the Predi.pdf:application/pdf;arXiv.org Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/UW6S2JKH/1407.html:text/html}
}

@online{cisco_data_2008,
	title = {Data Leakage Worldwide White Paper: The High Cost of Insider Threats},
	url = {http://cisco.com/c/en/us/solutions/collateral/enterprise-networks/data-loss-prevention/white_paper_c11-506224.html},
	shorttitle = {Data Leakage Worldwide White Paper},
	abstract = {This white paper investigates the business and technical issues pertaining to a platform, solution, or technology and examine its technical implications within the overall network architecture.},
	titleaddon = {Cisco},
	author = {Cisco},
	urldate = {2014-09-08},
	date = {2008},
	file = {Data Leakage Worldwide White Paper\: The High Cost of Insider Threats - white_paper_c11-506224.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/KJDS7IIF/white_paper_c11-506224.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/SRB6HWQU/white_paper_c11-506224.html:text/html}
}

@inproceedings{chang_libsvm_2011,
	title = {{LIBSVM} : a library for support vector machines},
	pages = {2:27:1--27:27},
	booktitle = {{ACM} Transactions on Intelligent Systems and Technology},
	author = {Chang, C.-C. and Lin, C.-J.},
	date = {2011}
}

@unpublished{lorenzo_alberton_graphs_????,
	title = {Graphs in the Database: Rdbms In The Social Networks Age},
	rights = {© All Rights Reserved},
	url = {http://www.slideshare.net/quipo/rdbms-in-the-social-networks-age},
	shorttitle = {Graphs in the Database},
	abstract = {Despite the {NoSQL} movement trying to flag traditional databases as a dying breed, the {RDBMS} keeps evolving and adding new powerful weapons to its arsenal. In this talk we'll explore Common Table Expressions ({SQL}-99) and how {SQL} handles recursion, breaking the bi-dimensional barriers and paving the way to more complex data structures like trees and graphs, and how we can replicate features from social networks and recommendation systems. We'll also have a look at window functions ({SQL}:2003) and the advanced reporting features they make finally possible.},
	type = {Technology},
	howpublished = {Technology},
	author = {{Lorenzo Alberton}},
	urldate = {2014-09-09}
}

@misc{_palladian-0.10-documentation.pdf_????,
	title = {palladian-0.10-documentation.pdf},
	url = {http://palladian.ws/downloads/palladian-0.10-documentation.pdf},
	file = {palladian-0.10-documentation.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/87JZPNDR/palladian-0.10-documentation.pdf:application/pdf}
}

@inproceedings{varadharajan_trust2:_2005,
	title = {Trust2: Developing trust in peer-to-peer environments},
	pages = {24--31},
	booktitle = {In Proceedings of 2005 {IEEE} International Conference on Services Computing ({SCC} 2005)},
	author = {Varadharajan, Y. Wang {\textbackslash}\& V.},
	date = {2005-07}
}

@online{richardson_beautiful_2013,
	title = {Beautiful Soup: We called him Tortoise because he taught us.},
	url = {http://www.crummy.com/software/BeautifulSoup/},
	author = {Richardson, Leonard},
	urldate = {2014-02-10},
	date = {2013-10-18},
	file = {Beautiful Soup\: We called him Tortoise because he taught us.:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/I7XMN54M/BeautifulSoup.html:text/html}
}

@inproceedings{doumit_semantic_2011,
	title = {Semantic knowledge inference from online news media using an {LDA}-{NLP} approach},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=6033626},
	pages = {3068--3071},
	booktitle = {Neural Networks ({IJCNN}), The 2011 International Joint Conference on},
	publisher = {{IEEE}},
	author = {Doumit, Sarjoun and Minai, Ali},
	urldate = {2014-02-05},
	date = {2011},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/2W7GTFIM/login.html:text/html}
}

@online{_questions_????,
	title = {Questions To Ask Before Quitting Your Job To Work At A Startup},
	url = {https://www.linkedin.com/today/post/article/20140805063038-155853-questions-to-ask-before-quitting-your-job-to-work-at-a-startup},
	abstract = {Twice in my career I have left corporate jobs for startups. The first time I left was because I wanted to be in an innovative work environment where we would be inventing and creating technology that},
	urldate = {2014-08-06},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/W24B9VZD/20140805063038-155853-questions-to-ask-before-quitting-your-job-to-work-at-a-startup.html:text/html}
}

@online{_how_????-4,
	title = {How Not To Sort By Average Rating},
	url = {http://www.evanmiller.org/how-not-to-sort-by-average-rating.html},
	urldate = {2014-03-11},
	file = {How Not To Sort By Average Rating:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/U5K93ES6/how-not-to-sort-by-average-rating.html:text/html}
}

@article{mccallum_topic_2007,
	title = {Topic and role discovery in social networks with experiments on enron and academic email.},
	volume = {30},
	url = {http://www.aaai.org/Papers/JAIR/Vol30/JAIR-3007.pdf},
	pages = {249--272},
	journaltitle = {J. Artif. Intell. Res.({JAIR})},
	author = {{McCallum}, Andrew and Wang, Xuerui and Corrada-Emmanuel, Andrés},
	urldate = {2014-06-22},
	date = {2007},
	file = {[PDF] from sri.com:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/Z3CDSE34/McCallum et al. - 2007 - Topic and role discovery in social networks with e.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/6B9WMENQ/JAIR-3007.pdf:application/pdf}
}

@online{_6.2._????,
	title = {6.2. Faster: producing a program that runs quicker},
	url = {http://www.haskell.org/ghc/docs/latest/html/users_guide/faster.html},
	urldate = {2014-03-11},
	file = {6.2. Faster\: producing a program that runs quicker:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/KNKI6VHS/faster.html:text/html}
}

@online{wright_smaller_2013,
	title = {"Smaller" Reviews are More Effective},
	url = {http://www.codestrokes.com/2013/10/smaller-reviews-are-more-effective/},
	titleaddon = {Code Strokes},
	author = {Wright, Jeremy},
	urldate = {2014-02-05},
	date = {2013-10-13},
	keywords = {Review},
	file = {“Smaller” Reviews are More Effective | Code Strokes:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/AC7WNZ5A/smaller-reviews-are-more-effective.html:text/html}
}

@inproceedings{kirubakaran_mobile_2013,
	title = {Mobile application testing \#x2014; Challenges and solution approach through automation},
	doi = {10.1109/ICPRIME.2013.6496451},
	abstract = {By the time this paper has been presented, the mobile app landscape will have changed. New {OS} versions will have been released. A bunch of new devices will have hit the market. And mobile application testing will have become that much more complex and challenging for all of us. There is no doubt that mobile applications need specific testing approaches. This paper wants to investigate new directions in research on the type of testing and skills required on mobile app testing by answering the following three research questions: ({RQ}1) How mobile applications testing are so different from traditional web applications, that require specialized testing skills and techniques?, ({RQ}2) What are the new challenges and future trends in mobile application testing, and ({RQ}3) How far automation effective in testing mobile application?. We answer those questions by analyzing the current trends in mobile application development and testing, and by proposing my view on the topic.},
	eventtitle = {2013 International Conference on Pattern Recognition, Informatics and Mobile Engineering ({PRIME})},
	pages = {79--84},
	booktitle = {2013 International Conference on Pattern Recognition, Informatics and Mobile Engineering ({PRIME})},
	author = {Kirubakaran, B. and Karthikeyani, V.},
	date = {2013-02},
	keywords = {automation, mobile application development, mobile application landscape, mobile applications, mobile application testing, Mobile Computing, operating systems, operating systems (computers), {OS} version, program testing, software testing, testing approach, Web application},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/MN2A3ZIE/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/QMT3P4KW/Kirubakaran and Karthikeyani - 2013 - Mobile application testing #x2014\; Challenges and .pdf:application/pdf}
}

@article{coffee_jr_what_2003,
	title = {What Caused Enron-A Capsule Social and Economic History of the 1990s},
	volume = {89},
	url = {http://heinonlinebackup.com/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/clqv89&section=16},
	pages = {269},
	journaltitle = {Cornell L. Rev.},
	author = {Coffee Jr, John C.},
	urldate = {2014-06-19},
	date = {2003},
	file = {[DOC] from utoronto.ca:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/GSDK7ZUN/Coffee Jr - 2003 - What Caused Enron-A Capsule Social and Economic Hi.doc:application/msword;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/A8DJUC8K/get_pdf.html:text/html}
}

@article{roussinov_scalable_1998,
	title = {A scalable self-organizing map algorithm for textual classification: A neural network approach to thesaurus generation},
	url = {http://arizona.openrepository.com/arizona/handle/10150/106141},
	shorttitle = {A scalable self-organizing map algorithm for textual classification},
	author = {Roussinov, Dmitri G. and Chen, Hsinchun},
	urldate = {2014-09-08},
	date = {1998},
	file = {[HTML] from openrepository.com:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/GMGMKSHW/A_Scalable-98.html:text/html;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/5ZRCPE6T/106141.html:text/html}
}

@online{_okws/okws_????,
	title = {okws/okws},
	url = {https://github.com/okws/okws},
	abstract = {okws - The {OK} Web Server},
	titleaddon = {{GitHub}},
	urldate = {2014-03-11},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/QXHKTUBI/okws.html:text/html}
}

@software{hipp_sqlite_2014,
	title = {{SQLite}},
	rights = {Public Domain},
	url = {http://www.sqlite.org/},
	abstract = {{SQLite} is an in-process library that implements a self-contained, serverless, zero-configuration, transactional {SQL} database engine. The code for {SQLite} is in the public domain and is thus free for use for any purpose, commercial or private. {SQLite} is currently found in more applications than we can count, including several high-profile projects.},
	version = {3.7.17},
	publisher = {{SQLite}},
	author = {Hipp, D. Richard},
	urldate = {2013-06-01},
	date = {2014-05-20}
}

@article{katakis_tracking_2010,
	title = {Tracking recurring contexts using ensemble classifiers: an application to email filtering},
	volume = {22},
	issn = {0219-1377, 0219-3116},
	url = {http://link.springer.com.ezproxy1.lib.asu.edu/article/10.1007/s10115-009-0206-2},
	doi = {10.1007/s10115-009-0206-2},
	shorttitle = {Tracking recurring contexts using ensemble classifiers},
	abstract = {Concept drift constitutes a challenging problem for the machine learning and data mining community that frequently appears in real world stream classification problems. It is usually defined as the unforeseeable concept change of the target variable in a prediction task. In this paper, we focus on the problem of recurring contexts, a special sub-type of concept drift, that has not yet met the proper attention from the research community. In the case of recurring contexts, concepts may re-appear in future and thus older classification models might be beneficial for future classifications. We propose a general framework for classifying data streams by exploiting stream clustering in order to dynamically build and update an ensemble of incremental classifiers. To achieve this, a transformation function that maps batches of examples into a new conceptual representation model is proposed. The clustering algorithm is then applied in order to group batches of examples into concepts and identify recurring contexts. The ensemble is produced by creating and maintaining an incremental classifier for every concept discovered in the data stream. An experimental study is performed using (a) two new real-world concept drifting datasets from the email domain, (b) an instantiation of the proposed framework and (c) five methods for dealing with drifting concepts. Results indicate the effectiveness of the proposed representation and the suitability of the concept-specific classifiers for problems with recurring contexts.},
	pages = {371--391},
	number = {3},
	journaltitle = {Knowledge and Information Systems},
	shortjournal = {Knowl Inf Syst},
	author = {Katakis, Ioannis and Tsoumakas, Grigorios and Vlahavas, Ioannis},
	urldate = {2014-06-19},
	date = {2010-03-01},
	langid = {english},
	keywords = {Business Information Systems, Information Systems and Communication Service},
	file = {Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/2MKI52EV/Katakis et al. - 2010 - Tracking recurring contexts using ensemble classif.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/AR9JPCSD/s10115-009-0206-2.html:text/html}
}

@inproceedings{tondel_learning_2008,
	title = {Learning from Software Security Testing},
	doi = {10.1109/ICSTW.2008.25},
	abstract = {Software security testing tools and methodologies are presently abundant, and the question no longer seems to be "if to test" for security, but rather "where and when to test" and "then what?". In this paper we present a review of security testing literature, and propose a software security testing scheme that exploits an intra-organisational repository of discovered vulnerabilities that closes the loop after the testing of one application is complete, providing useful input to the next application to be tested.},
	eventtitle = {{IEEE} International Conference on Software Testing Verification and Validation Workshop, 2008. {ICSTW} '08},
	pages = {286--294},
	booktitle = {{IEEE} International Conference on Software Testing Verification and Validation Workshop, 2008. {ICSTW} '08},
	author = {Tondel, {IA} and Jaatun, M.G. and Jensen, J.},
	date = {2008-04},
	keywords = {Application software, Communications technology, Information security, Internet, intra-organisational repository, Programming, program testing, Quality assurance, security of data, Software performance, software products, Software safety, software security testing, software testing, Software tools},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/9JHPQJBA/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/44GMAARX/Tondel et al. - 2008 - Learning from Software Security Testing.pdf:application/pdf}
}

@online{_high_????,
	title = {High Scalability - High Scalability - Justin.tv's Live Video Broadcasting Architecture},
	url = {http://highscalability.com/blog/2010/3/16/justintvs-live-video-broadcasting-architecture.html},
	urldate = {2014-03-11},
	file = {High Scalability - High Scalability - Justin.tv's Live Video Broadcasting Architecture:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/8IK8RSQ8/justintvs-live-video-broadcasting-architecture.html:text/html}
}

@inproceedings{savola_identification_2009,
	title = {Identification of Basic Measurable Security Components for a Distributed Messaging System},
	doi = {10.1109/SECURWARE.2009.26},
	abstract = {The lack of appropriate information security solutions in software intensive systems can have serious consequences for businesses and the stakeholders. Carefully designed security metrics can be used to offer evidence of the security behavior of the system under development or operation. This study investigates holistic development of security metrics for a distributed messaging system based on threat analysis, security requirements, decomposition and use case information. Our approach is thus requirement centric. The highlevel security requirements are expressed in terms of lower level measurable components applying a decomposition approach.},
	eventtitle = {Third International Conference on Emerging Security Information, Systems and Technologies, 2009. {SECURWARE} '09},
	pages = {121--128},
	booktitle = {Third International Conference on Emerging Security Information, Systems and Technologies, 2009. {SECURWARE} '09},
	author = {Savola, R.M. and Abie, Habtamu},
	date = {2009-06},
	keywords = {Appropriate technology, Distributed information systems, distributed messaging system, distributed processing, Genetics, Information analysis, Information security, Information systems, Iterative methods, measurable security components, Message-oriented middleware, messaging systems, Monitoring, Resilience, risk analysis, security metrics, security of data, security requirements, threat analysis},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/7SQHVKFF/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/DCCJX2KZ/Savola and Abie - 2009 - Identification of Basic Measurable Security Compon.pdf:application/pdf}
}

@article{_trustworthiness-based_????,
	title = {A Trustworthiness-Based Distribution Model for Data Leakage Prevention},
	file = {art%3A10.1007%2Fs11859-010-0305-7.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/WZ3HUXSS/art%3A10.1007%2Fs11859-010-0305-7.pdf:application/pdf}
}

@inproceedings{ramos_using_2003,
	title = {Using tf-idf to determine word relevance in document queries},
	url = {https://www.cs.rutgers.edu/~mlittman/courses/ml03/iCML03/papers/ramos.pdf},
	booktitle = {Proceedings of the First Instructional Conference on Machine Learning},
	author = {Ramos, Juan},
	urldate = {2014-09-14},
	date = {2003},
	file = {[PDF] from rutgers.edu:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/RDMWSZ32/Ramos - 2003 - Using tf-idf to determine word relevance in docume.pdf:application/pdf}
}

@online{_mathias_????,
	title = {Mathias Hasselmann - Taschenorakel.de},
	url = {http://taschenorakel.de/mathias/2012/04/18/fulltext-search-benchmarks/},
	urldate = {2014-02-05},
	file = {Mathias Hasselmann - Taschenorakel.de:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/EM3A9SQS/fulltext-search-benchmarks.html:text/html}
}

@inproceedings{jang_semantic_2012,
	title = {Semantic Social Networks Constructed by Topical Aspects of Conversations: An Explorative Study.},
	url = {http://www.aaai.org/ocs/index.php/ICWSM/ICWSM12/paper/download/4606/5039},
	shorttitle = {Semantic Social Networks Constructed by Topical Aspects of Conversations},
	booktitle = {{ICWSM}},
	author = {Jang, Jiyeon and Choi, Jinhyuk and Jang, Gwan and Myaeng, Sung-Hyon},
	urldate = {2014-02-05},
	date = {2012},
	file = {[PDF] from kaist.ac.kr:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/XB4KTRA3/Jang et al. - 2012 - Semantic Social Networks Constructed by Topical As.pdf:application/pdf}
}

@inproceedings{sun_trust_2006,
	title = {A trust evaluation framework in distributed networks: Vulnerability analysis and defense against attacks},
	doi = {10.1109/INFOCOM.2006.154},
	shorttitle = {A trust evaluation framework in distributed networks},
	abstract = {Not Available},
	eventtitle = {{INFOCOM} 2006. 25th {IEEE} International Conference on Computer Communications. Proceedings},
	pages = {1--13},
	booktitle = {{INFOCOM} 2006. 25th {IEEE} International Conference on Computer Communications. Proceedings},
	author = {Sun, Y.L. and Han, Zhu and Yu, Wei and Liu, K.J.R.},
	date = {2006-04},
	keywords = {ad hoc networks, Authentication, Collaboration, Communication system security, Computational modeling, computer architecture, Computer networks, Educational institutions, Public key},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/FD7DD84Q/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/HIJ4WVTA/Sun et al. - 2006 - A trust evaluation framework in distributed networ.pdf:application/pdf}
}

@inproceedings{zilberman_analyzing_2011,
	title = {Analyzing group communication for preventing data leakage via email},
	doi = {10.1109/ISI.2011.5984047},
	abstract = {Modern business activities rely on extensive email exchange. Various solutions attempt to analyze email exchange in order to prevent emails from being sent to the wrong recipients. However there are still no satisfying solutions; many email addressing mistakes are not detected and in many cases correct recipients are wrongly marked as potential addressing mistakes. In this paper we present a new approach for preventing emails addressing mistakes in organizations. The approach is based on analysis of emails exchange among members of the organization and the identification of groups based on common topics. Each member's topics are then used during the enforcement phase for detecting potential leakage. When a new email is composed and about to be sent, each email recipient is analyzed. A recipient is approved if the email's content belongs to at least one of the topics common to the sender and the recipient. We evaluated the new approach using the Enron Email dataset. Our evaluation results suggest that the new approach easily copes with email recipients that have no previous direct connection with the sender.},
	eventtitle = {2011 {IEEE} International Conference on Intelligence and Security Informatics ({ISI})},
	pages = {37--41},
	booktitle = {2011 {IEEE} International Conference on Intelligence and Security Informatics ({ISI})},
	author = {Zilberman, P. and Dolev, S. and Katz, G. and Elovici, Y. and Shabtai, A},
	date = {2011-07},
	keywords = {Classification algorithms, data leakage, data leakage prevention, Electronic mail, e-mail addressing mistakes, emails analysis, Enron e-mail dataset, group communication, organization security, security of data},
	file = {Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/AWBSGRZN/Zilberman et al. - 2013 - Analyzing group E-mail exchange to detect data lea.pdf:application/pdf;IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/PZM6Q4UJ/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/5F64PGAI/Zilberman et al. - 2011 - Analyzing group communication for preventing data .pdf:application/pdf;[PDF] from usenix.org:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/W3CAEDDH/Zilberman et al. - 2011 - Analyzing group communication for preventing data .pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/9Z94USNH/login.html:text/html}
}

@inproceedings{blei_dynamic_2006,
	title = {Dynamic topic models},
	url = {http://dl.acm.org/citation.cfm?id=1143859},
	pages = {113--120},
	booktitle = {Proceedings of the 23rd international conference on Machine learning},
	publisher = {{ACM}},
	author = {Blei, David M. and Lafferty, John D.},
	urldate = {2014-10-12},
	date = {2006},
	file = {[PDF] from cmu.edu:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/XQ3Q99V5/Blei and Lafferty - 2006 - Dynamic topic models.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/6SG6DMT4/citation.html:text/html}
}

@online{_scotts_????,
	title = {Scott's Space - Quotes About C++},
	url = {http://www.stgray.com/quotes/cppquotes.html},
	urldate = {2014-02-05},
	file = {Scott's Space - Quotes About C++:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/VFHTEWDI/cppquotes.html:text/html}
}

@online{_testingbestpractices_????,
	title = {{TestingBestPractices} - {TestingBestPractice}.pdf},
	url = {http://www.cs.ucf.edu/~turgut/COURSES/EEL5881_SEI_Fall03/TestingBestPractice.pdf},
	urldate = {2014-08-24},
	file = {TestingBestPractices - TestingBestPractice.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/HR6ZH67W/TestingBestPractice.pdf:application/pdf}
}

@misc{_generic-graph-algorithms.pdf_????,
	title = {generic-graph-algorithms.pdf},
	file = {generic-graph-algorithms.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/DFQN9983/generic-graph-algorithms.pdf:application/pdf}
}

@inproceedings{chang_reading_2009,
	title = {Reading tea leaves: How humans interpret topic models},
	url = {http://machinelearning.wustl.edu/mlpapers/paper_files/NIPS2009_0125.pdf},
	shorttitle = {Reading tea leaves},
	pages = {288--296},
	booktitle = {Advances in neural information processing systems},
	author = {Chang, Jonathan and Gerrish, Sean and Wang, Chong and Boyd-graber, Jordan L. and Blei, David M.},
	urldate = {2014-09-14},
	date = {2009},
	file = {[PDF] from wustl.edu:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/4PKBJZEA/Chang et al. - 2009 - Reading tea leaves How humans interpret topic mod.pdf:application/pdf}
}

@online{bishop_introduction_2009,
	title = {Introduction To Bayesian Inference},
	url = {http://videolectures.net/mlss09uk_bishop_ibi/},
	author = {Bishop, Chris},
	urldate = {2014-09-08},
	date = {2009-11},
	file = {mlss09uk_bishop_ibi_01.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/RP8M9TP9/mlss09uk_bishop_ibi_01.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/HJKT2MUI/mlss09uk_bishop_ibi.html:text/html}
}

@online{_moowahaha/despamilator_????,
	title = {moowahaha/despamilator},
	url = {https://github.com/moowahaha/despamilator},
	abstract = {despamilator - spam detection in text, made specifically for web forms},
	titleaddon = {{GitHub}},
	urldate = {2014-02-10},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/Z2HNEHNV/despamilator.html:text/html}
}

@article{spivey_when_2012,
	title = {When Maybe is not good enough},
	volume = {22},
	doi = {10.1017/S0956796812000329},
	pages = {747--756},
	number = {6},
	journaltitle = {Journal of Functional Programming},
	author = {Spivey, Michael},
	date = {2012},
	file = {Cambridge Journals PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/IIJC2GKF/Spivey - 2012 - When Maybe is not good enough.pdf:application/pdf;Cambridge Journals Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/CQA6D2U8/displayAbstract.html:text/html}
}

@online{_doe_????,
	title = {{DOE} in Software Testing: The Potential and the Risks},
	url = {http://www.isixsigma.com/tools-templates/design-of-experiments-doe/doe-software-testing-potential-and-risks/},
	shorttitle = {{DOE} in Software Testing},
	abstract = {While statistical approaches to software testing like {DOE} do hold promise, those who use them need to understand them in a balanced way  looking for where they},
	urldate = {2014-09-13},
	keywords = {design of experiments, doe, six sigma, software, software design factorials},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/CMZ4BJPA/doe-software-testing-potential-and-risks.html:text/html}
}

@online{_mq_2010,
	title = {{MQ} Telemetry Transport ({MQTT}) V3.1 Protocol Specification},
	rights = {© Copyright {IBM} Corporation 2010},
	url = {http://www.ibm.com/developerworks/webservices/library/ws-mqtt/index.html},
	type = {{CT}316},
	urldate = {2014-10-13},
	date = {2010-08-19},
	langid = {english},
	keywords = {{SW}666, {TT}700},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/GREEIDMU/2010 - MQ Telemetry Transport (MQTT) V3.1 Protocol Specif.html:text/html}
}

@article{denoyer_bayesian_2004,
	title = {Bayesian network model for semi-structured document classification},
	journaltitle = {Information Processing and Management},
	author = {Denoyer and Ludovic and Gallinari and Patrick},
	date = {2004-06}
}

@inproceedings{marecki_decision_2010,
	title = {A Decision Theoretic Approach to Data Leakage Prevention},
	doi = {10.1109/SocialCom.2010.119},
	abstract = {In both the commercial and defense sectors a compelling need is emerging for rapid, yet secure, dissemination of information. In this paper we address the threat of information leakage that often accompanies such information flows. We focus on domains with one information source (sender) and many information sinks (recipients) where: (i) sharing is mutually beneficial for the sender and the recipients, (ii) leaking a shared information is beneficial to the recipients but undesirable to the sender, and (iii) information sharing decisions of the sender are determined using imperfect monitoring of the (un)intended information leakage by the recipients. We make two key contributions in this context: First, we formulate data leakage prevention problems as Partially Observable Markov Decision Processes; we show how to encode one sample monitoring mechanism - digital watermarking - into our model. Second, we derive optimal information sharing strategies for the sender and optimal information leakage strategies for a rational-malicious recipient as a function of the efficacy of the monitoring mechanism. We believe that our approach offers a first of a kind solution for addressing complex information sharing problems under uncertainty.},
	eventtitle = {2010 {IEEE} Second International Conference on Social Computing ({SocialCom})},
	pages = {776--784},
	booktitle = {2010 {IEEE} Second International Conference on Social Computing ({SocialCom})},
	author = {Marecki, J. and Srivatsa, M. and Varakantham, P.},
	date = {2010-08},
	keywords = {Accuracy, data leakage prevention, data leakage prevention problems, decision theoretic approach, decision theory, digital watermarking, Electronic mail, information dissemination, information flows, information leakage, information sharing decisions, information sinks, Markov processes, Monitoring, Organizations, partially observable Markov decision process, Partially observable Markov decision processes, rational-malicious recipient, security of data, watermarking},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/5FQSTS2Q/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/5W4ABWF2/Marecki et al. - 2010 - A Decision Theoretic Approach to Data Leakage Prev.pdf:application/pdf}
}

@article{diesner_communication_2005,
	title = {Communication Networks from the Enron Email Corpus “It's Always About the People. Enron is no Different”},
	volume = {11},
	issn = {1381-298X, 1572-9346},
	url = {http://link.springer.com.ezproxy1.lib.asu.edu/article/10.1007/s10588-005-5377-0},
	doi = {10.1007/s10588-005-5377-0},
	abstract = {The Enron email corpus is appealing to researchers because it represents a rich temporal record of internal communication within a large, real-world organization facing a severe and survival-threatening crisis. We describe how we enhanced the original corpus database and present findings from our investigation undertaken with a social network analytic perspective. We explore the dynamics of the structure and properties of the organizational communication network, as well as the characteristics and patterns of communicative behavior of the employees from different organizational levels. We found that during the crisis period, communication among employees became more diverse with respect to established contacts and formal roles. Also during the crisis period, previously disconnected employees began to engage in mutual communication, so that interpersonal communication was intensified and spread through the network, bypassing formal chains of communication. The findings of this study provide valuable insight into a real-world organizational crisis, which may be further used for validating or developing theories and dynamic models of organizational crises; thereby leading to a better understanding of the underlying causes of, and response to, organization failure.},
	pages = {201--228},
	number = {3},
	journaltitle = {Computational \& Mathematical Organization Theory},
	shortjournal = {Comput Math Organiz Theor},
	author = {Diesner, Jana and Frantz, Terrill L. and Carley, Kathleen M.},
	urldate = {2014-06-19},
	date = {2005-10-01},
	langid = {english},
	keywords = {Artificial Intelligence (incl. Robotics), communication networks, dynamic network analysis, email corpus, Enron, Management, Methodology of the Social Sciences, Operations Research/Decision Theory, organizational crisis, organizational hierarchy, social network analysis, Sociology},
	file = {Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/QRB88W4J/Diesner et al. - 2005 - Communication Networks from the Enron Email Corpus.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/GRGQAJN9/s10588-005-5377-0.html:text/html}
}

@online{_freestore_????,
	title = {Freestore management, C++ {FAQ}},
	url = {http://www.parashift.com/c++-faq-lite/freestore-mgmt.html},
	urldate = {2014-02-05},
	file = {Freestore management, C++ FAQ:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/HW7ZHIS2/freestore-mgmt.html:text/html}
}

@inproceedings{stumpf_toward_2007,
	location = {New York, {NY}, {USA}},
	title = {Toward Harnessing User Feedback for Machine Learning},
	isbn = {1-59593-481-2},
	url = {http://doi.acm.org/10.1145/1216295.1216316},
	doi = {10.1145/1216295.1216316},
	series = {{IUI} '07},
	abstract = {There has been little research into how end users might be able to communicate advice to machine learning systems. If this resource--the users themselves--could somehow work hand-in-hand with machine learning systems, the accuracy of learning systems could be improved and the users' understanding and trust of the system could improve as well. We conducted a think-aloud study to see how willing users were to provide feedback and to understand what kinds of feedback users could give. Users were shown explanations of machine learning predictions and asked to provide feedback to improve the predictions. We found that users had no difficulty providing generous amounts of feedback. The kinds of feedback ranged from suggestions for reweighting of features to proposals for new features, feature combinations, relational features, and wholesale changes to the learning algorithm. The results show that user feedback has the potential to significantly improve machine learning systems, but that learning algorithms need to be extended in several ways to be able to assimilate this feedback.},
	pages = {82--91},
	booktitle = {Proceedings of the 12th International Conference on Intelligent User Interfaces},
	publisher = {{ACM}},
	author = {Stumpf, Simone and Rajaram, Vidya and Li, Lida and Burnett, Margaret and Dietterich, Thomas and Sullivan, Erin and Drummond, Russell and Herlocker, Jonathan},
	urldate = {2014-06-19},
	date = {2007},
	keywords = {explanations, machine learning, user feedback for learning},
	file = {ACM Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/QNPJ36Q3/Stumpf et al. - 2007 - Toward Harnessing User Feedback for Machine Learni.pdf:application/pdf}
}

@article{van_noort_lightweight_2010,
	title = {A lightweight approach to datatype-generic rewriting},
	volume = {20},
	doi = {10.1017/S0956796810000183},
	abstract = {Term-rewriting systems can be expressed as generic programs parameterised over the shape of the terms being rewritten. Previous implementations of generic rewriting libraries require users to either adapt the datatypes that are used to describe these terms or to specify rewrite rules as functions. These are fundamental limitations: the former implies a lot of work for the user, while the latter makes it hard if not impossible to document, test, and analyze rewrite rules. In this article, we demonstrate how to overcome these limitations by making essential use of type-indexed datatypes. Our approach is lightweight in that it is entirely expressible in Haskell with {GADTs} and type families and can be readily packaged for use with contemporary Haskell distributions.},
	pages = {375--413},
	issue = {Special Issue 3-4},
	journaltitle = {Journal of Functional Programming},
	author = {Van Noort, Thomas and Rodriguez Yakushev, Alexey and Holdermans, Stefan and Jeuring, Johan and Heeren, Bastiaan and Magalhães, José Pedro},
	date = {2010},
	file = {Cambridge Journals Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/RDA7RC8I/displayAbstract.html:text/html}
}

@online{_projects/tracker_????,
	title = {Projects/Tracker - {GNOME} Wiki!},
	url = {https://wiki.gnome.org/Projects/Tracker},
	urldate = {2014-03-11},
	file = {Projects/Tracker - GNOME Wiki!:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/6RQSXEQ6/Tracker.html:text/html}
}

@software{scipy_scientific_2014,
	title = {Scientific Computing Tools for Python},
	rights = {{BSD} License},
	url = {http://www.scipy.org/about.html},
	shorttitle = {{SciPy}},
	abstract = {{SciPy} refers to several related but distinct entities:

    The {SciPy} Stack, a collection of open source software for scientific computing in Python, and particularly a specified set of core packages.
    The community of people who use and develop this stack.
    Several conferences dedicated to scientific computing in Python - {SciPy}, {EuroSciPy} and {SciPy}.in.
    The {SciPy} library, one component of the {SciPy} stack, providing many numerical routines.},
	version = {0.14.0},
	publisher = {Enthought},
	author = {{SciPy}},
	date = {2014-05-03},
	file = {NumPy — Numpy:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/CD6E5P5H/www.numpy.org.html:text/html}
}

@software{stonebraker_postgresql_2014,
	title = {{PostgreSQL}},
	rights = {{BSD} License},
	url = {http://www.postgresql.org/docs/9.2/static/release-9-2-9.html},
	abstract = {{PostgreSQL} is a powerful, open source object-relational database system. It has more than 15 years of active development and a proven architecture that has earned it a strong reputation for reliability, data integrity, and correctness. It runs on all major operating systems, including Linux, {UNIX} ({AIX}, {BSD}, {HP}-{UX}, {SGI} {IRIX}, Mac {OS} X, Solaris, Tru64), and Windows. It is fully {ACID} compliant, has full support for foreign keys, joins, views, triggers, and stored procedures (in multiple languages). It includes most {SQL}:2008 data types, including {INTEGER}, {NUMERIC}, {BOOLEAN}, {CHAR}, {VARCHAR}, {DATE}, {INTERVAL}, and {TIMESTAMP}. It also supports storage of binary large objects, including pictures, sounds, or video. It has native programming interfaces for C/C++, Java, .Net, Perl, Python, Ruby, Tcl, {ODBC}, among others, and exceptional documentation.},
	version = {9.2.9},
	publisher = {{PostgreSQL}},
	author = {Stonebraker, Michael},
	urldate = {2014-09-29},
	date = {2014-07-24}
}

@online{_official_????-1,
	title = {Official Gmail Blog: “Don't forget Bob” and “Got the wrong Bob?” graduate from Labs},
	url = {http://gmailblog.blogspot.com/2011/04/dont-forget-bob-and-got-wrong-bob.html},
	shorttitle = {Official Gmail Blog},
	urldate = {2014-09-26},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/7QQKSES4/Official Gmail Blog “Don't forget Bob” and “Got t.html:text/html}
}

@article{kumar_digital_2002,
	title = {Digital leakage},
	volume = {59},
	rights = {Copyright Institute of Internal Auditors, Incorporated Dec 2002},
	issn = {00205745},
	url = {http://search.proquest.com.ezproxy1.lib.asu.edu/docview/202744618?pq-origsite=summon},
	abstract = {Ensuring the confidentiality of intellectual property proves difficult when sensitive documents reside in electronic format. Digital leakage can occur in a number of ways, with perhaps the most popular image being an attack from an outside hacker. However, actual incidents are more often committed by those inside an organization. The threat of digital leakage is even more dangerous in times of corporate downsizing. Despite difficulties associated with preventing digital leakage, there are methods companies can use to minimize the problem. Diagnosing the problem is the first step. Companies must be aware of how digital leakage is affecting them and how it can be prevented. Companies have to recognize the benefits of a technology, figure out how to implement it in the most secure way, and craft a policy around it.},
	pages = {25--27},
	number = {6},
	journaltitle = {The Internal Auditor},
	author = {Kumar, Vishesh},
	urldate = {2014-07-19},
	date = {2002-12},
	keywords = {Business And Economics--Accounting, Confidentiality, Document management, Intellectual property, Network security},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/NDJTVGI2/202744618.html:text/html}
}

@online{_file_????,
	title = {File system vs. {SQLite} tile store},
	url = {http://dev.mapproxy.org/misc/tilestorebench/},
	urldate = {2014-03-11},
	file = {File system vs. SQLite tile store:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/R27AEFEQ/tilestorebench.html:text/html}
}

@online{_c++11:_????,
	title = {C++11: Multi-core Programming - {PPL} Parallel Aggregation Explained},
	url = {http://katyscode.wordpress.com/2013/08/17/c11-multi-core-programming-ppl-parallel-aggregation-explained/},
	shorttitle = {C++11},
	abstract = {In the first part of this series we looked at general multi-threading and multi-core programming concepts without getting into the meat of any real problems, and in the second part we looked at the...},
	titleaddon = {Katy's Code},
	urldate = {2014-02-05},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/BB6JFIEI/c11-multi-core-programming-ppl-parallel-aggregation-explained.html:text/html}
}

@online{hoke_host-based_2012,
	title = {Host-Based Detection and Data Loss Prevention Using Open Source Tools},
	url = {http://www.sans.org/reading-room/whitepapers/detection/host-based-detection-data-loss-prevention-open-source-tools-34055},
	abstract = {This paper will explore the feasibility of combining open-source network and host-based
monitoring tools to build a virtualized appliance capable of both detecting common attacks
and serving as an at-rest data loss prevention platform on a host operating system. The
research will explore the performance and functionality impacts of using common open
source tools such as Snort, Suricata, {OpenDLP}, {VMware} Player, and open-source operating
systems to accomplish goals that would otherwise require significant capital outlay to
achieve.},
	titleaddon = {{SANS}},
	author = {Hoke, Christopher},
	urldate = {2014-09-08},
	date = {2012-11-16},
	keywords = {intrusion detection and preventsion systems},
	file = {Host-Based Detection and Data Loss Prevention Using Open Source Tools - host-based-detection-data-loss-prevention-open-source-tools-34055:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/4QNTTHV4/host-based-detection-data-loss-prevention-open-source-tools-34055.pdf:application/pdf}
}

@article{graham-cummings_naive_2005,
	title = {Naive Bayesian Text Classification},
	pages = {16--20},
	journaltitle = {Dr. Dobb's Journal},
	author = {Graham-Cummings, John},
	date = {2005-05}
}

@article{keila_structure_2005,
	title = {Structure in the Enron Email Dataset},
	volume = {11},
	issn = {1381-298X, 1572-9346},
	url = {http://link.springer.com.ezproxy1.lib.asu.edu/article/10.1007/s10588-005-5379-y},
	doi = {10.1007/s10588-005-5379-y},
	abstract = {We investigate the structures present in the Enron email dataset using singular value decomposition and semidiscrete decomposition. Using word frequency profiles, we show that messages fall into two distinct groups, whose extrema are characterized by short messages and rare words versus long messages and common words. It is surprising that length of message and word use pattern should be related in this way. We also investigate relationships among individuals based on their patterns of word use in email. We show that word use is correlated to function within the organization, as expected. Lastly, we show that relative changes to individuals' word usage over time can be used to identify key players in major company events.},
	pages = {183--199},
	number = {3},
	journaltitle = {Computational \& Mathematical Organization Theory},
	shortjournal = {Comput Math Organiz Theor},
	author = {Keila, P. S. and Skillicorn, D. B.},
	urldate = {2014-06-19},
	date = {2005-10-01},
	langid = {english},
	keywords = {Artificial Intelligence (incl. Robotics), data mining, Management, matrix decompositions, Methodology of the Social Sciences, Operations Research/Decision Theory, organizational role, organizational structure, singular value decomposition, Sociology, word frequency},
	file = {Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/E8XWC2DK/Keila and Skillicorn - 2005 - Structure in the Enron Email Dataset.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/HBVDPS3C/s10588-005-5379-y.html:text/html}
}

@inproceedings{groce_help_2013,
	title = {Help, help, i'm being suppressed \#x0021; The significance of suppressors in software testing},
	doi = {10.1109/ISSRE.2013.6698892},
	abstract = {Test features are basic compositional units used to describe what a test does (and does not) involve. For example, in {API}-based testing, the most obvious features are function calls; in grammar-based testing, the obvious features are the elements of the grammar. The relationship between features as abstractions of tests and produced behaviors of the tested program is surprisingly poorly understood. This paper shows how large-scale random testing modified to use diverse feature sets can uncover causal relationships between what a test contains and what the program being tested does. We introduce a general notion of observable behaviors as targets, where a target can be a detected fault, an executed branch or statement, or a complex coverage entity such as a state, predicate-valuation, or program path. While it is obvious that targets have triggers - features without which they cannot be hit by a test - the notion of suppressors - features which make a test less likely to hit a target - has received little attention despite having important implications for automated test generation and program understanding. For a set of subjects including C compilers, a flash file system, and {JavaScript} engines, we show that suppression is both common and important.},
	eventtitle = {2013 {IEEE} 24th International Symposium on Software Reliability Engineering ({ISSRE})},
	pages = {390--399},
	booktitle = {2013 {IEEE} 24th International Symposium on Software Reliability Engineering ({ISSRE})},
	author = {Groce, A. and Zhang, Chaoqiang and Alipour, M.A. and Eide, E. and Chen, Yang and Regehr, J.},
	date = {2013-11},
	keywords = {{API}-based testing, authoring languages, automated test generation, causal relationships, complex coverage entity, compositional units, Computer crashes, Containers, fault detection, fault diagnosis, file organisation, flash file system, Grammar, grammar-based testing, {HTML}, {JavaScript} engines, large-scale random testing, predicate-valuation, program diagnostics, program path, program testing, program understanding, Sociology, software fault tolerance, software testing, Statistics, test features, Testing},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/EBUTGN5T/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/MP6XVKBZ/Groce et al. - 2013 - Help, help, i'm being suppressed #x0021\; The signi.pdf:application/pdf}
}

@inproceedings{rehurek_software_2010,
	title = {Software Framework for Topic Modelling with Large Corpora},
	booktitle = {Proceedings of the {LREC} 2010 Workshop on New Challenges for {NLP} Frameworks},
	author = {Rehurek, Radim and Sojka, Petr},
	date = {2010},
	file = {lrec2010-rehurek-sojka.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/7MDGQRGA/lrec2010-rehurek-sojka.pdf:application/pdf}
}

@video{joe_kava_2011_2011,
	title = {2011 Data Center Efficiency Summit: Joe Kava {\textbar} Google},
	url = {http://www.youtube.com/watch?v=APynRrGuZJA&feature=youtube_gdata_player},
	shorttitle = {2011 Data Center Efficiency Summit},
	abstract = {In this presentation, you'll hear from Google's Joe Kava on "Central Network Room ({CNR}) {PUE} Efficiency Project - A True Story."

This talk was given at the 2011 Data Centre Efficiency Summit held on May 24 in Zürich, Switzerland.

For more information on Google's approach to data center efficiency and to view best practices that all data center practioners can apply immediately, visit our website at http://www.google.com/corporate/datacenter/index.html.},
	editora = {{Joe Kava}},
	editoratype = {collaborator},
	urldate = {2014-09-05},
	date = {2011-06-04}
}

@article{zhang_neural_2000,
	title = {Neural Networks for Classification: A Survey},
	volume = {30},
	number = {4},
	journaltitle = {{IEEE} Transactions on Systems, Man and Cybernetics},
	author = {Zhang, Guoqiang Peter},
	date = {2000},
	keywords = {classification, conventional classifiers, Costs, Decision making, feature variable selection, generalisation (artificial intelligence), generalization, Humans, Input variables, learning, learning (artificial intelligence), Medical diagnosis, Medical diagnostic imaging, misclassification costs, Network synthesis, neural classifiers, neural nets, neural networks, pattern classification, posterior probability estimation, Probability, Speech recognition},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/86TH2Z98/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/2H9PQJ7C/Zhang - 2000 - Neural networks for classification a survey.pdf:application/pdf}
}

@article{nykanen_note_2011,
	title = {A note on the genuine Sieve of Eratosthenes},
	volume = {21},
	doi = {10.1017/S0956796811000128},
	abstract = {O'Neill (The genuine Sieve of Eratosthenes. J. Funct. Program. 19(1), 2009, 95–106) has previously considered a functional implementation for the genuine Sieve of Eratosthenes, based on the well-known heap data structure. Here, we develop it further by adapting this data structure to this particular application.},
	pages = {563--572},
	number = {6},
	journaltitle = {Journal of Functional Programming},
	author = {Nykänen, Matti},
	date = {2011},
	file = {Cambridge Journals PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/B29HW8CD/Nykänen - 2011 - A note on the genuine Sieve of Eratosthenes.pdf:application/pdf;Cambridge Journals Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/KNR8F83K/displayAbstract.html:text/html}
}

@article{zinkewicz_dealing_2009,
	title = {Dealing with Data Leakage},
	volume = {152},
	rights = {Copyright Rough Notes Co., Inc. Apr 2009},
	issn = {00358525},
	url = {http://search.proquest.com.ezproxy1.lib.asu.edu/docview/200371198?pq-origsite=summon},
	abstract = {These days, a great many financial transactions take place without any face-to-face contact, and these transactions occur based on names and numbers -- addresses, account numbers, Social Security numbers. People use their credit cards to make online purchases, or a bank's Web site to pay their bills. The numbers are out there and could "leak" into cyberspace through something as innocent as employee error or as devious as intentional vandalism. The problem is that data leakage is an unknown until the event is realized. You can't insure something that's unknown. But you can insure the monetary loss to an organization as the result of data leakage. And you can put plans into effect to prevent data leakage. Ninety-eight percent of computer investment today involves trying to prevent people from getting into a system. It is believed that some of that money would be well spent in trying to keep information from getting out.},
	pages = {82--83},
	number = {4},
	journaltitle = {Rough Notes},
	author = {Zinkewicz, Phil},
	urldate = {2014-07-19},
	date = {2009-04},
	keywords = {Data integrity, Insurance, Insured losses, Risk management},
	file = {out.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/94QBRRN5/out.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/3MSJEIGA/200371198.html:text/html}
}

@inproceedings{mei_empirical_2009,
	title = {An Empirical Study of the Use of Frankl-Weyuker Data Flow Testing Criteria to Test {BPEL} Web Services},
	volume = {1},
	doi = {10.1109/COMPSAC.2009.21},
	abstract = {Programs using service-oriented architecture ({SOA}) often feature ultra-late binding among components. These components have well-defined interfaces and are known as Web services. Messages between every pair of Web services dually conform to the output interface of a sender and the input interface of a receiver. Unit testing of Web services should not only test the logic of Web services, but also assure the correctness of the Web services during input, manipulation, and output of messages. There is, however, little software testing research in this area. In this paper, we study the unit testing problem to assure components written in orchestration languages, {WS}-{BPEL} in particular. We report an empirical study of the effectiveness of the Frankl-Weyuker data flow testing criteria (particularly the all-uses criterion) on {WS}-{BPEL} subject programs. Our study shows that conventional data flow testing criteria can be much less effective in revealing faults in interface artifacts ({WSDL} documents) and message manipulations ({XPath} queries) than revealing faults in {BPEL} artifacts.},
	eventtitle = {Computer Software and Applications Conference, 2009. {COMPSAC} '09. 33rd Annual {IEEE} International},
	pages = {81--88},
	booktitle = {Computer Software and Applications Conference, 2009. {COMPSAC} '09. 33rd Annual {IEEE} International},
	author = {Mei, Lijun and Chan, W.K. and Tse, T. H. and Kuo, Fei-Ching},
	date = {2009-07},
	keywords = {Application software, {BPEL} Web service, business data processing, Computer applications, Councils, data flow analysis, Data flow computing, data flow testing, Frankl-Weyuker data flow testing criteria, information retrieval, Logic testing, program testing, Service oriented architecture, service-oriented architecture, software architecture, software fault, software fault tolerance, software testing, specification languages, unit testing, Web services, {WS}-{BPEL}, {XML}, {XPath}},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/F5I2F5TJ/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/NDBZHDNW/Mei et al. - 2009 - An Empirical Study of the Use of Frankl-Weyuker Da.pdf:application/pdf}
}

@online{_commentary/compiler/optordering_????,
	title = {Commentary/Compiler/{OptOrdering} – {GHC}},
	url = {https://ghc.haskell.org/trac/ghc/wiki/Commentary/Compiler/OptOrdering},
	urldate = {2014-03-11},
	file = {Commentary/Compiler/OptOrdering – GHC:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/RIXWRK39/OptOrdering.html:text/html}
}

@article{cebrian_how_2011,
	title = {How to think about algorithms, by Jeff Edmonds, Cambridge University Press, {ISBN} 0521614104},
	volume = {21},
	doi = {10.1017/S0956796811000177},
	pages = {664--666},
	number = {6},
	journaltitle = {Journal of Functional Programming},
	author = {Cebrián, Toni},
	date = {2011},
	file = {Cambridge Journals PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/X5VDU2M3/Cebrián - 2011 - How to think about algorithms, by Jeff Edmonds, Ca.pdf:application/pdf;Cambridge Journals Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/TEXDM36X/displayAbstract.html:text/html}
}

@article{_composite_????,
	title = {A Composite Privacy Leakage Indicator},
	file = {art%3A10.1007%2Fs11277-011-0383-7.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/8BBPR3B9/art%3A10.1007%2Fs11277-011-0383-7.pdf:application/pdf}
}

@online{_jacob_????,
	title = {Jacob Kaplan-Moss},
	url = {http://jacobian.org/writing/rest-worst-practices/},
	urldate = {2014-03-11},
	file = {Jacob Kaplan-Moss:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/GNMGJAQ3/rest-worst-practices.html:text/html}
}

@article{blei_correlated_2007,
	title = {A correlated topic model of Science},
	volume = {1},
	issn = {1932-6157},
	url = {http://arxiv.org/abs/0708.3601},
	doi = {10.1214/07-AOAS114},
	abstract = {Topic models, such as latent Dirichlet allocation ({LDA}), can be useful tools for the statistical analysis of document collections and other discrete data. The {LDA} model assumes that the words of each document arise from a mixture of topics, each of which is a distribution over the vocabulary. A limitation of {LDA} is the inability to model topic correlation even though, for example, a document about genetics is more likely to also be about disease than X-ray astronomy. This limitation stems from the use of the Dirichlet distribution to model the variability among the topic proportions. In this paper we develop the correlated topic model ({CTM}), where the topic proportions exhibit correlation via the logistic normal distribution [J. Roy. Statist. Soc. Ser. B 44 (1982) 139--177]. We derive a fast variational inference algorithm for approximate posterior inference in this model, which is complicated by the fact that the logistic normal is not conjugate to the multinomial. We apply the {CTM} to the articles from Science published from 1990--1999, a data set that comprises 57M words. The {CTM} gives a better fit of the data than {LDA}, and we demonstrate its use as an exploratory tool of large document collections.},
	pages = {17--35},
	number = {1},
	journaltitle = {The Annals of Applied Statistics},
	author = {Blei, David M. and Lafferty, John D.},
	urldate = {2014-09-13},
	date = {2007-06},
	eprinttype = {arxiv},
	eprint = {0708.3601},
	keywords = {Statistics - Applications},
	file = {arXiv\:0708.3601 PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/CST5ABDR/Blei and Lafferty - 2007 - A correlated topic model of Science.pdf:application/pdf;arXiv.org Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/WVVNGZUN/0708.html:text/html}
}

@inreference{_tf-idf_2014,
	title = {tf-idf},
	rights = {Creative Commons Attribution-{ShareAlike} License},
	url = {http://en.wikipedia.org/w/index.php?title=Tf%E2%80%93idf&oldid=623618416},
	abstract = {tf–idf, short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.[1]:8 It is often used as a weighting factor in information retrieval and text mining. The tf-idf value increases proportionally to the number of times a word appears in the document, but is offset by the frequency of the word in the corpus, which helps to control for the fact that some words are generally more common than others.},
	booktitle = {Wikipedia, the free encyclopedia},
	urldate = {2014-10-13},
	date = {2014-10-12},
	langid = {english},
	note = {Page Version {ID}: 623618416},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/FCISN8IP/index.html:text/html}
}

@incollection{kohle_visualizing_1996,
	title = {Visualizing similarities in high dimensional input spaces with a growing and splitting neural network},
	url = {http://link.springer.com/chapter/10.1007/3-540-61510-5_99},
	pages = {581--586},
	booktitle = {Artificial Neural Networks—{ICANN} 96},
	publisher = {Springer},
	author = {Köhle, Monika and Merkl, Dieter},
	urldate = {2014-09-08},
	date = {1996},
	file = {[PDF] from researchgate.net:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/9PSJEZ3G/Köhle and Merkl - 1996 - Visualizing similarities in high dimensional input.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/MS8PXIGN/3-540-61510-5_99.html:text/html}
}

@article{kohonen_self_2000,
	title = {Self organization of a massive document collection},
	volume = {11},
	url = {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=846729},
	pages = {574--585},
	number = {3},
	journaltitle = {Neural Networks, {IEEE} Transactions on},
	author = {Kohonen, Teuvo and Kaski, Samuel and Lagus, Krista and Salojarvi, Jarkko and Honkela, Jukka and Paatero, Vesa and Saarela, Antti},
	urldate = {2014-09-08},
	date = {2000},
	file = {[PDF] from msu.su:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/QKI6BWBF/Kohonen et al. - 2000 - Self organization of a massive document collection.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/9R9ES9SZ/login.html:text/html}
}

@article{fokkinga_hough_2011,
	title = {The Hough transform},
	volume = {21},
	doi = {10.1017/S0956796810000341},
	pages = {129--133},
	number = {2},
	journaltitle = {Journal of Functional Programming},
	author = {Fokkinga, Maarten},
	date = {2011},
	file = {Cambridge Journals Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/FRF7AHEM/displayAbstract.html:text/html}
}

@online{_semantic_????,
	title = {Semantic Search Art},
	url = {http://www.semanticsearchart.com/researchPO.html},
	urldate = {2014-02-10},
	file = {Semantic Search Art:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/P6RZ5WRT/researchPO.html:text/html}
}

@online{_is_????,
	title = {Is it possible to insert multiple rows at a time in an {SQLite} database?},
	url = {http://stackoverflow.com/questions/1609637/is-it-possible-to-insert-multiple-rows-at-a-time-in-an-sqlite-database},
	abstract = {In {MySQL} you can insert multiple rows like this:

{INSERT} {INTO} 'tablename' ('column1', 'column2') {VALUES}
    ('data1', 'data2'),
    ('data1', 'data2'),
    ('data1', 'data2'),
    ('data1', 'data2'...},
	urldate = {2014-03-11},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/KF6R9CR5/is-it-possible-to-insert-multiple-rows-at-a-time-in-an-sqlite-database.html:text/html}
}

@article{burnett_warning:_????,
	title = {{WARNING}: wild extrapolation (a classification system for science news)},
	issn = {0261-3077},
	url = {http://www.theguardian.com/science/brain-flapping/2014/sep/10/wild-extrapolation-classification-system-science-media-scepticism},
	shorttitle = {{WARNING}},
	abstract = {Science news and articles are becoming increasingly popular, but with so much being written about so many things, it can be confusing for the beginner science enthusiast to grasp what they’re reading and how to interpret it. A simple classification system could help remedy this},
	journaltitle = {The Guardian},
	author = {Burnett, Dean},
	urldate = {2014-09-13},
	langid = {british},
	keywords = {Media, Newspapers, Newspapers \& magazines, Science, Science and scepticism},
	file = {Guardian Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/8N3BNUTD/wild-extrapolation-classification-system-science-media-scepticism.html:text/html}
}

@online{_efficiency:_????,
	title = {Efficiency: How we do it – Data Centers – Google},
	url = {https://www.google.com/about/datacenters/efficiency/internal/},
	urldate = {2014-02-02},
	file = {Efficiency\: How we do it – Data Centers – Google:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/WB52FWCG/internal.html:text/html}
}

@inproceedings{wallach_evaluation_2009,
	location = {New York, {NY}, {USA}},
	title = {Evaluation Methods for Topic Models},
	isbn = {978-1-60558-516-1},
	url = {http://doi.acm.org/10.1145/1553374.1553515},
	doi = {10.1145/1553374.1553515},
	series = {{ICML} '09},
	abstract = {A natural evaluation metric for statistical topic models is the probability of held-out documents given a trained model. While exact computation of this probability is intractable, several estimators for this probability have been used in the topic modeling literature, including the harmonic mean method and empirical likelihood method. In this paper, we demonstrate experimentally that commonly-used methods are unlikely to accurately estimate the probability of held-out documents, and propose two alternative methods that are both accurate and efficient.},
	pages = {1105--1112},
	booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
	publisher = {{ACM}},
	author = {Wallach, Hanna M. and Murray, Iain and Salakhutdinov, Ruslan and Mimno, David},
	urldate = {2014-07-29},
	date = {2009},
	file = {ACM Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/GKRKRRWN/Wallach et al. - 2009 - Evaluation Methods for Topic Models.pdf:application/pdf}
}

@inproceedings{yatoh_arbitcheck:_2014,
	title = {{ArbitCheck}: A Highly Automated Property-Based Testing Tool for Java},
	doi = {10.1109/ICSTW.2014.68},
	shorttitle = {{ArbitCheck}},
	abstract = {Lightweight property-based testing tools are becoming popular these days. With property-based testing, developers can test properties of the system under test against large varieties of randomly generated inputs without writing test cases. Despite the advantages of property-based testing, current property-based testing tools have a major drawback: they require developers to write generator functions for user-defined types. This is because it is difficult for a tool to infer the possible values for the type. However, user-defined generators sometimes fail to find faults by only producing overly limited varieties of values. In this paper, we present a new property-based testing tool, called {ArbitCheck}, which automates object generation by adapting the feedback-directed random test generation technique. With the help of feedback-directed random test generation, {ArbitCheck} exhaustively generates possible values of user-defined types and tests properties with them, so that it can reveal faults that are hard to find with either manually written tests or existing property-based testing tools.},
	eventtitle = {2014 {IEEE} Seventh International Conference on Software Testing, Verification and Validation Workshops ({ICSTW})},
	pages = {405--412},
	booktitle = {2014 {IEEE} Seventh International Conference on Software Testing, Verification and Validation Workshops ({ICSTW})},
	author = {Yatoh, K. and Sakamoto, K. and Ishikawa, F. and Honiden, S.},
	date = {2014-03},
	keywords = {{ArbitCheck}, Computer bugs, Feedback-directed random test generation, generator functions, Generators, highly automated property, Java, Java testing tool, Monitoring, object generation, Object-oriented, program testing, Property-based testing, property based testing, {QuickCheck}, Random testing, Randoop, software, Testing, unit testing, Writing},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/7GU8HUWG/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/XDPFVIXE/Yatoh et al. - 2014 - ArbitCheck A Highly Automated Property-Based Test.pdf:application/pdf}
}

@online{_amazon.com_????,
	title = {Amazon.com Investor Relations: Annual Reports and Proxies},
	url = {http://phx.corporate-ir.net/phoenix.zhtml?c=97664&p=irol-reportsAnnual},
	urldate = {2014-02-02},
	file = {Amazon.com Investor Relations\: Annual Reports and Proxies:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/DZG4Z9VR/phoenix.html:text/html}
}

@inproceedings{li_two-way_2010,
	title = {Two-way trust evaluation based on feedback},
	volume = {3},
	doi = {10.1109/ICLSIM.2010.5461291},
	abstract = {The simple trust evaluation methods that result in a final trust level ({FTL}) value can't be able to evaluate service trust trend ({STT}). Furthermore, statistical trust values include some unfair and questionable trust values caused by subjective or objective factors. In response to these problems in trust management, an approach called two-way trust evaluation based on feedback is presented. This approach adopted the fitting a-ary quadratic trend curve to evaluate {STT}. According to the fitting a-ary quadratic trend curve, replace unfair and questionable trust values with {STT} expectations. Meanwhile, send feedbacks for these clients who sent unfair and questionable trust values to the trust management system and realize two-way trust evaluation based on these feedbacks. Experimental data show that this approach is able to evaluate {STT}, lessen the trust evaluation errors and enhance the fairness and rationality of trust evaluation.},
	eventtitle = {2010 International Conference on Logistics Systems and Intelligent Management},
	pages = {1910--1914},
	booktitle = {2010 International Conference on Logistics Systems and Intelligent Management},
	author = {Li, Jimin and Li, Jimin and An, Aiguo and Liu, Zhenpeng},
	date = {2010-01},
	keywords = {a-ary quadratic trend curve, ad hoc networks, Advertising, Computational modeling, Computer science, Curve fitting, Feedback, final trust level, Fitting Curve, Humans, Mathematics, objective factors, Quality of service, questionable trust values, security of data, service trust trend, simple trust evaluation, statistical trust values, subjective factors, Trust, Trust Evaluation, trust management system, Trust Trend, two-way trust evaluation based on feedback, unfair trust values, Web and internet services},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/N85Q5PUV/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/KANP9VMQ/Li et al. - 2010 - Two-way trust evaluation based on feedback.pdf:application/pdf}
}

@misc{nils_ulltveit-moe_measuring_????,
	title = {Measuring Privacy Leakage for {IDS} Rules},
	abstract = {This paper proposes a measurement approach for
estimating the privacy leakage from Intrusion Detection System
({IDS}) alarms. Quantitative information flow analysis is used
to build a theoretical model of privacy leakage from {IDS}
rules, based on information entropy. This theoretical model is
subsequently verified empirically both based on simulations and
in an experimental study. The analysis shows that the metric
is able to distinguish between {IDS} rules that have no or low
expected privacy leakage and {IDS} rules with a significant risk
of leaking sensitive information, for example on user behaviour.
The analysis is based on measurements of number of {IDS} alarms,
data length and data entropy for relevant parts of {IDS} rules (for
example payload). This is a promising approach that opens up for
privacy benchmarking of Managed Security Service providers.},
	author = {{Nils Ulltveit-Moe} and {Vladimir Oleshchuk}},
	file = {1308.5421v1.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/672PZAJS/1308.5421v1.pdf:application/pdf}
}

@article{gordon_what_2002,
	title = {What Enron means for the management and control of the modern business corporation: some initial reflections},
	url = {http://www.jstor.org.ezproxy1.lib.asu.edu/stable/1600646},
	shorttitle = {What Enron means for the management and control of the modern business corporation},
	pages = {1233--1250},
	journaltitle = {The University of Chicago Law Review},
	author = {Gordon, Jeffrey N.},
	urldate = {2014-06-19},
	date = {2002}
}

@article{_sound_????,
	title = {A sound and practical approach to quantifying security risk in enterprise networks.},
	file = {tr_homer_0809.pdf:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/CEPQVXMU/tr_homer_0809.pdf:application/pdf}
}

@online{william_w._cohen_enron_2009,
	title = {Enron Email Dataset},
	url = {https://www.cs.cmu.edu/~enron/},
	author = {{William W. Cohen}},
	urldate = {2014-02-10},
	date = {2009-08-21},
	file = {Enron Email Dataset:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/VIJ3UIC9/~enron.html:text/html}
}

@inproceedings{doumit_topic_2012,
	title = {Topic Identification and Analysis in Large News Corpora},
	url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.232.913&rep=rep1&type=pdf#page=39},
	pages = {31},
	booktitle = {Midwest Artificial Intelligence and Cognitive Science Conference},
	publisher = {Citeseer},
	author = {Doumit, Sarjoun and Minai, Ali},
	urldate = {2014-02-05},
	date = {2012},
	file = {[PDF] from psu.edu:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/8IPDIQAQ/Doumit and Minai - 2012 - Topic Identification and Analysis in Large News Co.pdf:application/pdf}
}

@inproceedings{varadharajan_interaction_2004,
	title = {Interaction trust evaluation in decentralized environments},
	volume = {{LNCS} 3182},
	pages = {144--153},
	booktitle = {Proceedings of 5th International Conference on Electronic Commerce and Web Technologies ({EC}-Web04)},
	publisher = {Springer-Verlag},
	author = {Varadharajan, Y. Wang {\textbackslash}\& V.},
	editor = {Pr?oll, K. Bauknecht {\textbackslash}\& M. Bichler {\textbackslash}\& B.},
	date = {2004-08},
	note = {Zaragoza, Spain}
}

@unpublished{andreas_pauley_introduction_????,
	title = {An Introduction to Functional Programming - {DeveloperUG} - 20140311},
	rights = {© All Rights Reserved},
	url = {http://www.slideshare.net/AndreasPauley/an-introduction-to-functional-programming-developerug-20140311},
	abstract = {Functional Programming has received increased attention in recent years. 
Some people claim that it provides important benefits to programming, but it seems somewhat inaccessible. You have to navigate through lots of academic-speak and look at examples that might only make sense to a professor in mathematics.

In this presentation I try to present some of the essential ideas behind functional programming, with simple examples first in Python and then in Haskell.

What do you need to know in order to enjoy this talk?

I have made some of the following assumptions about the kind of developer who will benefit from this talk: 
1. You are a programmer using any programming language 
2. You can read Python examples (it's {WAY} shorter on slides than C\# or Java) 
3. You are interested enough in improving your code that you are willing to challenge some common assumptions.},
	author = {Andreas Pauley},
	urldate = {2014-03-16}
}

@online{_best_????,
	title = {Best practice: Optimizing {SQLite} database performance - Data Storage - Development Guide - {BlackBerry} Java {SDK} - 6.0},
	url = {http://docs.blackberry.com/en/developers/deliverables/17952/BP_Optimizing_SQLite_database_performance_1219781_11.jsp},
	urldate = {2014-03-11},
	file = {Best practice\: Optimizing SQLite database performance - Data Storage - Development Guide - BlackBerry Java SDK - 6.0:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/ISZ48IGK/BP_Optimizing_SQLite_database_performance_1219781_11.html:text/html}
}

@article{jain_artificial_1996,
	title = {Artificial neural networks: A tutorial},
	volume = {29},
	url = {http://www.computer.org/csdl/mags/co/1996/03/r3031.pdf},
	shorttitle = {Artificial neural networks},
	pages = {31--44},
	number = {3},
	journaltitle = {Computer},
	author = {Jain, Anil K. and Mao, Jianchang and Mohiuddin, K. M.},
	urldate = {2014-09-08},
	date = {1996},
	file = {[PDF] from googlecode.com:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/FNQF7VWP/Jain et al. - 1996 - Artificial neural networks A tutorial.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/K22UIWGP/r3031-abs.html:text/html}
}

@inproceedings{yoo_mining_2009,
	location = {New York, {NY}, {USA}},
	title = {Mining Social Networks for Personalized Email Prioritization},
	isbn = {978-1-60558-495-9},
	url = {http://doi.acm.org/10.1145/1557019.1557124},
	doi = {10.1145/1557019.1557124},
	series = {{KDD} '09},
	abstract = {Email is one of the most prevalent communication tools today, and solving the email overload problem is pressingly urgent. A good way to alleviate email overload is to automatically prioritize received messages according to the priorities of each user. However, research on statistical learning methods for fully personalized email prioritization ({PEP}) has been sparse due to privacy issues, since people are reluctant to share personal messages and importance judgments with the research community. It is therefore important to develop and evaluate {PEP} methods under the assumption that only limited training examples can be available, and that the system can only have the personal email data of each user during the training and testing of the model for that user. This paper presents the first study (to the best of our knowledge) under such an assumption. Specifically, we focus on analysis of personal social networks to capture user groups and to obtain rich features that represent the social roles from the viewpoint of a particular user. We also developed a novel semi-supervised (transductive) learning algorithm that propagates importance labels from training examples to test examples through message and user nodes in a personal email network. These methods together enable us to obtain an enriched vector representation of each new email message, which consists of both standard features of an email message (such as words in the title or body, sender and receiver {IDs}, etc.) and the induced social features from the sender and receivers of the message. Using the enriched vector representation as the input in {SVM} classifiers to predict the importance level for each test message, we obtained significant performance improvement over the baseline system (without induced social features) in our experiments on a multi-user data collection. We obtained significant performance improvement over the baseline system (without induced social features) in our experiments on a multi-user data collection: the relative error reduction in {MAE} was 31\% in micro-averaging, and 14\% in macro-averaging.},
	pages = {967--976},
	booktitle = {Proceedings of the 15th {ACM} {SIGKDD} International Conference on Knowledge Discovery and Data Mining},
	publisher = {{ACM}},
	author = {Yoo, Shinjae and Yang, Yiming and Lin, Frank and Moon, Il-Chul},
	urldate = {2014-06-19},
	date = {2009},
	keywords = {email prioritization, social network, text mining},
	file = {ACM Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/UFVBFKHM/Yoo et al. - 2009 - Mining Social Networks for Personalized Email Prio.pdf:application/pdf}
}

@online{_performance/ghc_????,
	title = {Performance/{GHC} - {HaskellWiki}},
	url = {http://www.haskell.org/haskellwiki/Performance/GHC#Inlining},
	urldate = {2014-03-11},
	file = {Performance/GHC - HaskellWiki:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/35UPXQED/GHC.html:text/html}
}

@online{tyma_paul_2010,
	title = {Paul Tyma: A Google Interviewing Story},
	url = {http://paultyma.blogspot.com/2010/11/google-interviewing-story.html},
	shorttitle = {Paul Tyma},
	titleaddon = {Paul Tyma},
	author = {Tyma, Paul},
	urldate = {2014-03-11},
	date = {2010-11-18},
	file = {Blogspot Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/IZXF3ZP7/google-interviewing-story.html:text/html}
}

@inproceedings{brause_neural_1999,
	title = {Neural data mining for credit card fraud detection},
	doi = {10.1109/TAI.1999.809773},
	abstract = {The prevention of credit card fraud is an important application for prediction techniques. One major obstacle for using neural network training techniques is the high necessary diagnostic quality: since only one financial transaction in a thousand is invalid no prediction success less than 99.9\% is acceptable. Because of these credit card transaction requirements, completely new concepts had to be developed and tested on real credit card data. This paper shows how advanced data mining techniques and a neural network algorithm can be combined successfully to obtain a high fraud coverage combined with a low false alarm rate},
	eventtitle = {11th {IEEE} International Conference on Tools with Artificial Intelligence, 1999. Proceedings},
	pages = {103--106},
	booktitle = {11th {IEEE} International Conference on Tools with Artificial Intelligence, 1999. Proceedings},
	author = {Brause, R. and Langsdorf, T. and Hepp, M.},
	date = {1999},
	keywords = {credit card fraud detection, Credit cards, credit transactions, data mining, diagnostic quality, diagnostic reasoning, Electrical capacitance tomography, Electronic switching systems, Expert systems, false alarm, financial transaction, fraud, high fraud coverage, neural data mining, neural nets, neural network training techniques, Ores, prediction techniques, Testing, user behavior},
	file = {IEEE Xplore Abstract Record:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/IANWK4VM/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/BRTZAUBJ/Brause et al. - 1999 - Neural data mining for credit card fraud detection.pdf:application/pdf}
}

@online{_draw_????,
	title = {Draw different color for nodes in networkx based on their node value},
	url = {http://stackoverflow.com/questions/13517614/draw-different-color-for-nodes-in-networkx-based-on-their-node-value},
	abstract = {I have a large graph of nodes and directed edges. Furthermore, I have an additional list of values assigned to each node.

I now want to change the color of each node according to their node value....},
	urldate = {2014-09-02},
	file = {Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/S839XEGD/draw-different-color-for-nodes-in-networkx-based-on-their-node-value.html:text/html}
}

@article{teh_hierarchical_2006,
	title = {Hierarchical Dirichlet Processes},
	volume = {101},
	issn = {0162-1459},
	url = {http://amstat.tandfonline.com.ezproxy1.lib.asu.edu/doi/abs/10.1198/016214506000000302},
	doi = {10.1198/016214506000000302},
	pages = {1566--1581},
	number = {476},
	journaltitle = {Journal of the American Statistical Association},
	shortjournal = {Journal of the American Statistical Association},
	author = {Teh, Yee Whye and Jordan, Michael I and Beal, Matthew J and Blei, David M},
	urldate = {2014-07-25},
	date = {2006-12-01},
	file = {Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/956BDF56/Teh et al. - 2006 - Hierarchical Dirichlet Processes.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/J6ECM42V/016214506000000302.html:text/html}
}

@letter{matthew_[erlang-questions_2011,
	title = {[erlang-questions 41] Re: A sudoku solver in Erlang compared to Python},
	url = {http://erlang.org/pipermail/erlang-questions/2011-March/057176.html},
	shorttitle = {[erlang-questions 41] Re},
	type = {E-mail},
	author = {Matthew, Evans},
	urldate = {2014-03-16},
	date = {2011-03-26},
	file = {snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/PW8NC2H8/057176.html:text/html}
}

@article{si_exploiting_????,
	title = {Exploiting Topic based Twitter Sentiment for Stock Prediction},
	url = {http://www.newdesign.aclweb.org/anthology-new/P/P13/P13-2005.pdf},
	author = {Si, Jianfeng and Mukherjee, Arjun and Liu, Bing and Li, Qing and Li, Huayi and Deng, Xiaotie},
	urldate = {2014-02-05},
	file = {[PDF] from aclweb.org:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/GI58VWP4/Si et al. - Exploiting Topic based Twitter Sentiment for Stock.pdf:application/pdf}
}

@article{savola_development_2010,
	title = {Development of Measurable Security for a Distributed Messaging System},
	volume = {2},
	issn = {1942-2636},
	url = {http://www.thinkmind.org/index.php?view=article&articleid=sec_v2_n4_2009_5},
	pages = {358--380},
	number = {4},
	journaltitle = {International Journal On Advances in Security},
	author = {Savola, Reijo M. and Abie, Habtamu},
	urldate = {2014-05-18},
	date = {2010-03-17},
	file = {Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/EPM7RSGA/Savola and Abie - 2010 - Development of Measurable Security for a Distribut.pdf:application/pdf;Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/QZGEEN7F/index.html:text/html}
}

@online{mccallum_4_1997,
	title = {4 Universities Data Set},
	url = {http://www.cs.cmu.edu/afs/cs.cmu.edu/project/theo-20/www/data/webkb-data.gtar.gz},
	titleaddon = {The 4 Universities Data Set},
	author = {{McCallum}, Andrew and Mitchell, Tom},
	date = {1997-01}
}

@article{ackerman_extracting_2013,
	title = {Extracting Causal Relations between News Topics from Distributed Sources},
	url = {http://www.qucosa.de/fileadmin/data/qucosa/documents/13006/doc.pdf},
	author = {Ackerman, Eduardo Jacobo Miranda},
	urldate = {2014-02-05},
	date = {2013},
	file = {[PDF] from qucosa.de:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/WBVQX4A3/Ackerman - 2013 - Extracting Causal Relations between News Topics fr.pdf:application/pdf}
}

@article{kaelbling_planning_1998,
	title = {Planning and Acting in Partially Observable Stochastic Domains},
	volume = {101.1-2},
	pages = {99--134},
	journaltitle = {Artificial Intelligence},
	author = {Kaelbling, Leslie P. and Littman, Michael L. and Cassandra, Anthony R.},
	date = {1998},
	keywords = {Partially observable Markov decision processes, Planning, Uncertainty},
	file = {ScienceDirect Full Text PDF:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/8TIXRAMF/Kaelbling et al. - 1998 - Planning and acting in partially observable stocha.pdf:application/pdf;ScienceDirect Snapshot:/home/jwright/.mozilla/firefox/pkxakp65.default/zotero/storage/JAU3WWRK/S000437029800023X.html:text/html}
}

@inproceedings{sharma_bayesian_2010,
	title = {A Bayesian game based adaptive fuzzy controller for multi agent {POMDPs}},
	pages = {1--7},
	booktitle = {Fuzzy Systems ({FUZZ})},
	publisher = {2010 {IEEE} International Conference on Communication},
	author = {Sharma, R. and Spaan, M.T.J},
	date = {2010},
	note = {Networking \& Broadcasting}
}
